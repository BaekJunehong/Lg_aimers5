{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<? column in train_data>\n",
      "CURE END POSITION ? Collect Result_Dam\n",
      "CURE START POSITION ? Collect Result_Dam\n",
      "<? column in test_data>\n",
      "<Θ in train_data>\n",
      "train_data:\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "test_data:\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "<Dam 공정 관련 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam\n",
      "Head Clean Position Z Collect Result_Dam\n",
      "Head Purge Position Z Collect Result_Dam\n",
      "Head Zero Position Y Collect Result_Dam\n",
      "Head Zero Position Z Collect Result_Dam\n",
      "Machine Tact time Collect Result_Dam\n",
      "PalletID Collect Result_Dam\n",
      "Production Qty Collect Result_Dam\n",
      "Receip No Collect Result_Dam\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n",
      "THICKNESS 1 Collect Result_Dam\n",
      "THICKNESS 2 Collect Result_Dam\n",
      "THICKNESS 3 Collect Result_Dam\n",
      "WorkMode Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "def plot_box(dataframe, column_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 열 이름에 대해 박스 플롯을 그리는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(dataframe[column_name], vert=False)\n",
    "    plt.xlabel(column_name)\n",
    "    plt.title(f'Box Plot of {column_name}')\n",
    "    plt.show()\n",
    "    \n",
    "def value_counts_ratio_count(df, col_name, target_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 비율과 갯수, 총 갯수를 출력하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 데이터프레임\n",
    "    col_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    \"\"\"\n",
    "    # 각 값마다 타겟 변수의 비율 계산\n",
    "    value_counts = df.groupby(col_name)[target_name].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 타겟 변수의 갯수 계산\n",
    "    counts = df.groupby(col_name)[target_name].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 총 갯수 계산\n",
    "    total_counts = df[col_name].value_counts().rename('Total_Count')\n",
    "    \n",
    "    # 비율과 갯수를 합침\n",
    "    result = value_counts.join(counts, lsuffix='_ratio', rsuffix='_count')\n",
    "    \n",
    "    # 총 갯수를 합침\n",
    "    result = result.join(total_counts, on=col_name)\n",
    "    \n",
    "    # 출력 형식 조정\n",
    "    result.index.name = 'variable'\n",
    "    print(f\"\\n{col_name}별 {target_name} 비율 및 갯수\\n\")\n",
    "    print(result.rename(columns=lambda x: x.split('_')[0]))\n",
    "    \n",
    "\n",
    "def summarize_grouped_data(df, group_by_columns):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_columns)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AdNormal' 비율과 갯수 계산\n",
    "        adnormal_count = group['target'].value_counts().get('AbNormal', 0)\n",
    "        adnormal_ratio = adnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, adnormal_count, adnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', \"'AdNormal' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그룹화된 변수들의 이름을 제목행으로 출력\n",
    "    print(f\"Grouped by: {', '.join(group_by_columns)}\")\n",
    "    print()\n",
    "    # 데이터프레임 출력\n",
    "    print(results_df)\n",
    "    \n",
    "    return results_df\n",
    "  \n",
    "  \n",
    "def plot_abnormal_ratio(dataframe, column_name, target_name, target_value, bins=20):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 특정 값 비율을 계산하고 막대그래프로 표시하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    target_value (str): 타겟 변수의 특정 값\n",
    "    bins (int): 구간의 수 (기본값은 20)\n",
    "    \"\"\"\n",
    "    def abnormal_ratio(dataframe, column_name, target_name, target_value):\n",
    "        \"\"\"\n",
    "        주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 특정 값 비율을 계산하는 함수.\n",
    "\n",
    "        Parameters:\n",
    "        dataframe (pd.DataFrame): 데이터프레임\n",
    "        column_name (str): 열 이름\n",
    "        target_name (str): 타겟 변수 이름\n",
    "        target_value (str): 타겟 변수의 특정 값\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: 각 값마다 타겟 변수의 특정 값 비율을 포함하는 데이터프레임\n",
    "        \"\"\"\n",
    "        # 각 값마다 타겟 변수의 특정 값 비율 계산\n",
    "        value_counts = dataframe.groupby(column_name)[target_name].apply(lambda x: (x == target_value).mean()).reset_index()\n",
    "        count_counts = dataframe.groupby(column_name)[target_name].count().reset_index()\n",
    "        \n",
    "        value_counts.columns = [column_name, 'ratio']\n",
    "        count_counts.columns = [column_name, 'count']\n",
    "        \n",
    "        # 비율과 카운트를 병합\n",
    "        result = pd.merge(value_counts, count_counts, on=column_name)\n",
    "        return result\n",
    "\n",
    "    # column_name 값을 지정된 구간으로 나누기\n",
    "    dataframe[f'{column_name}_bins'] = pd.cut(dataframe[column_name], bins=bins)\n",
    "\n",
    "    # 비율 계산\n",
    "    ratios = abnormal_ratio(dataframe, f'{column_name}_bins', target_name, target_value)\n",
    "\n",
    "    # 막대그래프 그리기\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    barplot = sns.barplot(x=f'{column_name}_bins', y='ratio', data=ratios, color='skyblue')\n",
    "    plt.xlabel(f'{column_name} (binned)')\n",
    "    plt.ylabel('AbNormal Ratio')\n",
    "    plt.title(f'AbNormal Ratio by {column_name} (binned)', pad=30)  # 제목과 그래프 사이의 간격 조정\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    # 각 막대 위에 비율 값과 카운트 표시\n",
    "    for p in barplot.patches:\n",
    "        # 막대의 x 좌표에 해당하는 구간을 찾기\n",
    "        bin_label = ratios[f'{column_name}_bins'].cat.categories[int(p.get_x() + p.get_width() / 2) - 1]\n",
    "        count_value = ratios.loc[ratios[f'{column_name}_bins'] == bin_label, 'count'].values[0]\n",
    "        barplot.annotate(f'{format(p.get_height(), \".2f\")} ({count_value})', \n",
    "                         (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                         ha='center', va='center', \n",
    "                         xytext=(0, 9), \n",
    "                         textcoords='offset points')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # _bins 변수 드랍\n",
    "    dataframe.drop(columns=[f'{column_name}_bins'], inplace=True)\n",
    "    \n",
    "    \n",
    "# train_data와 test_data에서 '?'를 포함하는 열 이름 필터링\n",
    "train_Process_Desc_col = train_data.filter(like='?').columns\n",
    "test_Process_Desc_col = test_data.filter(like='?').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<? column in train_data>\")\n",
    "for col in train_Process_Desc_col:\n",
    "    print(col)\n",
    "\n",
    "print(\"<? column in test_data>\")\n",
    "for col in test_Process_Desc_col:\n",
    "    print(col)\n",
    "\n",
    "# ? -> Θ로 변경할 열 이름과 새 열 이름 생성\n",
    "train_new_columns = {col: col.replace('?', 'Θ') for col in train_Process_Desc_col}\n",
    "test_new_columns = {col: col.replace('?', 'Θ') for col in test_Process_Desc_col}\n",
    "\n",
    "# 열 이름 변경\n",
    "train_data.rename(columns=train_new_columns, inplace=True)\n",
    "test_data.rename(columns=test_new_columns, inplace=True)\n",
    "\n",
    "# 'Θ'를 포함하는 열 이름 필터링\n",
    "train_Process_Desc_col = train_data.filter(like='Θ').columns\n",
    "test_Process_Desc_col = test_data.filter(like='Θ').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Θ in train_data>\")\n",
    "print(\"train_data:\")\n",
    "for col in train_Process_Desc_col:\n",
    "    print(col)\n",
    "\n",
    "print(\"test_data:\")\n",
    "for col in test_Process_Desc_col:\n",
    "    print(col)\n",
    "    \n",
    "# '_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Dam 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEAD Clean position Z 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Head Clean Position Z Collect Result_Dam\n",
       "130.85    23418\n",
       "124.00     8493\n",
       "133.50     8231\n",
       "124.50      331\n",
       "118.85       33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Head Clean Position Z Collect Result_Dam'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Model.Suffix, Head Clean Position Z Collect Result_Dam\n",
      "\n",
      "                    group  'AdNormal' count     ratio  Total\n",
      "0   (AJX75334501, 118.85)                 0  0.000000     33\n",
      "1    (AJX75334501, 124.0)               200  0.041459   4824\n",
      "2    (AJX75334501, 124.5)                28  0.084592    331\n",
      "3   (AJX75334501, 130.85)               965  0.047184  20452\n",
      "4    (AJX75334501, 133.5)               725  0.088631   8180\n",
      "5    (AJX75334502, 124.0)                58  0.068884    842\n",
      "6   (AJX75334502, 130.85)               163  0.065226   2499\n",
      "7    (AJX75334502, 133.5)                 9  0.183673     49\n",
      "8    (AJX75334503, 124.0)                 1  0.010417     96\n",
      "9   (AJX75334503, 130.85)                43  0.671875     64\n",
      "10   (AJX75334503, 133.5)                 0  0.000000      2\n",
      "11   (AJX75334505, 124.0)               128  0.050354   2542\n",
      "12  (AJX75334505, 130.85)                 2  0.021505     93\n",
      "13   (AJX75334506, 124.0)                 2  0.083333     24\n",
      "14  (AJX75334506, 130.85)                 6  0.057143    105\n",
      "15   (AJX75334507, 124.0)                12  0.087591    137\n",
      "16  (AJX75334507, 130.85)                 6  0.034682    173\n",
      "17   (AJX75334508, 124.0)                 2  0.071429     28\n",
      "18  (AJX75334508, 130.85)                 0  0.000000     32\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['Model.Suffix','Head Clean Position Z Collect Result_Dam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성: 3개의 컬럼 값이 모두 동일하면 해당 값을 저장, 아니면 diff\n",
    "train_data['Receip_No'] = train_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "test_data['Receip_No'] = test_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성: Receip No와 Model.Suffix의 조합\n",
    "train_data['model_receip'] = train_data['Model.Suffix'] + '_' + train_data['Receip_No'].astype(str)\n",
    "test_data['model_receip'] = test_data['Model.Suffix'] + '_' + test_data['Receip_No'].astype(str)\n",
    "\n",
    "# 파생변수 생성: workorder 앞 4자리 -> workorder_prefix\n",
    "train_data['workorder_prefix'] = train_data['Workorder'].str[:4]\n",
    "test_data['workorder_prefix'] = test_data['Workorder'].str[:4]\n",
    "\n",
    "# 파생변수 생성: Receip No와 workorder_prefix의 조합 -> diff, 3.0, 9.0의 경우에만\n",
    "train_data['workorder_receip'] = train_data.apply(\n",
    "    lambda row: f\"{row['workorder_prefix']}_{row['Receip_No']}\" \n",
    "    if row['Receip_No'] in ['diff', 3.0, 9.0] else row['workorder_prefix'],\n",
    "    axis=1\n",
    ")\n",
    "test_data['workorder_receip'] = test_data.apply(\n",
    "    lambda row: f\"{row['workorder_prefix']}_{row['Receip_No']}\" \n",
    "    if row['Receip_No'] in ['diff', 3.0, 9.0] else row['workorder_prefix'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "workorder_receip\n",
       "3G1X         4608\n",
       "3M1X         4585\n",
       "3J1X         4057\n",
       "4A1X         3962\n",
       "3L1X         3665\n",
       "3H1X         3322\n",
       "3K1X         3176\n",
       "4B1X         2852\n",
       "4E1X         2696\n",
       "3I1X         2227\n",
       "4C1X         2103\n",
       "3F1X         1276\n",
       "4F1X          960\n",
       "3LPM          153\n",
       "4BPM          139\n",
       "3KPM          123\n",
       "3JPX          100\n",
       "3MPX           78\n",
       "4BPX_9         68\n",
       "3HPX_3         64\n",
       "3HPM           63\n",
       "4CPM           53\n",
       "4EPM           46\n",
       "3FPM           24\n",
       "3HPX_9         24\n",
       "3GPM           23\n",
       "3HPX           21\n",
       "3KPX           11\n",
       "4APX            9\n",
       "4CPX            8\n",
       "4APX_9          4\n",
       "4B1X_diff       3\n",
       "3FPX            2\n",
       "3M1X_diff       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['workorder_receip'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_prefix, Head Clean Position Z Collect Result_Dam\n",
      "\n",
      "             group  'AdNormal' count     ratio  Total\n",
      "0    (3F1X, 124.5)                28  0.084592    331\n",
      "1    (3F1X, 133.5)                85  0.089947    945\n",
      "2    (3FPM, 133.5)                 0  0.000000     24\n",
      "3    (3FPX, 133.5)                 0  0.000000      2\n",
      "4    (3G1X, 133.5)               435  0.094401   4608\n",
      "5    (3GPM, 133.5)                 1  0.043478     23\n",
      "6   (3H1X, 130.85)                60  0.079365    756\n",
      "7    (3H1X, 133.5)               209  0.081450   2566\n",
      "8    (3HPM, 133.5)                 4  0.063492     63\n",
      "9    (3HPX, 124.0)                 0  0.000000     24\n",
      "10  (3HPX, 130.85)                46  0.541176     85\n",
      "11  (3I1X, 130.85)               165  0.074091   2227\n",
      "12  (3J1X, 130.85)               190  0.046833   4057\n",
      "13  (3JPX, 130.85)                 4  0.040000    100\n",
      "14  (3K1X, 130.85)               100  0.031486   3176\n",
      "15  (3KPM, 130.85)                 6  0.048780    123\n",
      "16  (3KPX, 130.85)                11  1.000000     11\n",
      "17  (3L1X, 130.85)               143  0.039018   3665\n",
      "18  (3LPM, 130.85)                 1  0.006536    153\n",
      "19  (3M1X, 130.85)               252  0.054950   4586\n",
      "20   (3MPX, 124.0)                 1  0.016667     60\n",
      "21  (3MPX, 130.85)                 3  0.166667     18\n",
      "22  (4A1X, 130.85)               195  0.049218   3962\n",
      "23   (4APX, 124.0)                 0  0.000000      4\n",
      "24  (4APX, 130.85)                 0  0.000000      9\n",
      "25  (4B1X, 118.85)                 0  0.000000     33\n",
      "26   (4B1X, 124.0)               102  0.043739   2332\n",
      "27  (4B1X, 130.85)                 9  0.018367    490\n",
      "28   (4BPM, 124.0)                 5  0.035971    139\n",
      "29   (4BPX, 124.0)                 1  0.014706     68\n",
      "30   (4C1X, 124.0)                88  0.041845   2103\n",
      "31   (4CPM, 124.0)                 0  0.000000     53\n",
      "32   (4CPX, 124.0)                 8  1.000000      8\n",
      "33   (4E1X, 124.0)               140  0.051929   2696\n",
      "34   (4EPM, 124.0)                 6  0.130435     46\n",
      "35   (4F1X, 124.0)                52  0.054167    960\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_prefix','Head Clean Position Z Collect Result_Dam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_receip, Head Clean Position Z Collect Result_Dam\n",
      "\n",
      "                  group  'AdNormal' count     ratio  Total\n",
      "0         (3F1X, 124.5)                28  0.084592    331\n",
      "1         (3F1X, 133.5)                85  0.089947    945\n",
      "2         (3FPM, 133.5)                 0  0.000000     24\n",
      "3         (3FPX, 133.5)                 0  0.000000      2\n",
      "4         (3G1X, 133.5)               435  0.094401   4608\n",
      "5         (3GPM, 133.5)                 1  0.043478     23\n",
      "6        (3H1X, 130.85)                60  0.079365    756\n",
      "7         (3H1X, 133.5)               209  0.081450   2566\n",
      "8         (3HPM, 133.5)                 4  0.063492     63\n",
      "9        (3HPX, 130.85)                 3  0.142857     21\n",
      "10     (3HPX_3, 130.85)                43  0.671875     64\n",
      "11      (3HPX_9, 124.0)                 0  0.000000     24\n",
      "12       (3I1X, 130.85)               165  0.074091   2227\n",
      "13       (3J1X, 130.85)               190  0.046833   4057\n",
      "14       (3JPX, 130.85)                 4  0.040000    100\n",
      "15       (3K1X, 130.85)               100  0.031486   3176\n",
      "16       (3KPM, 130.85)                 6  0.048780    123\n",
      "17       (3KPX, 130.85)                11  1.000000     11\n",
      "18       (3L1X, 130.85)               143  0.039018   3665\n",
      "19       (3LPM, 130.85)                 1  0.006536    153\n",
      "20       (3M1X, 130.85)               251  0.054744   4585\n",
      "21  (3M1X_diff, 130.85)                 1  1.000000      1\n",
      "22        (3MPX, 124.0)                 1  0.016667     60\n",
      "23       (3MPX, 130.85)                 3  0.166667     18\n",
      "24       (4A1X, 130.85)               195  0.049218   3962\n",
      "25       (4APX, 130.85)                 0  0.000000      9\n",
      "26      (4APX_9, 124.0)                 0  0.000000      4\n",
      "27       (4B1X, 118.85)                 0  0.000000     33\n",
      "28        (4B1X, 124.0)                99  0.042508   2329\n",
      "29       (4B1X, 130.85)                 9  0.018367    490\n",
      "30   (4B1X_diff, 124.0)                 3  1.000000      3\n",
      "31        (4BPM, 124.0)                 5  0.035971    139\n",
      "32      (4BPX_9, 124.0)                 1  0.014706     68\n",
      "33        (4C1X, 124.0)                88  0.041845   2103\n",
      "34        (4CPM, 124.0)                 0  0.000000     53\n",
      "35        (4CPX, 124.0)                 8  1.000000      8\n",
      "36        (4E1X, 124.0)               140  0.051929   2696\n",
      "37        (4EPM, 124.0)                 6  0.130435     46\n",
      "38        (4F1X, 124.0)                52  0.054167    960\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_receip','Head Clean Position Z Collect Result_Dam'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head Purge Position Z 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_receip, Head Clean Position Z Collect Result_Dam, Head Purge Position Z Collect Result_Dam\n",
      "\n",
      "                          group  'AdNormal' count     ratio  Total\n",
      "0          (3F1X, 124.5, 124.5)                28  0.084592    331\n",
      "1          (3F1X, 133.5, 133.5)                85  0.089947    945\n",
      "2          (3FPM, 133.5, 133.5)                 0  0.000000     24\n",
      "3          (3FPX, 133.5, 133.5)                 0  0.000000      2\n",
      "4          (3G1X, 133.5, 133.5)               435  0.094401   4608\n",
      "5          (3GPM, 133.5, 133.5)                 1  0.043478     23\n",
      "6        (3H1X, 130.85, 130.85)                58  0.078273    741\n",
      "7         (3H1X, 130.85, 133.5)                 2  0.133333     15\n",
      "8          (3H1X, 133.5, 133.5)               209  0.081450   2566\n",
      "9          (3HPM, 133.5, 133.5)                 4  0.063492     63\n",
      "10       (3HPX, 130.85, 130.85)                 3  0.142857     21\n",
      "11     (3HPX_3, 130.85, 130.85)                43  0.671875     64\n",
      "12      (3HPX_9, 124.0, 130.85)                 0  0.000000     24\n",
      "13       (3I1X, 130.85, 130.85)               165  0.074091   2227\n",
      "14       (3J1X, 130.85, 130.85)               190  0.046833   4057\n",
      "15       (3JPX, 130.85, 130.85)                 4  0.040000    100\n",
      "16       (3K1X, 130.85, 130.85)               100  0.031486   3176\n",
      "17       (3KPM, 130.85, 130.85)                 6  0.048780    123\n",
      "18       (3KPX, 130.85, 130.85)                11  1.000000     11\n",
      "19       (3L1X, 130.85, 130.85)               143  0.039018   3665\n",
      "20       (3LPM, 130.85, 130.85)                 1  0.006536    153\n",
      "21       (3M1X, 130.85, 130.85)               251  0.054744   4585\n",
      "22  (3M1X_diff, 130.85, 130.85)                 1  1.000000      1\n",
      "23        (3MPX, 124.0, 130.85)                 1  0.016667     60\n",
      "24       (3MPX, 130.85, 130.85)                 3  0.166667     18\n",
      "25       (4A1X, 130.85, 130.85)               195  0.049218   3962\n",
      "26       (4APX, 130.85, 130.85)                 0  0.000000      9\n",
      "27      (4APX_9, 124.0, 130.85)                 0  0.000000      4\n",
      "28       (4B1X, 118.85, 130.85)                 0  0.000000     33\n",
      "29        (4B1X, 124.0, 130.85)                99  0.042508   2329\n",
      "30       (4B1X, 130.85, 130.85)                 9  0.018367    490\n",
      "31   (4B1X_diff, 124.0, 130.85)                 3  1.000000      3\n",
      "32        (4BPM, 124.0, 130.85)                 5  0.035971    139\n",
      "33      (4BPX_9, 124.0, 130.85)                 1  0.014706     68\n",
      "34        (4C1X, 124.0, 130.85)                88  0.041845   2103\n",
      "35        (4CPM, 124.0, 130.85)                 0  0.000000     53\n",
      "36        (4CPX, 124.0, 130.85)                 8  1.000000      8\n",
      "37        (4E1X, 124.0, 130.85)               140  0.051929   2696\n",
      "38        (4EPM, 124.0, 130.85)                 6  0.130435     46\n",
      "39        (4F1X, 124.0, 130.85)                52  0.054167    960\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_receip',\n",
    "                                                 'Head Clean Position Z Collect Result_Dam'\n",
    "                                                 , 'Head Purge Position Z Collect Result_Dam'\n",
    "                                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head Zero Position Y 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_receip, Head Zero Position Y Collect Result_Dam\n",
      "\n",
      "                 group  'AdNormal' count     ratio  Total\n",
      "0        (3F1X, 303.5)               113  0.088558   1276\n",
      "1        (3FPM, 303.5)                 0  0.000000     24\n",
      "2        (3FPX, 303.5)                 0  0.000000      2\n",
      "3        (3G1X, 300.0)               110  0.088710   1240\n",
      "4        (3G1X, 303.5)               325  0.096496   3368\n",
      "5        (3GPM, 303.5)                 1  0.043478     23\n",
      "6        (3H1X, 300.0)               269  0.080975   3322\n",
      "7        (3HPM, 300.0)                 4  0.063492     63\n",
      "8        (3HPX, 300.0)                 3  0.142857     21\n",
      "9      (3HPX_3, 303.5)                43  0.671875     64\n",
      "10     (3HPX_9, 300.0)                 0  0.000000     24\n",
      "11       (3I1X, 300.0)               165  0.074091   2227\n",
      "12       (3J1X, 300.0)               190  0.046833   4057\n",
      "13       (3JPX, 300.0)                 4  0.040000    100\n",
      "14       (3K1X, 300.0)               100  0.031486   3176\n",
      "15       (3KPM, 300.0)                 6  0.048780    123\n",
      "16       (3KPX, 300.0)                11  1.000000     11\n",
      "17       (3L1X, 300.0)               143  0.039018   3665\n",
      "18       (3LPM, 300.0)                 1  0.006536    153\n",
      "19       (3M1X, 300.0)               251  0.054744   4585\n",
      "20  (3M1X_diff, 300.0)                 1  1.000000      1\n",
      "21       (3MPX, 300.0)                 4  0.051282     78\n",
      "22       (4A1X, 300.0)               195  0.049218   3962\n",
      "23       (4APX, 300.0)                 0  0.000000      9\n",
      "24     (4APX_9, 300.0)                 0  0.000000      4\n",
      "25       (4B1X, 300.0)               108  0.037868   2852\n",
      "26  (4B1X_diff, 300.0)                 3  1.000000      3\n",
      "27       (4BPM, 300.0)                 5  0.035971    139\n",
      "28     (4BPX_9, 300.0)                 1  0.014706     68\n",
      "29       (4C1X, 300.0)                88  0.041845   2103\n",
      "30       (4CPM, 300.0)                 0  0.000000     53\n",
      "31       (4CPX, 300.0)                 8  1.000000      8\n",
      "32       (4E1X, 300.0)               140  0.051929   2696\n",
      "33       (4EPM, 300.0)                 6  0.130435     46\n",
      "34       (4F1X, 300.0)                52  0.054167    960\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_receip','Head Zero Position Y Collect Result_Dam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_receip, Head Clean Position Z Collect Result_Dam, Head Zero Position Y Collect Result_Dam\n",
      "\n",
      "                         group  'AdNormal' count     ratio  Total\n",
      "0         (3F1X, 124.5, 303.5)                28  0.084592    331\n",
      "1         (3F1X, 133.5, 303.5)                85  0.089947    945\n",
      "2         (3FPM, 133.5, 303.5)                 0  0.000000     24\n",
      "3         (3FPX, 133.5, 303.5)                 0  0.000000      2\n",
      "4         (3G1X, 133.5, 300.0)               110  0.088710   1240\n",
      "5         (3G1X, 133.5, 303.5)               325  0.096496   3368\n",
      "6         (3GPM, 133.5, 303.5)                 1  0.043478     23\n",
      "7        (3H1X, 130.85, 300.0)                60  0.079365    756\n",
      "8         (3H1X, 133.5, 300.0)               209  0.081450   2566\n",
      "9         (3HPM, 133.5, 300.0)                 4  0.063492     63\n",
      "10       (3HPX, 130.85, 300.0)                 3  0.142857     21\n",
      "11     (3HPX_3, 130.85, 303.5)                43  0.671875     64\n",
      "12      (3HPX_9, 124.0, 300.0)                 0  0.000000     24\n",
      "13       (3I1X, 130.85, 300.0)               165  0.074091   2227\n",
      "14       (3J1X, 130.85, 300.0)               190  0.046833   4057\n",
      "15       (3JPX, 130.85, 300.0)                 4  0.040000    100\n",
      "16       (3K1X, 130.85, 300.0)               100  0.031486   3176\n",
      "17       (3KPM, 130.85, 300.0)                 6  0.048780    123\n",
      "18       (3KPX, 130.85, 300.0)                11  1.000000     11\n",
      "19       (3L1X, 130.85, 300.0)               143  0.039018   3665\n",
      "20       (3LPM, 130.85, 300.0)                 1  0.006536    153\n",
      "21       (3M1X, 130.85, 300.0)               251  0.054744   4585\n",
      "22  (3M1X_diff, 130.85, 300.0)                 1  1.000000      1\n",
      "23        (3MPX, 124.0, 300.0)                 1  0.016667     60\n",
      "24       (3MPX, 130.85, 300.0)                 3  0.166667     18\n",
      "25       (4A1X, 130.85, 300.0)               195  0.049218   3962\n",
      "26       (4APX, 130.85, 300.0)                 0  0.000000      9\n",
      "27      (4APX_9, 124.0, 300.0)                 0  0.000000      4\n",
      "28       (4B1X, 118.85, 300.0)                 0  0.000000     33\n",
      "29        (4B1X, 124.0, 300.0)                99  0.042508   2329\n",
      "30       (4B1X, 130.85, 300.0)                 9  0.018367    490\n",
      "31   (4B1X_diff, 124.0, 300.0)                 3  1.000000      3\n",
      "32        (4BPM, 124.0, 300.0)                 5  0.035971    139\n",
      "33      (4BPX_9, 124.0, 300.0)                 1  0.014706     68\n",
      "34        (4C1X, 124.0, 300.0)                88  0.041845   2103\n",
      "35        (4CPM, 124.0, 300.0)                 0  0.000000     53\n",
      "36        (4CPX, 124.0, 300.0)                 8  1.000000      8\n",
      "37        (4E1X, 124.0, 300.0)               140  0.051929   2696\n",
      "38        (4EPM, 124.0, 300.0)                 6  0.130435     46\n",
      "39        (4F1X, 124.0, 300.0)                52  0.054167    960\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_receip',\n",
    "                                                 'Head Clean Position Z Collect Result_Dam'\n",
    "                                                 , 'Head Zero Position Y Collect Result_Dam'\n",
    "                                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thickness 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: THICKNESS 1 Collect Result_Dam, THICKNESS 2 Collect Result_Dam\n",
      "\n",
      "              group  'AdNormal' count     ratio  Total\n",
      "0  (-0.054, -0.219)                37  0.041855    884\n",
      "1  (-0.019, -0.021)                74  0.044876   1649\n",
      "2  (-0.015, -0.036)                72  0.074689    964\n",
      "3        (0.0, 0.0)              2091  0.059036  35419\n",
      "4   (0.012, -0.022)                 2  0.016000    125\n",
      "5   (0.014, -0.058)                62  0.051796   1197\n",
      "6    (0.014, 0.007)                 6  0.040000    150\n",
      "7    (0.037, 0.005)                 6  0.050847    118\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['THICKNESS 1 Collect Result_Dam','THICKNESS 2 Collect Result_Dam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Model.Suffix, THICKNESS 1 Collect Result_Dam, THICKNESS 2 Collect Result_Dam\n",
      "\n",
      "                            group  'AdNormal' count     ratio  Total\n",
      "0   (AJX75334501, -0.054, -0.219)                17  0.029463    577\n",
      "1   (AJX75334501, -0.019, -0.021)                37  0.039828    929\n",
      "2   (AJX75334501, -0.015, -0.036)                35  0.081967    427\n",
      "3         (AJX75334501, 0.0, 0.0)              1810  0.057776  31328\n",
      "4    (AJX75334501, 0.012, -0.022)                 2  0.016000    125\n",
      "5    (AJX75334501, 0.014, -0.058)                13  0.040373    322\n",
      "6     (AJX75334501, 0.014, 0.007)                 4  0.045977     87\n",
      "7     (AJX75334501, 0.037, 0.005)                 0  0.000000     25\n",
      "8   (AJX75334502, -0.054, -0.219)                20  0.071685    279\n",
      "9   (AJX75334502, -0.019, -0.021)                13  0.057269    227\n",
      "10  (AJX75334502, -0.015, -0.036)                12  0.120000    100\n",
      "11        (AJX75334502, 0.0, 0.0)               177  0.064954   2725\n",
      "12   (AJX75334502, 0.014, -0.058)                 8  0.135593     59\n",
      "13  (AJX75334503, -0.054, -0.219)                 0  0.000000     28\n",
      "14  (AJX75334503, -0.019, -0.021)                 1  0.111111      9\n",
      "15        (AJX75334503, 0.0, 0.0)                43  0.344000    125\n",
      "16  (AJX75334505, -0.019, -0.021)                21  0.044968    467\n",
      "17  (AJX75334505, -0.015, -0.036)                17  0.039627    429\n",
      "18        (AJX75334505, 0.0, 0.0)                44  0.053204    827\n",
      "19   (AJX75334505, 0.014, -0.058)                40  0.052910    756\n",
      "20    (AJX75334505, 0.014, 0.007)                 2  0.031746     63\n",
      "21    (AJX75334505, 0.037, 0.005)                 6  0.064516     93\n",
      "22  (AJX75334506, -0.019, -0.021)                 2  0.117647     17\n",
      "23        (AJX75334506, 0.0, 0.0)                 6  0.053571    112\n",
      "24  (AJX75334507, -0.015, -0.036)                 8  1.000000      8\n",
      "25        (AJX75334507, 0.0, 0.0)                 9  0.037190    242\n",
      "26   (AJX75334507, 0.014, -0.058)                 1  0.016667     60\n",
      "27        (AJX75334508, 0.0, 0.0)                 2  0.033333     60\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['Model.Suffix',\n",
    "                                                 'THICKNESS 1 Collect Result_Dam'\n",
    "                                                 , 'THICKNESS 2 Collect Result_Dam'\n",
    "                                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: workorder_receip, THICKNESS 1 Collect Result_Dam, THICKNESS 2 Collect Result_Dam\n",
      "\n",
      "                       group  'AdNormal' count     ratio  Total\n",
      "0           (3F1X, 0.0, 0.0)               113  0.088558   1276\n",
      "1           (3FPM, 0.0, 0.0)                 0  0.000000     24\n",
      "2           (3FPX, 0.0, 0.0)                 0  0.000000      2\n",
      "3           (3G1X, 0.0, 0.0)               435  0.094401   4608\n",
      "4           (3GPM, 0.0, 0.0)                 1  0.043478     23\n",
      "5           (3H1X, 0.0, 0.0)               269  0.080975   3322\n",
      "6           (3HPM, 0.0, 0.0)                 4  0.063492     63\n",
      "7           (3HPX, 0.0, 0.0)                 3  0.142857     21\n",
      "8         (3HPX_3, 0.0, 0.0)                43  0.671875     64\n",
      "9   (3HPX_9, -0.054, -0.219)                 0  0.000000     24\n",
      "10          (3I1X, 0.0, 0.0)               165  0.074091   2227\n",
      "11          (3J1X, 0.0, 0.0)               190  0.046833   4057\n",
      "12          (3JPX, 0.0, 0.0)                 4  0.040000    100\n",
      "13          (3K1X, 0.0, 0.0)               100  0.031486   3176\n",
      "14          (3KPM, 0.0, 0.0)                 6  0.048780    123\n",
      "15          (3KPX, 0.0, 0.0)                11  1.000000     11\n",
      "16          (3L1X, 0.0, 0.0)               143  0.039018   3665\n",
      "17          (3LPM, 0.0, 0.0)                 1  0.006536    153\n",
      "18          (3M1X, 0.0, 0.0)               251  0.054744   4585\n",
      "19     (3M1X_diff, 0.0, 0.0)                 1  1.000000      1\n",
      "20          (3MPX, 0.0, 0.0)                 3  0.166667     18\n",
      "21     (3MPX, 0.014, -0.058)                 1  0.016667     60\n",
      "22          (4A1X, 0.0, 0.0)               195  0.049218   3962\n",
      "23          (4APX, 0.0, 0.0)                 0  0.000000      9\n",
      "24  (4APX_9, -0.054, -0.219)                 0  0.000000      4\n",
      "25    (4B1X, -0.054, -0.219)                37  0.043224    856\n",
      "26          (4B1X, 0.0, 0.0)                71  0.035571   1996\n",
      "27     (4B1X_diff, 0.0, 0.0)                 3  1.000000      3\n",
      "28          (4BPM, 0.0, 0.0)                 5  0.035971    139\n",
      "29  (4BPX_9, -0.019, -0.021)                 1  0.111111      9\n",
      "30        (4BPX_9, 0.0, 0.0)                 0  0.000000     59\n",
      "31    (4C1X, -0.015, -0.036)                 6  0.032258    186\n",
      "32          (4C1X, 0.0, 0.0)                29  0.031385    924\n",
      "33     (4C1X, 0.014, -0.058)                51  0.054839    930\n",
      "34      (4C1X, 0.014, 0.007)                 2  0.031746     63\n",
      "35          (4CPM, 0.0, 0.0)                 0  0.000000     53\n",
      "36    (4CPX, -0.015, -0.036)                 8  1.000000      8\n",
      "37    (4E1X, -0.019, -0.021)                57  0.045600   1250\n",
      "38    (4E1X, -0.015, -0.036)                58  0.075325    770\n",
      "39          (4E1X, 0.0, 0.0)                 3  0.021583    139\n",
      "40     (4E1X, 0.012, -0.022)                 2  0.016000    125\n",
      "41     (4E1X, 0.014, -0.058)                10  0.048309    207\n",
      "42      (4E1X, 0.014, 0.007)                 4  0.045977     87\n",
      "43      (4E1X, 0.037, 0.005)                 6  0.050847    118\n",
      "44          (4EPM, 0.0, 0.0)                 6  0.130435     46\n",
      "45    (4F1X, -0.019, -0.021)                16  0.041026    390\n",
      "46          (4F1X, 0.0, 0.0)                36  0.063158    570\n"
     ]
    }
   ],
   "source": [
    "summary_df = summarize_grouped_data(train_data, ['workorder_receip',\n",
    "                                                 'THICKNESS 1 Collect Result_Dam'\n",
    "                                                 , 'THICKNESS 2 Collect Result_Dam'\n",
    "                                                 ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
