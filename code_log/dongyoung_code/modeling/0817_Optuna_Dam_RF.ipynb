{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a6bbc",
   "metadata": {},
   "source": [
    "기본 전처리 할것들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e1367da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Workorder_AutoClave' 열에서 '-' 다음 숫자 값 추출 및 '000' 제거\n",
    "train_data['Workorder'] = train_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)\n",
    "test_data['Workorder'] = test_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "735040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispenser_num 값에 따라 새로운 변수 생성\n",
    "train_data['Dispenser_1'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "train_data['Dispenser_2'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "test_data['Dispenser_1'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "test_data['Dispenser_2'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['Dispenser_num'], axis=1, inplace=True)\n",
    "test_data.drop(['Dispenser_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "262866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6e2e5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "38ab6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_receip_no_collect_result(df):\n",
    "    df['Receip_No_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Receip No Collect Result_Dam'] \n",
    "                    if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_receip_no_collect_result(train_data)\n",
    "create_receip_no_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d60cd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Receip No Collect Result_Dam',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "66f9a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['PalletID_Collect_Result'] = df.apply(\n",
    "        lambda row: row['PalletID Collect Result_Dam'] \n",
    "                    if (row['PalletID Collect Result_Dam'] == row['PalletID Collect Result_Fill1'] == row['PalletID Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f4f7c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e14c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['Production_Qty_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Production Qty Collect Result_Dam'] \n",
    "                    if (row['Production Qty Collect Result_Dam'] == row['Production Qty Collect Result_Fill1'] == row['Production Qty Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b8fdec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a22797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Chamber Temp. Judge Value_AutoClave\" 변수의 값을 기준으로 파생 변수 생성 함수\n",
    "def create_judge_value_binary(df):\n",
    "    df['Chamber_Temp_OKNG_AutoClave'] = df['Chamber Temp. Judge Value_AutoClave'].apply(\n",
    "        lambda x: 1 if x == 'OK' else 0\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_binary(train_data)\n",
    "create_judge_value_binary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dd9ccf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Judge Value 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "Chamber Temp. Judge Value_AutoClave\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'Judge Value'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Judge Value').columns\n",
    "\n",
    "print(\"\\n Judge Value 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "efa52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 변수 목록\n",
    "judge_value_columns = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_judge_value_feature(df):\n",
    "    df['Judge_Value_OK'] = df[judge_value_columns].apply(\n",
    "        lambda row: 1 if any(row == 'OK') else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_feature(train_data)\n",
    "create_judge_value_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ebe087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Chamber Temp. Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4fb1e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 변경\n",
    "train_data = train_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})\n",
    "test_data = test_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6cdd01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 108 entries, Model.Suffix to Judge_Value_OK\n",
      "dtypes: float64(56), int64(49), object(3)\n",
      "memory usage: 33.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c4b1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 109 entries, Set ID to Judge_Value_OK\n",
      "dtypes: float64(86), int64(20), object(3)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d3595",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54df9c3",
   "metadata": {},
   "source": [
    "반복적으로 쓰는 툴 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "09d2efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, col_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 열 이름에 대해 박스 플롯을 그리는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.boxplot(df[col_name], vert=False)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.title(f'Box Plot of {col_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7515da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_ratio(df, col_name, target_name='target'):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 비율과 갯수, 총 갯수를 출력하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 데이터프레임\n",
    "    col_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    \"\"\"\n",
    "    # 각 값마다 타겟 변수의 비율 계산\n",
    "    value_counts = df.groupby(col_name)[target_name].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 타겟 변수의 갯수 계산\n",
    "    counts = df.groupby(col_name)[target_name].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 총 갯수 계산\n",
    "    total_counts = df[col_name].value_counts().rename('Total_Count')\n",
    "    \n",
    "    # 비율과 갯수를 합침\n",
    "    result = value_counts.join(counts, lsuffix='_ratio', rsuffix='_count')\n",
    "    \n",
    "    # 총 갯수를 합침\n",
    "    result = result.join(total_counts, on=col_name)\n",
    "    \n",
    "    # 출력 형식 조정\n",
    "    result.index.name = 'variable'\n",
    "    print(f\"\\n{col_name}별 {target_name} 비율 및 갯수\\n\")\n",
    "    print(result.rename(columns=lambda x: x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9eed238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_group(df, group_by_columns):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_columns)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AdNormal' 비율과 갯수 계산\n",
    "        adnormal_count = group['target'].value_counts().get('AbNormal', 0)\n",
    "        adnormal_ratio = adnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, adnormal_count, adnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', \"'AdNormal' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그룹화된 변수들의 이름을 제목행으로 출력\n",
    "    print(f\"Grouped by: {', '.join(group_by_columns)}\")\n",
    "    print()\n",
    "    # 데이터프레임 출력\n",
    "    print(results_df)\n",
    "\n",
    "# 예시코드\n",
    "# summarize_grouped_data(train_data, ['1st Pressure Collect Result_AutoClave', '1st Pressure Unit Time_AutoClave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f4bfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio(df, group_by_column, target_column='target', abnormal_value='AbNormal'):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_column)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AbNormal' 비율과 갯수 계산\n",
    "        abnormal_count = group[target_column].value_counts().get(abnormal_value, 0)\n",
    "        abnormal_ratio = abnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, abnormal_count, abnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', f\"'{abnormal_value}' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # 막대 그래프 생성\n",
    "    ax = results_df.plot(kind='bar', x='group', y='ratio', legend=False)\n",
    "    \n",
    "    # 각 막대 위에 AbNormal 갯수와 총 갯수 표시\n",
    "    for i, (abnormal_count, total) in enumerate(zip(results_df[f\"'{abnormal_value}' count\"], results_df['Total'])):\n",
    "        ax.text(i, results_df['ratio'][i], f'{abnormal_count} ({total})', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "     # 그래프 제목 및 축 레이블 설정\n",
    "    ax.set_title(f'{abnormal_value} Ratio by {group_by_column}')\n",
    "    ax.set_xlabel(group_by_column)\n",
    "    ax.set_ylabel(f'{abnormal_value} Ratio')\n",
    "   \n",
    "    # 그래프 출력\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aad45361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_ratio_boxplot(data, time_ratio_column, target_column='target'):\n",
    "    # 그래프 스타일 설정\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=time_ratio_column, y=target_column, data=data)\n",
    "\n",
    "    # 그래프 제목 및 레이블 설정\n",
    "    plt.title(f'{time_ratio_column} vs {target_column}')\n",
    "    plt.xlabel(time_ratio_column)\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    # 그래프 출력\n",
    "    plt.show()\n",
    "\n",
    "# 함수 호출 예제\n",
    "#plot_time_ratio_vs_target(train_data, 'time_ratio_Dam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8a90c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0e84bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model.Suffix',\n",
       " 'Workorder',\n",
       " 'CURE END POSITION X Collect Result_Dam',\n",
       " 'CURE END POSITION Z Collect Result_Dam',\n",
       " 'CURE END POSITION Θ Collect Result_Dam',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'CURE START POSITION X Collect Result_Dam',\n",
       " 'CURE START POSITION Θ Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage1) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage2) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Head Zero Position Z Collect Result_Dam',\n",
       " 'Machine Tact time Collect Result_Dam',\n",
       " 'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
       " 'THICKNESS 1 Collect Result_Dam',\n",
       " 'THICKNESS 2 Collect Result_Dam',\n",
       " 'THICKNESS 3 Collect Result_Dam',\n",
       " 'WorkMode Collect Result',\n",
       " '1st Pressure Collect Result_AutoClave',\n",
       " '1st Pressure Unit Time_AutoClave',\n",
       " '2nd Pressure Collect Result_AutoClave',\n",
       " '2nd Pressure Unit Time_AutoClave',\n",
       " '3rd Pressure Collect Result_AutoClave',\n",
       " '3rd Pressure Unit Time_AutoClave',\n",
       " 'Chamber Temp. Collect Result_AutoClave',\n",
       " 'Chamber Temp. Unit Time_AutoClave',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage1) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage2) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
       " 'Head Purge Position Z Collect Result_Fill1',\n",
       " 'Machine Tact time Collect Result_Fill1',\n",
       " 'CURE END POSITION X Collect Result_Fill2',\n",
       " 'CURE END POSITION Z Collect Result_Fill2',\n",
       " 'CURE SPEED Collect Result_Fill2',\n",
       " 'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
       " 'CURE START POSITION X Collect Result_Fill2',\n",
       " 'CURE START POSITION Z Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2',\n",
       " 'Head Purge Position Z Collect Result_Fill2',\n",
       " 'Machine Tact time Collect Result_Fill2',\n",
       " 'target',\n",
       " 'Dispenser_1',\n",
       " 'Dispenser_2',\n",
       " 'Receip_No_Collect_Result',\n",
       " 'PalletID_Collect_Result',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'Chamber_Temp_OKNG_AutoClave',\n",
       " 'Judge_Value_OK']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9465e",
   "metadata": {},
   "source": [
    "### 1. CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45bdcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'와 '_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33dc2f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION Θ Collect Result_Dam, CURE START POSITION Θ Collect Result_Dam\n",
      "\n",
      "              group  'AdNormal' count     ratio  Total\n",
      "0  (0, 0, -90, -90)                19  1.000000     19\n",
      "1    (0, 0, 90, 90)                15  1.000000     15\n",
      "2    (0, 1, 90, 90)               850  0.054977  15461\n",
      "3  (1, 0, -90, -90)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE START POSITION X Collect Result_Dam'\n",
    ", 'CURE START POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aff796",
   "metadata": {},
   "source": [
    "dispenser 종류에 따라 POSITION Θ 값이 따라감  \n",
    "-> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a2bcdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION Θ Collect Result_Dam'\n",
    "    , 'CURE START POSITION Θ Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b7aff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61cf9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION X Collect Result_Dam, CURE END POSITION Z Collect Result_Dam, CURE START POSITION X Collect Result_Dam\n",
      "\n",
      "                     group  'AdNormal' count     ratio  Total\n",
      "0   (0, 0, 240, 2.5, 1030)                19  1.000000     19\n",
      "1  (0, 0, 1000, 12.5, 280)                15  1.000000     15\n",
      "2  (0, 1, 1000, 12.5, 280)               850  0.054977  15461\n",
      "3   (1, 0, 240, 2.5, 1030)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    ", 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Z Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    ", 'CURE START POSITION X Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d641dc",
   "metadata": {},
   "source": [
    "좌표값을 통해 좌표간의 거리를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "96d3ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Dam'\n",
    "start_z_col = 33.5\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Dam'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a5fa846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Fill2'\n",
    "start_z_col = 'CURE START POSITION Z Collect Result_Fill2'\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Fill2'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Fill2'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fbe2fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE START POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "    , 'CURE START POSITION X Collect Result_Fill2'\n",
    "    , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "    , 'CURE END POSITION X Collect Result_Fill2'\n",
    "    , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2b9efd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "46e713c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "\n",
      "   group  'AdNormal' count     ratio  Total\n",
      "0  (22,)                34  0.072495    469\n",
      "1  (23,)                22  0.107843    204\n",
      "2  (32,)               421  0.085866   4903\n",
      "3  (33,)              1873  0.053622  34930\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    " 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE_DISTANCE_Dam'\n",
    "# , 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b3d80",
   "metadata": {},
   "source": [
    "'CURE STANDBY POSITION Z Collect Result_Fill2' 변수의 유의미함을 찾을수 x  \n",
    "다른 변수와 연결된만한것도 찾지 못함 -> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dc313406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = ['CURE STANDBY POSITION Z Collect Result_Fill2']\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "50fe7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "18af7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE_DISTANCE_Dam, CURE_DISTANCE_Fill2\n",
      "\n",
      "                                          group  'AdNormal' count     ratio  \\\n",
      "0              (0, 0, 720.3061848963953, 780.0)                15  1.000000   \n",
      "1               (0, 0, 790.607993888248, 780.0)                19  1.000000   \n",
      "2              (0, 1, 720.3061848963953, 780.0)               827  0.054645   \n",
      "3  (0, 1, 720.3061848963953, 780.0006410253776)                23  0.070552   \n",
      "4  (0, 1, 720.3061848963953, 780.0775602464155)                 0  0.000000   \n",
      "5               (1, 0, 790.607993888248, 780.0)              1129  0.054418   \n",
      "6   (1, 0, 790.607993888248, 780.0006410253776)               286  0.077591   \n",
      "7   (1, 0, 790.607993888248, 780.0640999302557)                51  0.088235   \n",
      "\n",
      "   Total  \n",
      "0     15  \n",
      "1     19  \n",
      "2  15134  \n",
      "3    326  \n",
      "4      1  \n",
      "5  20747  \n",
      "6   3686  \n",
      "7    578  \n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    ", 'CURE_DISTANCE_Dam'\n",
    ", 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dbf40",
   "metadata": {},
   "source": [
    "거리의 차이에 따라 ratio 값 변화 크지 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c26ff29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 / 속도 -> 시간 파생 변수 생성\n",
    "train_data['CURE_Time_Dam']  = train_data['CURE_DISTANCE_Dam'] / train_data['CURE SPEED Collect Result_Dam']\n",
    "test_data['CURE_Time_Dam']  = test_data['CURE_DISTANCE_Dam'] / test_data['CURE SPEED Collect Result_Dam']\n",
    "\n",
    "train_data['CURE_Time_Fill2']  = train_data['CURE_DISTANCE_Fill2'] / train_data['CURE SPEED Collect Result_Fill2']\n",
    "test_data['CURE_Time_Fill2']  = test_data['CURE_DISTANCE_Fill2'] / test_data['CURE SPEED Collect Result_Fill2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "48b4c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4195b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE_DISTANCE_Dam'\n",
    "    , 'CURE SPEED Collect Result_Dam'\n",
    "    , 'CURE_DISTANCE_Fill2'\n",
    "    , 'CURE SPEED Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2d0840f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caac149",
   "metadata": {},
   "source": [
    "### 2. HEAD NORMAL COORDINATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "39a38fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL COORDINATE 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL COORDINATE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL COORDINATE').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL COORDINATE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "acc3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "287f0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    # data['HEAD NORMAL DISTANCE_TRIANGLE_area_Dam'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Dam'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "efb87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dd662cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9fb0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    # data['HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0df37c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ac6abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4c4cf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9688a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "47c86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0fa789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a2e0",
   "metadata": {},
   "source": [
    "### 3. RESIN(처리x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "91c64cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'RESIN' 또는 'Dispense Volume' 포함 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4652063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispense Volume(Stage1) Collect Result_Dam, Dispense Volume(Stage2) Collect Result_Dam, Dispense Volume(Stage3) Collect Result_Dam\n",
      "\n",
      "                  group  'AdNormal' count     ratio  Total\n",
      "0    (0.67, 0.26, 1.49)                 8  0.075472    106\n",
      "1    (0.67, 0.27, 1.49)               277  0.086293   3210\n",
      "2    (0.67, 0.28, 1.49)                 0  0.000000      2\n",
      "3    (0.67, 0.33, 1.49)                51  0.099415    513\n",
      "4    (0.67, 0.34, 1.49)               467  0.082276   5676\n",
      "..                  ...               ...       ...    ...\n",
      "155  (1.63, 0.92, 1.49)                41  0.048810    840\n",
      "156  (1.63, 0.93, 1.49)                46  0.080844    569\n",
      "157  (1.63, 0.94, 1.49)                34  0.068273    498\n",
      "158  (2.34, 0.71, 1.49)                 0  0.000000      1\n",
      "159  (2.34, 0.72, 1.49)                 0  0.000000      3\n",
      "\n",
      "[160 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    " 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b1d5d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_time_speed_product(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         speed_col = 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Time_x_Speed_{stage}_Dam'\n",
    "#         df[new_col_name] = df[time_col] * df[speed_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_time_speed_product(train_data)\n",
    "# create_time_speed_product(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0ebb3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dd57994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_volume_time_ratio(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         volume_col = f'Dispense Volume({stage}) Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Volume_Time_Ratio_{stage}_Dam'\n",
    "#         df[new_col_name] = df[volume_col] / df[time_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_volume_time_ratio(train_data)\n",
    "# create_volume_time_ratio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b42b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 출력 옵션을 설정\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# # 출력 옵션을 원래대로\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9df4ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# # , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "# # , 'RESIN Time_x_Speed_Stage1_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage2_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage3_Dam'\n",
    "# #  'RESIN Volume_Time_Ratio_Stage1_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage2_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage3_Dam'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f6643f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "# Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "# print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "# for col in Process_Desc_col:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac6aad",
   "metadata": {},
   "source": [
    "### 4. Distance Speed Collect Result_Dam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6a2ba",
   "metadata": {},
   "source": [
    "Dam 공정의 Circle, Line 길이 변수들 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8f1ca6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance Speed Collect Result_Dam 포함 변수>\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance Speed Collect Result_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance Speed Collect Result_Dam').columns\n",
    "\n",
    "print(\"\\n Distance Speed Collect Result_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ac6dc",
   "metadata": {},
   "source": [
    "Stage 별 Speed 값들의 평균 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "74dc87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stage_totals(data, stages, suffix='_Distance_Speed_avg_Dam'):\n",
    "    for stage in stages:\n",
    "        stage_cols = data.filter(like=stage).columns\n",
    "        data[f'{stage}{suffix}'] = data[stage_cols].sum(axis=1) / 8\n",
    "\n",
    "stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "\n",
    "# train_data에 대해 파생변수 추가\n",
    "add_stage_totals(train_data, stages)\n",
    "\n",
    "# test_data에 대해 파생변수 추가\n",
    "add_stage_totals(test_data, stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a453df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Stage1 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2d2c9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance_Speed_avg_Dam 포함 변수>\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance_Speed_avg_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance_Speed_avg_Dam').columns\n",
    "\n",
    "print(\"\\n Distance_Speed_avg_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a4274",
   "metadata": {},
   "source": [
    "### 5. THICKNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d1907522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "THICKNESS 1 Collect Result_Dam\n",
      "THICKNESS 2 Collect Result_Dam\n",
      "THICKNESS 3 Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c3ae04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 파생변수 생성 함수\n",
    "def create_total_thickness_dam(data):\n",
    "    data['THICKNESS_total_Dam'] = (\n",
    "        data['THICKNESS 1 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 2 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 3 Collect Result_Dam']**2\n",
    "    )\n",
    "    # 기존 변수 삭제\n",
    "    data.drop(columns=[\n",
    "        'THICKNESS 1 Collect Result_Dam',\n",
    "        'THICKNESS 2 Collect Result_Dam',\n",
    "        'THICKNESS 3 Collect Result_Dam'\n",
    "    ], inplace=True)\n",
    "    return data\n",
    "\n",
    "train_data = create_total_thickness_dam(train_data)\n",
    "test_data = create_total_thickness_dam(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "af96f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "THICKNESS_total_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4349a",
   "metadata": {},
   "source": [
    "### 6. AutoClave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "27ac3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b3c024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성\n",
    "train_data['1st_Pressure_x_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure Unit Time_AutoClave'] \n",
    "test_data['1st_Pressure_x_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['2nd_Pressure_x_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave'] \n",
    "test_data['2nd_Pressure_x_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['3rd_Pressure_x_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave'] \n",
    "test_data['3rd_Pressure_x_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['All_Pressure_x_AutoClave'] = train_data['1st_Pressure_x_AutoClave'] + train_data['2nd_Pressure_x_AutoClave'] + train_data['3rd_Pressure_x_AutoClave']\n",
    "test_data['All_Pressure_x_AutoClave'] = test_data['1st_Pressure_x_AutoClave'] + test_data['2nd_Pressure_x_AutoClave'] + test_data['3rd_Pressure_x_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_avg_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['All_Pressure_avg_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['Chamber_Temp_x_AutoClave'] = train_data['Chamber Temp. Collect Result_AutoClave'] * train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['Chamber_Temp_x_AutoClave'] = test_data['Chamber Temp. Collect Result_AutoClave'] * test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber_Temp_x_AutoClave']\n",
    "test_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber_Temp_x_AutoClave']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a69ad859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3e714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "# '1st Pressure Collect Result_AutoClave'\n",
    "'1st Pressure Unit Time_AutoClave'\n",
    "# , '2nd Pressure Collect Result_AutoClave'\n",
    ", '2nd Pressure Unit Time_AutoClave'\n",
    "# , '3rd Pressure Collect Result_AutoClave'\n",
    ", '3rd Pressure Unit Time_AutoClave'\n",
    "# , 'Chamber Temp. Collect Result_AutoClave'\n",
    "# , 'Chamber Temp. Unit Time_AutoClave'\n",
    "\n",
    "# , '1st_Pressure_x_AutoClave'\n",
    "# , '2nd_Pressure_x_AutoClave'\n",
    "# , '3rd_Pressure_x_AutoClave'\n",
    ", 'All_Pressure_x_AutoClave'\n",
    "# , 'All_Pressure_avg_AutoClave'\n",
    "# , 'Chamber_Temp_x_AutoClave'\n",
    "# , 'All_Pressure_frac_Chamber_Temp_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "20ce50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69dcf",
   "metadata": {},
   "source": [
    "### 7. ETC.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b05ca",
   "metadata": {},
   "source": [
    "7-1. workorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e2e4240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수를 0과 1로 변환\n",
    "train_data['target_binary'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# Workorder 변수의 값에 대한 타겟 변수 비율 계산\n",
    "workorder_target_ratio = train_data.groupby('Workorder')['target_binary'].mean()\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_derived_variable(row, ratio_dict, threshold):\n",
    "    return 1 if ratio_dict.get(row['Workorder'], 0) >= threshold else 0\n",
    "\n",
    "# 파생 변수 생성\n",
    "train_data['Workorder_0.9'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "train_data['Workorder_0.6'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.6)\n",
    "\n",
    "test_data['Workorder_0.9'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "test_data['Workorder_0.6'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.6)\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['target_binary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48c3f8",
   "metadata": {},
   "source": [
    "7-2. Machine Tact time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4d866fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 총시간 대비 비율 변수\n",
    "def calculate_total_time_and_ratios(data):\n",
    "    data['total_time'] = (\n",
    "        data['Machine Tact time Collect Result_Dam'] +\n",
    "        data['Machine Tact time Collect Result_Fill1'] +\n",
    "        data['Machine Tact time Collect Result_Fill2'] +\n",
    "        data['Chamber Temp. Unit Time_AutoClave']\n",
    "    )\n",
    "    data['time_ratio_Dam'] = (data['Machine Tact time Collect Result_Dam'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill1'] = (data['Machine Tact time Collect Result_Fill1'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill2'] = (data['Machine Tact time Collect Result_Fill2'] / data['total_time']).round(3)\n",
    "    data['time_ratio_AutoClave'] = (data['Chamber Temp. Unit Time_AutoClave'] / data['total_time']).round(3)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 함수 적용\n",
    "train_data = calculate_total_time_and_ratios(train_data)\n",
    "test_data = calculate_total_time_and_ratios(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dec2a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 제거\n",
    "train_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)\n",
    "\n",
    "test_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "49a7d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  object \n",
      " 1   Workorder                                              40506 non-null  object \n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 44  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 45  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 46  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  THICKNESS_total_Dam                                    40506 non-null  float64\n",
      " 48  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 49  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 50  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 52  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 53  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 54  Workorder_0.9                                          40506 non-null  int64  \n",
      " 55  Workorder_0.6                                          40506 non-null  int64  \n",
      " 56  time_ratio_Dam                                         40506 non-null  float64\n",
      " 57  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 58  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 59  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(44), int64(13), object(3)\n",
      "memory usage: 18.5+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "769e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b20a3",
   "metadata": {},
   "source": [
    "## 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fb37ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model.Suffix', 'Workorder', 'target'], dtype='object')  train_object_columns 갯수 : 3\n",
      "Index(['Set ID', 'Model.Suffix', 'Workorder', 'target'], dtype='object')  test_object_columns 갯수 : 4\n",
      "\n",
      "Train Data:\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 663\n",
      "target unique 값 갯수: 2\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 662\n",
      "target unique 값 갯수: 0\n"
     ]
    }
   ],
   "source": [
    "# 'target' 열의 변수 타입을 object로 변경\n",
    "# -> test 데이터는 float64 타입으로 되어있음 \n",
    "test_data['target'] = test_data['target'].astype('object')\n",
    "\n",
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "156c68be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model.Suffix  Workorder\n",
      "0      0.049336   0.158385\n",
      "1      0.049336   0.015314\n",
      "2      0.056712   0.009534\n",
      "   Model.Suffix  Workorder\n",
      "0      0.056712   0.091912\n",
      "1      0.056712   0.024247\n",
      "2      0.056712   0.091463\n",
      "--- train_data ---\n",
      "target  \n",
      "Normal      38156\n",
      "AbNormal     2350\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# 타겟 변수와 범주형 변수 지정\n",
    "## Target Encoding의 smoothing 파라미터는 default로 auto로 설정되어 있음\n",
    "target = 'target'  # 타겟 변수 이름으로 변경\n",
    "categorical_columns = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "]  # 범주형 변수 이름으로 변경\n",
    "\n",
    "# 타겟 값을 숫자로 변환\n",
    "target_mapping = {'Normal': 0, 'AbNormal': 1}\n",
    "train_data[target] = train_data[target].map(target_mapping)\n",
    "test_data[target] = test_data[target].map(target_mapping)\n",
    "\n",
    "# 열이 존재하는지 확인\n",
    "missing_columns = [col for col in categorical_columns if col not in train_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"train_data에 다음 열이 존재하지 않습니다: {missing_columns}\")\n",
    "\n",
    "# 타겟 인코더 생성 및 학습\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "train_data = encoder.fit_transform(train_data, train_data[target])\n",
    "\n",
    "# Set ID 열을 별도로 저장\n",
    "set_id = test_data['Set ID']\n",
    "\n",
    "# 테스트 데이터 인코딩 (Set ID 열 제외)\n",
    "test_data = test_data.drop(columns=['Set ID'])\n",
    "test_data = encoder.transform(test_data)\n",
    "\n",
    "# Set ID 열을 맨 앞에 추가\n",
    "test_data.insert(0, 'Set ID', set_id)\n",
    "\n",
    "# categorical_columns에 해당하는 열의 데이터 값만 확인\n",
    "print(train_data[categorical_columns].head(3))\n",
    "print(test_data[categorical_columns].head(3))\n",
    "\n",
    "# 역 매핑 딕셔너리 생성\n",
    "reverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "# 타겟 값을 원래대로 변환\n",
    "train_data[target] = train_data[target].map(reverse_target_mapping)\n",
    "test_data[target] = test_data[target].map(reverse_target_mapping)\n",
    "\n",
    "print(\"--- train_data ---\")\n",
    "\n",
    "# 변환된 타겟 값 확인\n",
    "print(train_data[[target]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6a108490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 44  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 45  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 46  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  THICKNESS_total_Dam                                    40506 non-null  float64\n",
      " 48  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 49  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 50  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 52  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 53  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 54  Workorder_0.9                                          40506 non-null  int64  \n",
      " 55  Workorder_0.6                                          40506 non-null  int64  \n",
      " 56  time_ratio_Dam                                         40506 non-null  float64\n",
      " 57  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 58  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 59  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(46), int64(13), object(1)\n",
      "memory usage: 18.5+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "dbf7c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Set ID                                                 17361 non-null  object \n",
      " 1   Model.Suffix                                           17361 non-null  float64\n",
      " 2   Workorder                                              17361 non-null  float64\n",
      " 3   DISCHARGED SPEED OF RESIN Collect Result_Dam           17361 non-null  int64  \n",
      " 4   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    17361 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    17361 non-null  float64\n",
      " 6   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    17361 non-null  float64\n",
      " 7   Dispense Volume(Stage1) Collect Result_Dam             17361 non-null  float64\n",
      " 8   Dispense Volume(Stage2) Collect Result_Dam             17361 non-null  float64\n",
      " 9   Dispense Volume(Stage3) Collect Result_Dam             17361 non-null  float64\n",
      " 10  Head Clean Position Z Collect Result_Dam               17361 non-null  float64\n",
      " 11  Head Purge Position Z Collect Result_Dam               17361 non-null  float64\n",
      " 12  Head Zero Position Y Collect Result_Dam                17361 non-null  float64\n",
      " 13  Head Zero Position Z Collect Result_Dam                17361 non-null  float64\n",
      " 14  WorkMode Collect Result                                17361 non-null  float64\n",
      " 15  1st Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 16  2nd Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 17  3rd Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 18  Chamber Temp. Collect Result_AutoClave                 17361 non-null  int64  \n",
      " 19  DISCHARGED SPEED OF RESIN Collect Result_Fill1         17361 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  17361 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  17361 non-null  float64\n",
      " 22  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  17361 non-null  float64\n",
      " 23  Dispense Volume(Stage1) Collect Result_Fill1           17361 non-null  float64\n",
      " 24  Dispense Volume(Stage2) Collect Result_Fill1           17361 non-null  float64\n",
      " 25  Dispense Volume(Stage3) Collect Result_Fill1           17361 non-null  float64\n",
      " 26  Head Purge Position Z Collect Result_Fill1             17361 non-null  float64\n",
      " 27  Head Purge Position Z Collect Result_Fill2             17361 non-null  float64\n",
      " 28  target                                                 0 non-null      object \n",
      " 29  Dispenser_1                                            17361 non-null  int64  \n",
      " 30  Dispenser_2                                            17361 non-null  int64  \n",
      " 31  Receip_No_Collect_Result                               17361 non-null  float64\n",
      " 32  PalletID_Collect_Result                                17361 non-null  float64\n",
      " 33  Production_Qty_Collect_Result                          17361 non-null  float64\n",
      " 34  Chamber_Temp_OKNG_AutoClave                            17361 non-null  int64  \n",
      " 35  Judge_Value_OK                                         17361 non-null  int64  \n",
      " 36  CURE_Time_Dam                                          17361 non-null  float64\n",
      " 37  CURE_Time_Fill2                                        17361 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 17361 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               17361 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               17361 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             17361 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               17361 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               17361 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               17361 non-null  float64\n",
      " 45  Stage1_Distance_Speed_avg_Dam                          17361 non-null  float64\n",
      " 46  Stage2_Distance_Speed_avg_Dam                          17361 non-null  float64\n",
      " 47  Stage3_Distance_Speed_avg_Dam                          17361 non-null  float64\n",
      " 48  THICKNESS_total_Dam                                    17361 non-null  float64\n",
      " 49  1st_Pressure_x_AutoClave                               17361 non-null  float64\n",
      " 50  2nd_Pressure_x_AutoClave                               17361 non-null  float64\n",
      " 51  3rd_Pressure_x_AutoClave                               17361 non-null  float64\n",
      " 52  All_Pressure_avg_AutoClave                             17361 non-null  float64\n",
      " 53  Chamber_Temp_x_AutoClave                               17361 non-null  int64  \n",
      " 54  All_Pressure_frac_Chamber_Temp_AutoClave               17361 non-null  float64\n",
      " 55  Workorder_0.9                                          17361 non-null  int64  \n",
      " 56  Workorder_0.6                                          17361 non-null  int64  \n",
      " 57  time_ratio_Dam                                         17361 non-null  float64\n",
      " 58  time_ratio_Fill1                                       17361 non-null  float64\n",
      " 59  time_ratio_Fill2                                       17361 non-null  float64\n",
      " 60  time_ratio_AutoClave                                   17361 non-null  float64\n",
      "dtypes: float64(50), int64(9), object(2)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# train_data.info()\n",
    "print('---')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276e6df",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "314cbecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "def print_stats(df: pd.DataFrame):\n",
    "    num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "    num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "    print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  \\tAbnormal\\tNormal\")\n",
    "print_stats(df_train)\n",
    "print_stats(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1771a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 44  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 45  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 46  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  THICKNESS_total_Dam                                    40506 non-null  float64\n",
      " 48  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 49  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 50  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 52  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 53  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 54  Workorder_0.9                                          40506 non-null  int64  \n",
      " 55  Workorder_0.6                                          40506 non-null  int64  \n",
      " 56  time_ratio_Dam                                         40506 non-null  float64\n",
      " 57  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 58  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 59  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(46), int64(13), object(1)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644f718d",
   "metadata": {},
   "source": [
    "### 상관계수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef448d9",
   "metadata": {},
   "source": [
    "상관계수 0.7 이상 drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519265e7",
   "metadata": {},
   "source": [
    "공통 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "67dbaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_variables = [\n",
    "    'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    , 'Workorder_0.6'\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[com_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "99dbb2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.049336\n",
       "1        0.049336\n",
       "2        0.056712\n",
       "3        0.056712\n",
       "4        0.056712\n",
       "           ...   \n",
       "40501    0.056712\n",
       "40502    0.056712\n",
       "40503    0.056712\n",
       "40504    0.056712\n",
       "40505    0.056712\n",
       "Name: Model.Suffix, Length: 40506, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['Model.Suffix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "cf966448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Variable 1               Variable 2  Correlation\n",
      "0              Dispenser_2  PalletID_Collect_Result     0.860274\n",
      "1  PalletID_Collect_Result              Dispenser_2     0.860274\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "105fe344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 삭제\n",
    "train_data.drop(['PalletID_Collect_Result'], axis=1, inplace=True)\n",
    "test_data.drop(['PalletID_Collect_Result'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "807ffaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 변수 리스트\n",
    "com_variables_train = [\n",
    "    'target'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    , 'Workorder_0.6'\n",
    "]\n",
    "\n",
    "com_variables_test = [\n",
    "    'target'\n",
    "    , 'Set ID'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    , 'Workorder_0.6'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955d978",
   "metadata": {},
   "source": [
    "Dam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3b5911a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dam 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "Head Clean Position Z Collect Result_Dam\n",
      "Head Purge Position Z Collect Result_Dam\n",
      "Head Zero Position Y Collect Result_Dam\n",
      "Head Zero Position Z Collect Result_Dam\n",
      "CURE_Time_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n",
      "THICKNESS_total_Dam\n",
      "time_ratio_Dam\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Dam 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5d01ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Dam\",\n",
    "    \"Head Clean Position Z Collect Result_Dam\",\n",
    "    \"Head Purge Position Z Collect Result_Dam\",\n",
    "    \"Head Zero Position Y Collect Result_Dam\",\n",
    "    \"Head Zero Position Z Collect Result_Dam\",\n",
    "    \"CURE_Time_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\",\n",
    "    \"Stage1_Distance_Speed_avg_Dam\",\n",
    "    \"Stage2_Distance_Speed_avg_Dam\",\n",
    "    \"Stage3_Distance_Speed_avg_Dam\",\n",
    "    \"THICKNESS_total_Dam\",\n",
    "    \"time_ratio_Dam\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "96b98835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Variable 1  \\\n",
      "0        DISCHARGED SPEED OF RESIN Collect Result_Dam   \n",
      "1   DISCHARGED TIME OF RESIN(Stage1) Collect Resul...   \n",
      "2   DISCHARGED TIME OF RESIN(Stage1) Collect Resul...   \n",
      "3   DISCHARGED TIME OF RESIN(Stage2) Collect Resul...   \n",
      "4   DISCHARGED TIME OF RESIN(Stage3) Collect Resul...   \n",
      "5   DISCHARGED TIME OF RESIN(Stage3) Collect Resul...   \n",
      "6          Dispense Volume(Stage1) Collect Result_Dam   \n",
      "7          Dispense Volume(Stage1) Collect Result_Dam   \n",
      "8          Dispense Volume(Stage1) Collect Result_Dam   \n",
      "9          Dispense Volume(Stage2) Collect Result_Dam   \n",
      "10         Dispense Volume(Stage2) Collect Result_Dam   \n",
      "11           Head Clean Position Z Collect Result_Dam   \n",
      "12            Head Zero Position Z Collect Result_Dam   \n",
      "13                                      CURE_Time_Dam   \n",
      "14                      Stage1_Distance_Speed_avg_Dam   \n",
      "15                      Stage3_Distance_Speed_avg_Dam   \n",
      "\n",
      "                                           Variable 2  Correlation  \n",
      "0             Head Zero Position Z Collect Result_Dam     0.808023  \n",
      "1   DISCHARGED TIME OF RESIN(Stage3) Collect Resul...     0.999476  \n",
      "2          Dispense Volume(Stage1) Collect Result_Dam     0.788676  \n",
      "3          Dispense Volume(Stage2) Collect Result_Dam     0.823917  \n",
      "4   DISCHARGED TIME OF RESIN(Stage1) Collect Resul...     0.999476  \n",
      "5          Dispense Volume(Stage1) Collect Result_Dam     0.783575  \n",
      "6   DISCHARGED TIME OF RESIN(Stage1) Collect Resul...     0.788676  \n",
      "7   DISCHARGED TIME OF RESIN(Stage3) Collect Resul...     0.783575  \n",
      "8          Dispense Volume(Stage2) Collect Result_Dam     0.767858  \n",
      "9   DISCHARGED TIME OF RESIN(Stage2) Collect Resul...     0.823917  \n",
      "10         Dispense Volume(Stage1) Collect Result_Dam     0.767858  \n",
      "11                                      CURE_Time_Dam     0.729409  \n",
      "12       DISCHARGED SPEED OF RESIN Collect Result_Dam     0.808023  \n",
      "13           Head Clean Position Z Collect Result_Dam     0.729409  \n",
      "14                      Stage3_Distance_Speed_avg_Dam     0.999898  \n",
      "15                      Stage1_Distance_Speed_avg_Dam     0.999898  \n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "749bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\"\n",
    "    , \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\"\n",
    "    , \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\"\n",
    "    , \"Dispense Volume(Stage1) Collect Result_Dam\"\n",
    "    , \"Head Clean Position Z Collect Result_Dam\"\n",
    "    , \"Head Zero Position Z Collect Result_Dam\"\n",
    "    , \"Stage3_Distance_Speed_avg_Dam\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9bf106",
   "metadata": {},
   "source": [
    "AutoCalve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f80651a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n",
      "time_ratio_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "566073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"1st Pressure Collect Result_AutoClave\"\n",
    "    , \"2nd Pressure Collect Result_AutoClave\"\n",
    "    , \"3rd Pressure Collect Result_AutoClave\"\n",
    "    , \"Chamber Temp. Collect Result_AutoClave\"\n",
    "    , \"Chamber_Temp_OKNG_AutoClave\"\n",
    "    , \"1st_Pressure_x_AutoClave\"\n",
    "    , \"2nd_Pressure_x_AutoClave\"\n",
    "    , \"3rd_Pressure_x_AutoClave\"\n",
    "    , \"All_Pressure_avg_AutoClave\"\n",
    "    , \"Chamber_Temp_x_AutoClave\"\n",
    "    , \"All_Pressure_frac_Chamber_Temp_AutoClave\"\n",
    "    , \"time_ratio_AutoClave\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "290c852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Variable 1  \\\n",
      "0  Chamber Temp. Collect Result_AutoClave   \n",
      "1             Chamber_Temp_OKNG_AutoClave   \n",
      "2                2nd_Pressure_x_AutoClave   \n",
      "3                Chamber_Temp_x_AutoClave   \n",
      "\n",
      "                               Variable 2  Correlation  \n",
      "0             Chamber_Temp_OKNG_AutoClave     0.742841  \n",
      "1  Chamber Temp. Collect Result_AutoClave     0.742841  \n",
      "2                Chamber_Temp_x_AutoClave     0.804096  \n",
      "3                2nd_Pressure_x_AutoClave     0.804096  \n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fff17e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"2nd_Pressure_x_AutoClave\"\n",
    "    , 'Chamber_Temp_OKNG_AutoClave'\n",
    "    , 'Chamber_Temp_x_AutoClave'\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa86a4b",
   "metadata": {},
   "source": [
    "Fill1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a03bc6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n",
      "Head Purge Position Z Collect Result_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "time_ratio_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill1').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3fa145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Fill1\",\n",
    "    \"Head Purge Position Z Collect Result_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\",\n",
    "    \"time_ratio_Fill1\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0e3d6b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Variable 1  \\\n",
      "0  DISCHARGED TIME OF RESIN(Stage1) Collect Resul...   \n",
      "1  DISCHARGED TIME OF RESIN(Stage2) Collect Resul...   \n",
      "2       Dispense Volume(Stage1) Collect Result_Fill1   \n",
      "3       Dispense Volume(Stage1) Collect Result_Fill1   \n",
      "4       Dispense Volume(Stage2) Collect Result_Fill1   \n",
      "5           HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1   \n",
      "\n",
      "                                          Variable 2  Correlation  \n",
      "0       Dispense Volume(Stage1) Collect Result_Fill1     0.834402  \n",
      "1       Dispense Volume(Stage2) Collect Result_Fill1     0.988529  \n",
      "2  DISCHARGED TIME OF RESIN(Stage1) Collect Resul...     0.834402  \n",
      "3           HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1     0.763230  \n",
      "4  DISCHARGED TIME OF RESIN(Stage2) Collect Resul...     0.988529  \n",
      "5       Dispense Volume(Stage1) Collect Result_Fill1     0.763230  \n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5e63aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"Dispense Volume(Stage1) Collect Result_Fill1\"\n",
    "    , \"Dispense Volume(Stage2) Collect Result_Fill1\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04408756",
   "metadata": {},
   "source": [
    "Fill2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "04ce5f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "Head Purge Position Z Collect Result_Fill2\n",
      "CURE_Time_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n",
      "time_ratio_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill2').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "dfb13c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"Head Purge Position Z Collect Result_Fill2\"\n",
    "    , \"CURE_Time_Fill2\"\n",
    "    , \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\"\n",
    "    , \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\"\n",
    "    , \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\"\n",
    "    , \"time_ratio_Fill2\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6ec9d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Variable 1  \\\n",
      "0  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2   \n",
      "1  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2   \n",
      "2  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2   \n",
      "3  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2   \n",
      "4  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2   \n",
      "5  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2   \n",
      "\n",
      "                                 Variable 2  Correlation  \n",
      "0  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2     0.999993  \n",
      "1  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2     0.999999  \n",
      "2  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2     0.999993  \n",
      "3  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2     0.999997  \n",
      "4  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2     0.999999  \n",
      "5  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2     0.999997  \n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7c533e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32095b",
   "metadata": {},
   "source": [
    "공정별 변수 + 공통 변수 결합  \n",
    "-> 총 4개의 데이터셋을 구성하고 각 데이터셋 마다 train,test 를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "84f9c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공정 이름 필터링 후 공통 변수와 결합\n",
    "def create_dataset(train_data, test_data, process_name, com_variables_train, com_variables_test):\n",
    "    # 열 이름 필터링\n",
    "    Process_Desc_col = train_data.filter(like=process_name).columns\n",
    "    \n",
    "    # train 데이터셋 생성\n",
    "    final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "    train_dataset = train_data[final_columns_train]\n",
    "    \n",
    "    # test 데이터셋 생성\n",
    "    final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "    test_dataset = test_data[final_columns_test]\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# 공통 변수 정의\n",
    "## com_variables_train = [...]  -> 이전 코드에서 정의한 변수 사용\n",
    "## com_variables_test = [...]   -> 이전 코드에서 정의한 변수 사용\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_data_dam, test_data_dam = create_dataset(train_data, test_data, '_Dam', com_variables_train, com_variables_test)\n",
    "train_data_fill1, test_data_fill1 = create_dataset(train_data, test_data, '_Fill1', com_variables_train, com_variables_test)\n",
    "train_data_fill2, test_data_fill2 = create_dataset(train_data, test_data, '_Fill2', com_variables_train, com_variables_test)\n",
    "train_data_autoclave, test_data_autoclave = create_dataset(train_data, test_data, '_AutoClave', com_variables_train, com_variables_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fb9e8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred_proba, threshold=0.5):\n",
    "    # 확률을 기준으로 예측 레이블 생성\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)  # 0.5 이상의 확률을 양성으로 간주\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba9f29",
   "metadata": {},
   "source": [
    "optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8e065",
   "metadata": {},
   "source": [
    "스레스홀드 0.3이고 300번 돌렸을 때 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8ec04f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimDongyoung\\AppData\\Local\\Temp\\ipykernel_12736\\4190609778.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_dam['target'] = train_data_dam['target'].map({'Normal': 0, 'AbNormal': 1})\n",
      "[I 2024-08-17 12:24:43,465] A new study created in memory with name: no-name-06a0bb07-27e2-4675-8948-fb201fac7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-17 12:25:28,730] Trial 0 finished with value: 0.20518867924528303 and parameters: {'n_estimators': 1116, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.20518867924528303.\n",
      "[I 2024-08-17 12:27:04,701] Trial 1 finished with value: 0.22900763358778628 and parameters: {'n_estimators': 1955, 'max_depth': 43, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:27:53,967] Trial 2 finished with value: 0.20411055988660523 and parameters: {'n_estimators': 1135, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:28:33,896] Trial 3 finished with value: 0.20120945574491475 and parameters: {'n_estimators': 1077, 'max_depth': 38, 'min_samples_split': 4, 'min_samples_leaf': 8, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:29:22,907] Trial 4 finished with value: 0.1984251968503937 and parameters: {'n_estimators': 1335, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 9, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:30:35,591] Trial 5 finished with value: 0.20628334321280378 and parameters: {'n_estimators': 1762, 'max_depth': 41, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:31:23,485] Trial 6 finished with value: 0.2169362511893435 and parameters: {'n_estimators': 1040, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:32:56,439] Trial 7 finished with value: 0.22720478325859492 and parameters: {'n_estimators': 1793, 'max_depth': 48, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:34:07,116] Trial 8 finished with value: 0.19968635650810246 and parameters: {'n_estimators': 1794, 'max_depth': 49, 'min_samples_split': 2, 'min_samples_leaf': 9, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:35:28,732] Trial 9 finished with value: 0.21231422505307856 and parameters: {'n_estimators': 1859, 'max_depth': 36, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:36:40,144] Trial 10 finished with value: 0.21983273596176822 and parameters: {'n_estimators': 1560, 'max_depth': 46, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:38:11,336] Trial 11 finished with value: 0.22277227722772278 and parameters: {'n_estimators': 1959, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:39:17,672] Trial 12 finished with value: 0.20844564240790656 and parameters: {'n_estimators': 1603, 'max_depth': 46, 'min_samples_split': 8, 'min_samples_leaf': 3, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:40:41,441] Trial 13 finished with value: 0.21316033364226133 and parameters: {'n_estimators': 1985, 'max_depth': 46, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.22900763358778628.\n",
      "[I 2024-08-17 12:42:03,044] Trial 14 finished with value: 0.23380281690140842 and parameters: {'n_estimators': 1679, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:43:04,396] Trial 15 finished with value: 0.2222222222222222 and parameters: {'n_estimators': 1403, 'max_depth': 36, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:44:11,403] Trial 16 finished with value: 0.21286735504368548 and parameters: {'n_estimators': 1638, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:45:13,447] Trial 17 finished with value: 0.21012416427889208 and parameters: {'n_estimators': 1438, 'max_depth': 39, 'min_samples_split': 10, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:46:21,923] Trial 18 finished with value: 0.2111111111111111 and parameters: {'n_estimators': 1682, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 4, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:47:19,731] Trial 19 finished with value: 0.22923976608187133 and parameters: {'n_estimators': 1310, 'max_depth': 34, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:48:13,406] Trial 20 finished with value: 0.21698113207547168 and parameters: {'n_estimators': 1232, 'max_depth': 33, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:49:18,495] Trial 21 finished with value: 0.23347398030942335 and parameters: {'n_estimators': 1311, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:50:16,774] Trial 22 finished with value: 0.21962616822429906 and parameters: {'n_estimators': 1272, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:51:16,576] Trial 23 finished with value: 0.2100238663484487 and parameters: {'n_estimators': 1490, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:52:23,929] Trial 24 finished with value: 0.2252252252252252 and parameters: {'n_estimators': 1344, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:53:13,900] Trial 25 finished with value: 0.21503330161750714 and parameters: {'n_estimators': 1184, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:54:22,856] Trial 26 finished with value: 0.22505800464037123 and parameters: {'n_estimators': 1533, 'max_depth': 38, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:55:11,932] Trial 27 finished with value: 0.20641913152926367 and parameters: {'n_estimators': 1312, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 6, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:56:02,138] Trial 28 finished with value: 0.19842053307008883 and parameters: {'n_estimators': 1417, 'max_depth': 40, 'min_samples_split': 3, 'min_samples_leaf': 10, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:57:02,232] Trial 29 finished with value: 0.23298429319371727 and parameters: {'n_estimators': 1176, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:57:54,175] Trial 30 finished with value: 0.2300653594771242 and parameters: {'n_estimators': 1008, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:58:46,135] Trial 31 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1001, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 12:59:44,653] Trial 32 finished with value: 0.2284263959390863 and parameters: {'n_estimators': 1134, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:00:52,345] Trial 33 finished with value: 0.23218997361477572 and parameters: {'n_estimators': 1194, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:01:44,641] Trial 34 finished with value: 0.22247191011235956 and parameters: {'n_estimators': 1084, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:02:37,728] Trial 35 finished with value: 0.2085661080074488 and parameters: {'n_estimators': 1159, 'max_depth': 34, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:03:33,078] Trial 36 finished with value: 0.2275600505689001 and parameters: {'n_estimators': 1086, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:04:23,262] Trial 37 finished with value: 0.20352941176470588 and parameters: {'n_estimators': 1251, 'max_depth': 38, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:05:12,826] Trial 38 finished with value: 0.22273781902552203 and parameters: {'n_estimators': 1007, 'max_depth': 31, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:06:29,521] Trial 39 finished with value: 0.20751113940165503 and parameters: {'n_estimators': 1859, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 6, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:07:58,639] Trial 40 finished with value: 0.23066841415465267 and parameters: {'n_estimators': 1721, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:09:01,063] Trial 41 finished with value: 0.22661396574440051 and parameters: {'n_estimators': 1203, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:09:59,355] Trial 42 finished with value: 0.2263157894736842 and parameters: {'n_estimators': 1115, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:10:50,689] Trial 43 finished with value: 0.21990740740740738 and parameters: {'n_estimators': 1060, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:11:59,742] Trial 44 finished with value: 0.2269861286254729 and parameters: {'n_estimators': 1358, 'max_depth': 34, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:12:54,915] Trial 45 finished with value: 0.21042471042471042 and parameters: {'n_estimators': 1219, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 3, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:13:55,534] Trial 46 finished with value: 0.23157894736842108 and parameters: {'n_estimators': 1162, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:14:46,394] Trial 47 finished with value: 0.2005509641873278 and parameters: {'n_estimators': 1281, 'max_depth': 48, 'min_samples_split': 7, 'min_samples_leaf': 8, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:15:57,785] Trial 48 finished with value: 0.22299651567944248 and parameters: {'n_estimators': 1486, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:17:23,364] Trial 49 finished with value: 0.2127659574468085 and parameters: {'n_estimators': 1863, 'max_depth': 45, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:18:37,742] Trial 50 finished with value: 0.22781065088757393 and parameters: {'n_estimators': 1371, 'max_depth': 37, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:19:38,423] Trial 51 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1169, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:20:31,476] Trial 52 finished with value: 0.22171945701357465 and parameters: {'n_estimators': 1128, 'max_depth': 33, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:21:30,755] Trial 53 finished with value: 0.22503160556257903 and parameters: {'n_estimators': 1186, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:22:25,250] Trial 54 finished with value: 0.23127463863337713 and parameters: {'n_estimators': 1044, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:23:20,401] Trial 55 finished with value: 0.22039859320046892 and parameters: {'n_estimators': 1254, 'max_depth': 41, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:24:43,895] Trial 56 finished with value: 0.23055555555555554 and parameters: {'n_estimators': 1608, 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:25:29,924] Trial 57 finished with value: 0.21821631878557876 and parameters: {'n_estimators': 1110, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:26:26,050] Trial 58 finished with value: 0.21788283658787255 and parameters: {'n_estimators': 1301, 'max_depth': 34, 'min_samples_split': 8, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:27:34,537] Trial 59 finished with value: 0.21397379912663755 and parameters: {'n_estimators': 1442, 'max_depth': 33, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:28:21,420] Trial 60 finished with value: 0.20766773162939295 and parameters: {'n_estimators': 1178, 'max_depth': 37, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:29:22,470] Trial 61 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1160, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:30:28,046] Trial 62 finished with value: 0.2280945757997218 and parameters: {'n_estimators': 1233, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:31:28,378] Trial 63 finished with value: 0.22774869109947646 and parameters: {'n_estimators': 1154, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:32:22,092] Trial 64 finished with value: 0.21843003412969283 and parameters: {'n_estimators': 1093, 'max_depth': 36, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:33:10,976] Trial 65 finished with value: 0.22751322751322756 and parameters: {'n_estimators': 1022, 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:34:15,903] Trial 66 finished with value: 0.23087621696801108 and parameters: {'n_estimators': 1210, 'max_depth': 33, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:35:23,280] Trial 67 finished with value: 0.2239297475301866 and parameters: {'n_estimators': 1384, 'max_depth': 34, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:36:04,474] Trial 68 finished with value: 0.21231422505307856 and parameters: {'n_estimators': 1058, 'max_depth': 39, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:37:14,830] Trial 69 finished with value: 0.23023578363384187 and parameters: {'n_estimators': 1324, 'max_depth': 37, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:38:34,796] Trial 70 finished with value: 0.21316033364226133 and parameters: {'n_estimators': 1899, 'max_depth': 43, 'min_samples_split': 7, 'min_samples_leaf': 3, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:39:29,379] Trial 71 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1058, 'max_depth': 35, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 14 with value: 0.23380281690140842.\n",
      "[I 2024-08-17 13:40:22,869] Trial 72 finished with value: 0.23733333333333334 and parameters: {'n_estimators': 1021, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:41:12,129] Trial 73 finished with value: 0.22675736961451246 and parameters: {'n_estimators': 1031, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:42:12,292] Trial 74 finished with value: 0.23199999999999998 and parameters: {'n_estimators': 1152, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:43:40,776] Trial 75 finished with value: 0.22752808988764045 and parameters: {'n_estimators': 1674, 'max_depth': 49, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:44:33,792] Trial 76 finished with value: 0.21843003412969283 and parameters: {'n_estimators': 1105, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:45:42,716] Trial 77 finished with value: 0.22916666666666666 and parameters: {'n_estimators': 1283, 'max_depth': 49, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:47:02,033] Trial 78 finished with value: 0.2211874272409779 and parameters: {'n_estimators': 1775, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:47:55,195] Trial 79 finished with value: 0.23513870541611626 and parameters: {'n_estimators': 1000, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:48:46,338] Trial 80 finished with value: 0.2269861286254729 and parameters: {'n_estimators': 1001, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:49:44,981] Trial 81 finished with value: 0.2318840579710145 and parameters: {'n_estimators': 1079, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:50:44,949] Trial 82 finished with value: 0.23127463863337713 and parameters: {'n_estimators': 1131, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:51:34,615] Trial 83 finished with value: 0.2183507549361208 and parameters: {'n_estimators': 1031, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:52:29,474] Trial 84 finished with value: 0.23670212765957446 and parameters: {'n_estimators': 1066, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:53:24,077] Trial 85 finished with value: 0.23096446700507614 and parameters: {'n_estimators': 1067, 'max_depth': 42, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:54:14,456] Trial 86 finished with value: 0.22503516174402252 and parameters: {'n_estimators': 1038, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:55:13,841] Trial 87 finished with value: 0.19980019980019978 and parameters: {'n_estimators': 1556, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 10, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:56:01,684] Trial 88 finished with value: 0.22429906542056074 and parameters: {'n_estimators': 1003, 'max_depth': 41, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:56:56,839] Trial 89 finished with value: 0.21914648212226068 and parameters: {'n_estimators': 1106, 'max_depth': 40, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:57:40,248] Trial 90 finished with value: 0.2 and parameters: {'n_estimators': 1188, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 8, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:58:40,218] Trial 91 finished with value: 0.2335958005249344 and parameters: {'n_estimators': 1140, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 72 with value: 0.23733333333333334.\n",
      "[I 2024-08-17 13:59:37,009] Trial 92 finished with value: 0.2394736842105263 and parameters: {'n_estimators': 1070, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:00:33,892] Trial 93 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1084, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:01:30,581] Trial 94 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1086, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:02:23,901] Trial 95 finished with value: 0.21945701357466063 and parameters: {'n_estimators': 1055, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:03:17,824] Trial 96 finished with value: 0.23320659062103927 and parameters: {'n_estimators': 1022, 'max_depth': 42, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:04:07,832] Trial 97 finished with value: 0.21633554083885212 and parameters: {'n_estimators': 1028, 'max_depth': 45, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:05:03,583] Trial 98 finished with value: 0.2256020278833967 and parameters: {'n_estimators': 1023, 'max_depth': 42, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:05:59,742] Trial 99 finished with value: 0.2322946175637394 and parameters: {'n_estimators': 1136, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:06:56,088] Trial 100 finished with value: 0.23347398030942335 and parameters: {'n_estimators': 1052, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:07:51,563] Trial 101 finished with value: 0.2296918767507003 and parameters: {'n_estimators': 1061, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:08:45,020] Trial 102 finished with value: 0.2277777777777778 and parameters: {'n_estimators': 1013, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:09:25,571] Trial 103 finished with value: 0.19738903394255877 and parameters: {'n_estimators': 1043, 'max_depth': 44, 'min_samples_split': 5, 'min_samples_leaf': 9, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:10:27,025] Trial 104 finished with value: 0.22950819672131145 and parameters: {'n_estimators': 1119, 'max_depth': 47, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:11:24,577] Trial 105 finished with value: 0.22657342657342655 and parameters: {'n_estimators': 1080, 'max_depth': 42, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:12:12,954] Trial 106 finished with value: 0.21871713985278654 and parameters: {'n_estimators': 1000, 'max_depth': 41, 'min_samples_split': 7, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:13:03,000] Trial 107 finished with value: 0.22721268163804495 and parameters: {'n_estimators': 1042, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:14:02,388] Trial 108 finished with value: 0.2280945757997218 and parameters: {'n_estimators': 1105, 'max_depth': 43, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:14:55,177] Trial 109 finished with value: 0.2167255594817432 and parameters: {'n_estimators': 1070, 'max_depth': 45, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:16:25,647] Trial 110 finished with value: 0.23574144486692017 and parameters: {'n_estimators': 1740, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:17:41,052] Trial 111 finished with value: 0.2326169405815423 and parameters: {'n_estimators': 1462, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:19:10,658] Trial 112 finished with value: 0.23184713375796182 and parameters: {'n_estimators': 1727, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:20:45,990] Trial 113 finished with value: 0.22971285892634205 and parameters: {'n_estimators': 1746, 'max_depth': 47, 'min_samples_split': 7, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:22:26,725] Trial 114 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 1829, 'max_depth': 39, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:23:55,207] Trial 115 finished with value: 0.22506393861892585 and parameters: {'n_estimators': 1682, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:25:06,392] Trial 116 finished with value: 0.22323462414578588 and parameters: {'n_estimators': 1620, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:26:40,413] Trial 117 finished with value: 0.23015873015873015 and parameters: {'n_estimators': 1798, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:27:44,438] Trial 118 finished with value: 0.2129760225669958 and parameters: {'n_estimators': 1518, 'max_depth': 47, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:28:40,684] Trial 119 finished with value: 0.22485207100591717 and parameters: {'n_estimators': 1141, 'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:29:19,031] Trial 120 finished with value: 0.20467836257309943 and parameters: {'n_estimators': 1019, 'max_depth': 40, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:30:15,006] Trial 121 finished with value: 0.2310756972111554 and parameters: {'n_estimators': 1049, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:31:12,729] Trial 122 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1102, 'max_depth': 44, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:32:10,484] Trial 123 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 1080, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:33:07,779] Trial 124 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1089, 'max_depth': 43, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:34:02,379] Trial 125 finished with value: 0.2230971128608924 and parameters: {'n_estimators': 1038, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:35:29,304] Trial 126 finished with value: 0.23214285714285715 and parameters: {'n_estimators': 1670, 'max_depth': 44, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:36:24,499] Trial 127 finished with value: 0.2250879249706917 and parameters: {'n_estimators': 1121, 'max_depth': 42, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:37:16,076] Trial 128 finished with value: 0.23482849604221637 and parameters: {'n_estimators': 1000, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:37:57,665] Trial 129 finished with value: 0.20358514724711907 and parameters: {'n_estimators': 1017, 'max_depth': 49, 'min_samples_split': 4, 'min_samples_leaf': 6, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:38:50,333] Trial 130 finished with value: 0.22503516174402252 and parameters: {'n_estimators': 1062, 'max_depth': 48, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:39:45,180] Trial 131 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1026, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:40:40,864] Trial 132 finished with value: 0.2357615894039735 and parameters: {'n_estimators': 1050, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:41:33,758] Trial 133 finished with value: 0.22721268163804495 and parameters: {'n_estimators': 1005, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:42:28,375] Trial 134 finished with value: 0.23482849604221637 and parameters: {'n_estimators': 1047, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:43:23,664] Trial 135 finished with value: 0.2316910785619174 and parameters: {'n_estimators': 1052, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:44:20,175] Trial 136 finished with value: 0.22834645669291337 and parameters: {'n_estimators': 1073, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:45:16,304] Trial 137 finished with value: 0.22900763358778628 and parameters: {'n_estimators': 1095, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:46:10,682] Trial 138 finished with value: 0.2310756972111554 and parameters: {'n_estimators': 1032, 'max_depth': 44, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:47:00,556] Trial 139 finished with value: 0.2176278563656148 and parameters: {'n_estimators': 1049, 'max_depth': 45, 'min_samples_split': 6, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:48:20,777] Trial 140 finished with value: 0.22784810126582278 and parameters: {'n_estimators': 1648, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:49:37,225] Trial 141 finished with value: 0.2089068825910931 and parameters: {'n_estimators': 1708, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:50:31,248] Trial 142 finished with value: 0.23451910408432147 and parameters: {'n_estimators': 1000, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:51:21,900] Trial 143 finished with value: 0.22514970059880238 and parameters: {'n_estimators': 1003, 'max_depth': 49, 'min_samples_split': 8, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:52:16,182] Trial 144 finished with value: 0.23138297872340427 and parameters: {'n_estimators': 1024, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:53:12,341] Trial 145 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 1068, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:54:07,075] Trial 146 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1044, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:55:04,244] Trial 147 finished with value: 0.23404255319148937 and parameters: {'n_estimators': 1093, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:55:56,706] Trial 148 finished with value: 0.22147651006711408 and parameters: {'n_estimators': 1090, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:57:12,955] Trial 149 finished with value: 0.23001402524544182 and parameters: {'n_estimators': 1407, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:58:06,276] Trial 150 finished with value: 0.22281167108753316 and parameters: {'n_estimators': 1112, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:58:59,041] Trial 151 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1001, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 14:59:55,419] Trial 152 finished with value: 0.228646517739816 and parameters: {'n_estimators': 1069, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:00:49,385] Trial 153 finished with value: 0.22646310432569974 and parameters: {'n_estimators': 1027, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:01:45,049] Trial 154 finished with value: 0.228646517739816 and parameters: {'n_estimators': 1051, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:03:10,834] Trial 155 finished with value: 0.23333333333333334 and parameters: {'n_estimators': 1586, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:04:34,734] Trial 156 finished with value: 0.23216783216783216 and parameters: {'n_estimators': 1558, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:06:00,889] Trial 157 finished with value: 0.23314606741573035 and parameters: {'n_estimators': 1597, 'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:06:56,514] Trial 158 finished with value: 0.22377622377622378 and parameters: {'n_estimators': 1134, 'max_depth': 47, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:08:34,546] Trial 159 finished with value: 0.2314540059347181 and parameters: {'n_estimators': 1751, 'max_depth': 45, 'min_samples_split': 3, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:09:27,404] Trial 160 finished with value: 0.22598870056497175 and parameters: {'n_estimators': 1091, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 1, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:10:21,293] Trial 161 finished with value: 0.23733333333333334 and parameters: {'n_estimators': 1020, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:11:50,987] Trial 162 finished with value: 0.23904382470119526 and parameters: {'n_estimators': 1699, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:13:26,535] Trial 163 finished with value: 0.23435419440745672 and parameters: {'n_estimators': 1796, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:15:00,975] Trial 164 finished with value: 0.23591087811271297 and parameters: {'n_estimators': 1773, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:16:35,968] Trial 165 finished with value: 0.23249669749009247 and parameters: {'n_estimators': 1798, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:18:08,372] Trial 166 finished with value: 0.22516556291390727 and parameters: {'n_estimators': 1769, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:19:43,606] Trial 167 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1816, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:21:15,474] Trial 168 finished with value: 0.22781456953642382 and parameters: {'n_estimators': 1703, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:22:55,294] Trial 169 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1871, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:24:26,278] Trial 170 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1733, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:26:05,626] Trial 171 finished with value: 0.23607427055702918 and parameters: {'n_estimators': 1838, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:27:45,165] Trial 172 finished with value: 0.23127463863337713 and parameters: {'n_estimators': 1863, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:29:24,290] Trial 173 finished with value: 0.2295514511873351 and parameters: {'n_estimators': 1850, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:31:05,308] Trial 174 finished with value: 0.22872340425531917 and parameters: {'n_estimators': 1890, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:32:54,907] Trial 175 finished with value: 0.2310756972111554 and parameters: {'n_estimators': 1915, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:34:29,113] Trial 176 finished with value: 0.22753128555176336 and parameters: {'n_estimators': 1825, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:36:09,172] Trial 177 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1784, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:37:47,157] Trial 178 finished with value: 0.2318840579710145 and parameters: {'n_estimators': 1772, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:39:33,466] Trial 179 finished with value: 0.23076923076923078 and parameters: {'n_estimators': 1936, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:41:02,955] Trial 180 finished with value: 0.22020431328036325 and parameters: {'n_estimators': 1841, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:42:35,984] Trial 181 finished with value: 0.2323097463284379 and parameters: {'n_estimators': 1755, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:44:23,946] Trial 182 finished with value: 0.23342175066312998 and parameters: {'n_estimators': 1997, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:46:00,617] Trial 183 finished with value: 0.23544973544973546 and parameters: {'n_estimators': 1798, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:47:37,618] Trial 184 finished with value: 0.23015873015873015 and parameters: {'n_estimators': 1811, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:49:07,962] Trial 185 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1742, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:50:50,295] Trial 186 finished with value: 0.22872340425531917 and parameters: {'n_estimators': 1879, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:52:22,831] Trial 187 finished with value: 0.23218997361477572 and parameters: {'n_estimators': 1792, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:53:54,160] Trial 188 finished with value: 0.23218997361477572 and parameters: {'n_estimators': 1798, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:55:22,662] Trial 189 finished with value: 0.2335958005249344 and parameters: {'n_estimators': 1702, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:56:51,691] Trial 190 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1723, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:58:19,878] Trial 191 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1764, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 15:59:47,477] Trial 192 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1765, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:01:28,406] Trial 193 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1843, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:03:08,715] Trial 194 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1809, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:04:45,865] Trial 195 finished with value: 0.23249669749009247 and parameters: {'n_estimators': 1761, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:06:31,649] Trial 196 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1828, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:08:11,981] Trial 197 finished with value: 0.23015873015873015 and parameters: {'n_estimators': 1784, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:09:08,494] Trial 198 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1024, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:10:49,322] Trial 199 finished with value: 0.23076923076923078 and parameters: {'n_estimators': 1872, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:12:14,097] Trial 200 finished with value: 0.2284263959390863 and parameters: {'n_estimators': 1688, 'max_depth': 45, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:13:06,789] Trial 201 finished with value: 0.22804718217562253 and parameters: {'n_estimators': 1040, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:13:57,041] Trial 202 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1002, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:14:51,504] Trial 203 finished with value: 0.22576361221779548 and parameters: {'n_estimators': 1068, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:16:20,556] Trial 204 finished with value: 0.23311258278145697 and parameters: {'n_estimators': 1736, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:17:13,875] Trial 205 finished with value: 0.23076923076923078 and parameters: {'n_estimators': 1019, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:18:06,233] Trial 206 finished with value: 0.23157894736842108 and parameters: {'n_estimators': 1037, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:19:31,739] Trial 207 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1661, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:20:53,370] Trial 208 finished with value: 0.21168687982359427 and parameters: {'n_estimators': 1654, 'max_depth': 45, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:22:17,008] Trial 209 finished with value: 0.21889400921658986 and parameters: {'n_estimators': 1707, 'max_depth': 49, 'min_samples_split': 9, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:23:32,704] Trial 210 finished with value: 0.22197055492638734 and parameters: {'n_estimators': 1628, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:24:56,188] Trial 211 finished with value: 0.23841059602649006 and parameters: {'n_estimators': 1682, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:26:17,371] Trial 212 finished with value: 0.23157894736842108 and parameters: {'n_estimators': 1654, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:27:42,689] Trial 213 finished with value: 0.23342175066312998 and parameters: {'n_estimators': 1689, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:29:15,956] Trial 214 finished with value: 0.2289473684210526 and parameters: {'n_estimators': 1725, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:30:48,676] Trial 215 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1681, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:32:23,353] Trial 216 finished with value: 0.23015873015873015 and parameters: {'n_estimators': 1774, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:33:49,699] Trial 217 finished with value: 0.2310756972111554 and parameters: {'n_estimators': 1660, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:35:20,848] Trial 218 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1714, 'max_depth': 45, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:36:10,865] Trial 219 finished with value: 0.23157894736842108 and parameters: {'n_estimators': 1000, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:37:43,109] Trial 220 finished with value: 0.23638778220451528 and parameters: {'n_estimators': 1830, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:39:17,730] Trial 221 finished with value: 0.23199999999999998 and parameters: {'n_estimators': 1818, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:40:55,337] Trial 222 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1839, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:42:32,302] Trial 223 finished with value: 0.23544973544973546 and parameters: {'n_estimators': 1858, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:44:12,971] Trial 224 finished with value: 0.22576361221779548 and parameters: {'n_estimators': 1802, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:45:49,718] Trial 225 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1913, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:47:23,427] Trial 226 finished with value: 0.23638778220451528 and parameters: {'n_estimators': 1853, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:49:01,369] Trial 227 finished with value: 0.23607427055702918 and parameters: {'n_estimators': 1851, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:50:38,710] Trial 228 finished with value: 0.2328042328042328 and parameters: {'n_estimators': 1850, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:52:10,352] Trial 229 finished with value: 0.22988505747126436 and parameters: {'n_estimators': 1826, 'max_depth': 49, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:53:44,497] Trial 230 finished with value: 0.23342175066312998 and parameters: {'n_estimators': 1858, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:55:21,299] Trial 231 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1884, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:56:58,884] Trial 232 finished with value: 0.23684210526315788 and parameters: {'n_estimators': 1859, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 16:58:32,562] Trial 233 finished with value: 0.2293333333333333 and parameters: {'n_estimators': 1844, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:00:10,170] Trial 234 finished with value: 0.2357615894039735 and parameters: {'n_estimators': 1900, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:01:47,583] Trial 235 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1953, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:03:25,134] Trial 236 finished with value: 0.23249669749009247 and parameters: {'n_estimators': 1899, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:05:00,276] Trial 237 finished with value: 0.2304635761589404 and parameters: {'n_estimators': 1876, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:06:32,110] Trial 238 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 1856, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:08:03,401] Trial 239 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1807, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:09:45,549] Trial 240 finished with value: 0.23249669749009247 and parameters: {'n_estimators': 1912, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:11:21,237] Trial 241 finished with value: 0.23404255319148937 and parameters: {'n_estimators': 1867, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:13:03,378] Trial 242 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1895, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:14:42,828] Trial 243 finished with value: 0.23544973544973546 and parameters: {'n_estimators': 1858, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:16:18,985] Trial 244 finished with value: 0.22811671087533153 and parameters: {'n_estimators': 1830, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:17:56,259] Trial 245 finished with value: 0.23544973544973546 and parameters: {'n_estimators': 1858, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:19:34,958] Trial 246 finished with value: 0.23342175066312998 and parameters: {'n_estimators': 1857, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:21:09,587] Trial 247 finished with value: 0.23138297872340427 and parameters: {'n_estimators': 1836, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:22:44,907] Trial 248 finished with value: 0.23513870541611626 and parameters: {'n_estimators': 1877, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:24:03,235] Trial 249 finished with value: 0.2071156289707751 and parameters: {'n_estimators': 1931, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 6, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:25:27,751] Trial 250 finished with value: 0.21069692058346842 and parameters: {'n_estimators': 1888, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:27:07,590] Trial 251 finished with value: 0.23157894736842108 and parameters: {'n_estimators': 1869, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:28:46,831] Trial 252 finished with value: 0.2335958005249344 and parameters: {'n_estimators': 1847, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:30:22,827] Trial 253 finished with value: 0.2295514511873351 and parameters: {'n_estimators': 1815, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:31:58,957] Trial 254 finished with value: 0.23048327137546468 and parameters: {'n_estimators': 1883, 'max_depth': 49, 'min_samples_split': 7, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:33:33,208] Trial 255 finished with value: 0.23066841415465267 and parameters: {'n_estimators': 1835, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:35:11,286] Trial 256 finished with value: 0.2357615894039735 and parameters: {'n_estimators': 1908, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:36:27,386] Trial 257 finished with value: 0.19874476987447695 and parameters: {'n_estimators': 1933, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 9, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:38:11,191] Trial 258 finished with value: 0.23342175066312998 and parameters: {'n_estimators': 1911, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:39:49,692] Trial 259 finished with value: 0.23218997361477572 and parameters: {'n_estimators': 1865, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:41:20,376] Trial 260 finished with value: 0.2222222222222222 and parameters: {'n_estimators': 1890, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:42:12,353] Trial 261 finished with value: 0.2335958005249344 and parameters: {'n_estimators': 1014, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:43:25,230] Trial 262 finished with value: 0.20144685587089592 and parameters: {'n_estimators': 1863, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 8, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:44:18,316] Trial 263 finished with value: 0.2316910785619174 and parameters: {'n_estimators': 1029, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:46:00,455] Trial 264 finished with value: 0.23076923076923078 and parameters: {'n_estimators': 1897, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:47:45,995] Trial 265 finished with value: 0.23715415019762848 and parameters: {'n_estimators': 1925, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:49:30,166] Trial 266 finished with value: 0.23607427055702918 and parameters: {'n_estimators': 1954, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:51:15,011] Trial 267 finished with value: 0.23591087811271297 and parameters: {'n_estimators': 1974, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:52:56,956] Trial 268 finished with value: 0.22733077905491697 and parameters: {'n_estimators': 1940, 'max_depth': 48, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:54:37,948] Trial 269 finished with value: 0.23097112860892388 and parameters: {'n_estimators': 1980, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 92 with value: 0.2394736842105263.\n",
      "[I 2024-08-17 17:56:21,624] Trial 270 finished with value: 0.24105960264900664 and parameters: {'n_estimators': 1959, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 17:58:09,131] Trial 271 finished with value: 0.22721268163804495 and parameters: {'n_estimators': 1977, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 17:59:53,763] Trial 272 finished with value: 0.23025435073627848 and parameters: {'n_estimators': 1960, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:01:39,925] Trial 273 finished with value: 0.23544973544973546 and parameters: {'n_estimators': 1965, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:03:15,624] Trial 274 finished with value: 0.22096956031567078 and parameters: {'n_estimators': 1950, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:04:57,068] Trial 275 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1965, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:06:42,802] Trial 276 finished with value: 0.22902796271637818 and parameters: {'n_estimators': 1995, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:08:25,671] Trial 277 finished with value: 0.22661396574440051 and parameters: {'n_estimators': 1978, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:10:08,432] Trial 278 finished with value: 0.22751322751322756 and parameters: {'n_estimators': 1921, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:11:49,565] Trial 279 finished with value: 0.2396804260985353 and parameters: {'n_estimators': 1961, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:13:28,971] Trial 280 finished with value: 0.2272727272727273 and parameters: {'n_estimators': 1948, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:15:11,307] Trial 281 finished with value: 0.22781456953642382 and parameters: {'n_estimators': 1927, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:16:55,289] Trial 282 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 1970, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:18:33,271] Trial 283 finished with value: 0.2219679633867277 and parameters: {'n_estimators': 1945, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:20:25,735] Trial 284 finished with value: 0.22902796271637818 and parameters: {'n_estimators': 1924, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:22:22,194] Trial 285 finished with value: 0.23015873015873015 and parameters: {'n_estimators': 1989, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:24:09,365] Trial 286 finished with value: 0.23373173970783534 and parameters: {'n_estimators': 1898, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:25:33,619] Trial 287 finished with value: 0.20709219858156028 and parameters: {'n_estimators': 1953, 'max_depth': 47, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:27:03,194] Trial 288 finished with value: 0.22448979591836735 and parameters: {'n_estimators': 1923, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 2, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:28:41,321] Trial 289 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1902, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:30:19,093] Trial 290 finished with value: 0.23127463863337713 and parameters: {'n_estimators': 1821, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:32:03,093] Trial 291 finished with value: 0.2292490118577075 and parameters: {'n_estimators': 2000, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:33:52,796] Trial 292 finished with value: 0.22721268163804495 and parameters: {'n_estimators': 1943, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:35:29,517] Trial 293 finished with value: 0.23404255319148937 and parameters: {'n_estimators': 1843, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:36:38,823] Trial 294 finished with value: 0.2029325513196481 and parameters: {'n_estimators': 1780, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 7, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:38:16,595] Trial 295 finished with value: 0.2298546895640687 and parameters: {'n_estimators': 1911, 'max_depth': 49, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:39:51,296] Trial 296 finished with value: 0.23841059602649006 and parameters: {'n_estimators': 1853, 'max_depth': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:41:21,765] Trial 297 finished with value: 0.23778071334214002 and parameters: {'n_estimators': 1827, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:42:54,404] Trial 298 finished with value: 0.2310756972111554 and parameters: {'n_estimators': 1806, 'max_depth': 46, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n",
      "[I 2024-08-17 18:44:27,335] Trial 299 finished with value: 0.2300884955752212 and parameters: {'n_estimators': 1827, 'max_depth': 46, 'min_samples_split': 6, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 270 with value: 0.24105960264900664.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.24105960264900664, \n",
      "params {'n_estimators': 1959, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_dam['target'] = train_data_dam['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "def objectiveRF(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "    'n_estimators' : trial.suggest_int('n_estimators', 1000, 2000),\n",
    "    'max_depth' : trial.suggest_int('max_depth', 30, 50),\n",
    "    'min_samples_split' : trial.suggest_int('min_samples_split', 2, 10),\n",
    "    'min_samples_leaf' : trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "    'criterion' : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\",]),\n",
    "    'class_weight' : trial.suggest_categorical(\"class_weight\", [\"balanced\"]),\n",
    "    }\n",
    "    \n",
    "    model = RandomForestClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred = model.predict(x_val)\n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_dam.drop(\"target\", axis=1),\n",
    "    train_data_dam[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveRF(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990ff79",
   "metadata": {},
   "source": [
    "Best trial: score 0.24105960264900664\n",
    "\n",
    "params 'n_estimators': 1959, 'max_depth': 48, 'min_samples_split': 5, 'min_samples_leaf': 1, 'criterion': 'entropy', 'class_weight': 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "187981b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터\n",
    "best_params = {\n",
    "    \n",
    "}\n",
    "\n",
    "# 모델 생성\n",
    "model = RandomForestClassifier(**best_params)\n",
    "\n",
    "# 데이터셋 분할 (재사용)\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_dam.drop(\"target\", axis=1),\n",
    "    train_data_dam[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "y_train = y_train.apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "y_val = y_val.apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 검증 데이터에 대한 예측\n",
    "y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "# 평가지표 계산\n",
    "f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'F1 Score: {f1}')\n",
    "print('---')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix) # 혼동 행렬 출력\n",
    "print('---')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc88d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
