{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a6bbc",
   "metadata": {},
   "source": [
    "기본 전처리 할것들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1367da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Workorder_AutoClave' 열에서 '-' 다음 숫자 값 추출 및 '000' 제거\n",
    "train_data['Workorder'] = train_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)\n",
    "test_data['Workorder'] = test_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispenser_num 값에 따라 새로운 변수 생성\n",
    "train_data['Dispenser_1'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "train_data['Dispenser_2'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "test_data['Dispenser_1'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "test_data['Dispenser_2'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['Dispenser_num'], axis=1, inplace=True)\n",
    "test_data.drop(['Dispenser_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2e5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ab6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_receip_no_collect_result(df):\n",
    "    df['Receip_No_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Receip No Collect Result_Dam'] \n",
    "                    if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_receip_no_collect_result(train_data)\n",
    "create_receip_no_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60cd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Receip No Collect Result_Dam',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f9a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['PalletID_Collect_Result'] = df.apply(\n",
    "        lambda row: row['PalletID Collect Result_Dam'] \n",
    "                    if (row['PalletID Collect Result_Dam'] == row['PalletID Collect Result_Fill1'] == row['PalletID Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f7c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['Production_Qty_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Production Qty Collect Result_Dam'] \n",
    "                    if (row['Production Qty Collect Result_Dam'] == row['Production Qty Collect Result_Fill1'] == row['Production Qty Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fdec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Chamber Temp. Judge Value_AutoClave\" 변수의 값을 기준으로 파생 변수 생성 함수\n",
    "def create_judge_value_binary(df):\n",
    "    df['Chamber_Temp_OKNG_AutoClave'] = df['Chamber Temp. Judge Value_AutoClave'].apply(\n",
    "        lambda x: 1 if x == 'OK' else 0\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_binary(train_data)\n",
    "create_judge_value_binary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9ccf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Judge Value 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "Chamber Temp. Judge Value_AutoClave\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'Judge Value'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Judge Value').columns\n",
    "\n",
    "print(\"\\n Judge Value 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 변수 목록\n",
    "judge_value_columns = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_judge_value_feature(df):\n",
    "    df['Judge_Value_OK'] = df[judge_value_columns].apply(\n",
    "        lambda row: 1 if any(row == 'OK') else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_feature(train_data)\n",
    "create_judge_value_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Chamber Temp. Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb1e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 변경\n",
    "train_data = train_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})\n",
    "test_data = test_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cdd01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 108 entries, Model.Suffix to Judge_Value_OK\n",
      "dtypes: float64(56), int64(49), object(3)\n",
      "memory usage: 33.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4b1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 109 entries, Set ID to Judge_Value_OK\n",
      "dtypes: float64(86), int64(20), object(3)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d3595",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54df9c3",
   "metadata": {},
   "source": [
    "반복적으로 쓰는 툴 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d2efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, col_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 열 이름에 대해 박스 플롯을 그리는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.boxplot(df[col_name], vert=False)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.title(f'Box Plot of {col_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7515da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_ratio(df, col_name, target_name='target'):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 비율과 갯수, 총 갯수를 출력하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 데이터프레임\n",
    "    col_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    \"\"\"\n",
    "    # 각 값마다 타겟 변수의 비율 계산\n",
    "    value_counts = df.groupby(col_name)[target_name].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 타겟 변수의 갯수 계산\n",
    "    counts = df.groupby(col_name)[target_name].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 총 갯수 계산\n",
    "    total_counts = df[col_name].value_counts().rename('Total_Count')\n",
    "    \n",
    "    # 비율과 갯수를 합침\n",
    "    result = value_counts.join(counts, lsuffix='_ratio', rsuffix='_count')\n",
    "    \n",
    "    # 총 갯수를 합침\n",
    "    result = result.join(total_counts, on=col_name)\n",
    "    \n",
    "    # 출력 형식 조정\n",
    "    result.index.name = 'variable'\n",
    "    print(f\"\\n{col_name}별 {target_name} 비율 및 갯수\\n\")\n",
    "    print(result.rename(columns=lambda x: x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eed238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_group(df, group_by_columns):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_columns)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AdNormal' 비율과 갯수 계산\n",
    "        adnormal_count = group['target'].value_counts().get('AbNormal', 0)\n",
    "        adnormal_ratio = adnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, adnormal_count, adnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', \"'AdNormal' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그룹화된 변수들의 이름을 제목행으로 출력\n",
    "    print(f\"Grouped by: {', '.join(group_by_columns)}\")\n",
    "    print()\n",
    "    # 데이터프레임 출력\n",
    "    print(results_df)\n",
    "\n",
    "# 예시코드\n",
    "# summarize_grouped_data(train_data, ['1st Pressure Collect Result_AutoClave', '1st Pressure Unit Time_AutoClave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4bfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio(df, group_by_column, target_column='target', abnormal_value='AbNormal'):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_column)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AbNormal' 비율과 갯수 계산\n",
    "        abnormal_count = group[target_column].value_counts().get(abnormal_value, 0)\n",
    "        abnormal_ratio = abnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, abnormal_count, abnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', f\"'{abnormal_value}' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # 막대 그래프 생성\n",
    "    ax = results_df.plot(kind='bar', x='group', y='ratio', legend=False)\n",
    "    \n",
    "    # 각 막대 위에 AbNormal 갯수와 총 갯수 표시\n",
    "    for i, (abnormal_count, total) in enumerate(zip(results_df[f\"'{abnormal_value}' count\"], results_df['Total'])):\n",
    "        ax.text(i, results_df['ratio'][i], f'{abnormal_count} ({total})', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "     # 그래프 제목 및 축 레이블 설정\n",
    "    ax.set_title(f'{abnormal_value} Ratio by {group_by_column}')\n",
    "    ax.set_xlabel(group_by_column)\n",
    "    ax.set_ylabel(f'{abnormal_value} Ratio')\n",
    "   \n",
    "    # 그래프 출력\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad45361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_ratio_boxplot(data, time_ratio_column, target_column='target'):\n",
    "    # 그래프 스타일 설정\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=time_ratio_column, y=target_column, data=data)\n",
    "\n",
    "    # 그래프 제목 및 레이블 설정\n",
    "    plt.title(f'{time_ratio_column} vs {target_column}')\n",
    "    plt.xlabel(time_ratio_column)\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    # 그래프 출력\n",
    "    plt.show()\n",
    "\n",
    "# 함수 호출 예제\n",
    "#plot_time_ratio_vs_target(train_data, 'time_ratio_Dam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8a90c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e84bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model.Suffix',\n",
       " 'Workorder',\n",
       " 'CURE END POSITION X Collect Result_Dam',\n",
       " 'CURE END POSITION Z Collect Result_Dam',\n",
       " 'CURE END POSITION Θ Collect Result_Dam',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'CURE START POSITION X Collect Result_Dam',\n",
       " 'CURE START POSITION Θ Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage1) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage2) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Head Zero Position Z Collect Result_Dam',\n",
       " 'Machine Tact time Collect Result_Dam',\n",
       " 'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
       " 'THICKNESS 1 Collect Result_Dam',\n",
       " 'THICKNESS 2 Collect Result_Dam',\n",
       " 'THICKNESS 3 Collect Result_Dam',\n",
       " 'WorkMode Collect Result',\n",
       " '1st Pressure Collect Result_AutoClave',\n",
       " '1st Pressure Unit Time_AutoClave',\n",
       " '2nd Pressure Collect Result_AutoClave',\n",
       " '2nd Pressure Unit Time_AutoClave',\n",
       " '3rd Pressure Collect Result_AutoClave',\n",
       " '3rd Pressure Unit Time_AutoClave',\n",
       " 'Chamber Temp. Collect Result_AutoClave',\n",
       " 'Chamber Temp. Unit Time_AutoClave',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage1) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage2) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
       " 'Head Purge Position Z Collect Result_Fill1',\n",
       " 'Machine Tact time Collect Result_Fill1',\n",
       " 'CURE END POSITION X Collect Result_Fill2',\n",
       " 'CURE END POSITION Z Collect Result_Fill2',\n",
       " 'CURE SPEED Collect Result_Fill2',\n",
       " 'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
       " 'CURE START POSITION X Collect Result_Fill2',\n",
       " 'CURE START POSITION Z Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2',\n",
       " 'Head Purge Position Z Collect Result_Fill2',\n",
       " 'Machine Tact time Collect Result_Fill2',\n",
       " 'target',\n",
       " 'Dispenser_1',\n",
       " 'Dispenser_2',\n",
       " 'Receip_No_Collect_Result',\n",
       " 'PalletID_Collect_Result',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'Chamber_Temp_OKNG_AutoClave',\n",
       " 'Judge_Value_OK']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9465e",
   "metadata": {},
   "source": [
    "### 1. CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45bdcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'와 '_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33dc2f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION Θ Collect Result_Dam, CURE START POSITION Θ Collect Result_Dam\n",
      "\n",
      "              group  'AdNormal' count     ratio  Total\n",
      "0  (0, 0, -90, -90)                19  1.000000     19\n",
      "1    (0, 0, 90, 90)                15  1.000000     15\n",
      "2    (0, 1, 90, 90)               850  0.054977  15461\n",
      "3  (1, 0, -90, -90)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE START POSITION X Collect Result_Dam'\n",
    ", 'CURE START POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aff796",
   "metadata": {},
   "source": [
    "dispenser 종류에 따라 POSITION Θ 값이 따라감  \n",
    "-> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2bcdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION Θ Collect Result_Dam'\n",
    "    , 'CURE START POSITION Θ Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b7aff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61cf9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION X Collect Result_Dam, CURE END POSITION Z Collect Result_Dam, CURE START POSITION X Collect Result_Dam\n",
      "\n",
      "                     group  'AdNormal' count     ratio  Total\n",
      "0   (0, 0, 240, 2.5, 1030)                19  1.000000     19\n",
      "1  (0, 0, 1000, 12.5, 280)                15  1.000000     15\n",
      "2  (0, 1, 1000, 12.5, 280)               850  0.054977  15461\n",
      "3   (1, 0, 240, 2.5, 1030)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    ", 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Z Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    ", 'CURE START POSITION X Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d641dc",
   "metadata": {},
   "source": [
    "좌표값을 통해 좌표간의 거리를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d3ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Dam'\n",
    "start_z_col = 33.5\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Dam'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5fa846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Fill2'\n",
    "start_z_col = 'CURE START POSITION Z Collect Result_Fill2'\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Fill2'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Fill2'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbe2fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE START POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "    , 'CURE START POSITION X Collect Result_Fill2'\n",
    "    , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "    , 'CURE END POSITION X Collect Result_Fill2'\n",
    "    , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b9efd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46e713c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "\n",
      "   group  'AdNormal' count     ratio  Total\n",
      "0     22                34  0.072495    469\n",
      "1     23                22  0.107843    204\n",
      "2     32               421  0.085866   4903\n",
      "3     33              1873  0.053622  34930\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    " 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE_DISTANCE_Dam'\n",
    "# , 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b3d80",
   "metadata": {},
   "source": [
    "'CURE STANDBY POSITION Z Collect Result_Fill2' 변수의 유의미함을 찾을수 x  \n",
    "다른 변수와 연결된만한것도 찾지 못함 -> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc313406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = ['CURE STANDBY POSITION Z Collect Result_Fill2']\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50fe7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18af7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE_DISTANCE_Dam, CURE_DISTANCE_Fill2\n",
      "\n",
      "                                          group  'AdNormal' count     ratio  \\\n",
      "0              (0, 0, 720.3061848963953, 780.0)                15  1.000000   \n",
      "1               (0, 0, 790.607993888248, 780.0)                19  1.000000   \n",
      "2              (0, 1, 720.3061848963953, 780.0)               827  0.054645   \n",
      "3  (0, 1, 720.3061848963953, 780.0006410253776)                23  0.070552   \n",
      "4  (0, 1, 720.3061848963953, 780.0775602464155)                 0  0.000000   \n",
      "5               (1, 0, 790.607993888248, 780.0)              1129  0.054418   \n",
      "6   (1, 0, 790.607993888248, 780.0006410253776)               286  0.077591   \n",
      "7   (1, 0, 790.607993888248, 780.0640999302557)                51  0.088235   \n",
      "\n",
      "   Total  \n",
      "0     15  \n",
      "1     19  \n",
      "2  15134  \n",
      "3    326  \n",
      "4      1  \n",
      "5  20747  \n",
      "6   3686  \n",
      "7    578  \n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    ", 'CURE_DISTANCE_Dam'\n",
    ", 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dbf40",
   "metadata": {},
   "source": [
    "거리의 차이에 따라 ratio 값 변화 크지 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c26ff29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 / 속도 -> 시간 파생 변수 생성\n",
    "train_data['CURE_Time_Dam']  = train_data['CURE_DISTANCE_Dam'] / train_data['CURE SPEED Collect Result_Dam']\n",
    "test_data['CURE_Time_Dam']  = test_data['CURE_DISTANCE_Dam'] / test_data['CURE SPEED Collect Result_Dam']\n",
    "\n",
    "train_data['CURE_Time_Fill2']  = train_data['CURE_DISTANCE_Fill2'] / train_data['CURE SPEED Collect Result_Fill2']\n",
    "test_data['CURE_Time_Fill2']  = test_data['CURE_DISTANCE_Fill2'] / test_data['CURE SPEED Collect Result_Fill2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48b4c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4195b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE_DISTANCE_Dam'\n",
    "    , 'CURE SPEED Collect Result_Dam'\n",
    "    , 'CURE_DISTANCE_Fill2'\n",
    "    , 'CURE SPEED Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d0840f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caac149",
   "metadata": {},
   "source": [
    "### 2. HEAD NORMAL COORDINATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39a38fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL COORDINATE 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL COORDINATE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL COORDINATE').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL COORDINATE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "287f0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Dam'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Dam'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efb87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd662cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9fb0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0df37c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac6abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c4cf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9688a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47c86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fa789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a2e0",
   "metadata": {},
   "source": [
    "### 3. RESIN(처리x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91c64cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'RESIN' 또는 'Dispense Volume' 포함 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4652063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispense Volume(Stage1) Collect Result_Dam, Dispense Volume(Stage2) Collect Result_Dam, Dispense Volume(Stage3) Collect Result_Dam\n",
      "\n",
      "                  group  'AdNormal' count     ratio  Total\n",
      "0    (0.67, 0.26, 1.49)                 8  0.075472    106\n",
      "1    (0.67, 0.27, 1.49)               277  0.086293   3210\n",
      "2    (0.67, 0.28, 1.49)                 0  0.000000      2\n",
      "3    (0.67, 0.33, 1.49)                51  0.099415    513\n",
      "4    (0.67, 0.34, 1.49)               467  0.082276   5676\n",
      "..                  ...               ...       ...    ...\n",
      "155  (1.63, 0.92, 1.49)                41  0.048810    840\n",
      "156  (1.63, 0.93, 1.49)                46  0.080844    569\n",
      "157  (1.63, 0.94, 1.49)                34  0.068273    498\n",
      "158  (2.34, 0.71, 1.49)                 0  0.000000      1\n",
      "159  (2.34, 0.72, 1.49)                 0  0.000000      3\n",
      "\n",
      "[160 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    " 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1d5d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_time_speed_product(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         speed_col = 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Time_x_Speed_{stage}_Dam'\n",
    "#         df[new_col_name] = df[time_col] * df[speed_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_time_speed_product(train_data)\n",
    "# create_time_speed_product(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ebb3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd57994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_volume_time_ratio(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         volume_col = f'Dispense Volume({stage}) Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Volume_Time_Ratio_{stage}_Dam'\n",
    "#         df[new_col_name] = df[volume_col] / df[time_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_volume_time_ratio(train_data)\n",
    "# create_volume_time_ratio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b42b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 출력 옵션을 설정\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# # 출력 옵션을 원래대로\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df4ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# # , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "# # , 'RESIN Time_x_Speed_Stage1_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage2_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage3_Dam'\n",
    "# #  'RESIN Volume_Time_Ratio_Stage1_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage2_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage3_Dam'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6643f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "# Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "# print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "# for col in Process_Desc_col:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac6aad",
   "metadata": {},
   "source": [
    "### 4. Distance Speed Collect Result_Dam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6a2ba",
   "metadata": {},
   "source": [
    "Dam 공정의 Circle, Line 길이 변수들 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f1ca6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance Speed Collect Result_Dam 포함 변수>\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance Speed Collect Result_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance Speed Collect Result_Dam').columns\n",
    "\n",
    "print(\"\\n Distance Speed Collect Result_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ac6dc",
   "metadata": {},
   "source": [
    "Stage 별 Speed 값들의 평균 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74dc87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stage_totals(data, stages, suffix='_Distance_Speed_avg_Dam'):\n",
    "    for stage in stages:\n",
    "        stage_cols = data.filter(like=stage).columns\n",
    "        data[f'{stage}{suffix}'] = data[stage_cols].sum(axis=1) / 8\n",
    "\n",
    "stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "\n",
    "# train_data에 대해 파생변수 추가\n",
    "add_stage_totals(train_data, stages)\n",
    "\n",
    "# test_data에 대해 파생변수 추가\n",
    "add_stage_totals(test_data, stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a453df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Stage1 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d2c9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance_Speed_avg_Dam 포함 변수>\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance_Speed_avg_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance_Speed_avg_Dam').columns\n",
    "\n",
    "print(\"\\n Distance_Speed_avg_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a4274",
   "metadata": {},
   "source": [
    "### 5. THICKNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1907522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "THICKNESS 1 Collect Result_Dam\n",
      "THICKNESS 2 Collect Result_Dam\n",
      "THICKNESS 3 Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3ae04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 파생변수 생성 함수\n",
    "def create_total_thickness_dam(data):\n",
    "    data['Total_THICKNESS_Collect_Result_Dam'] = (\n",
    "        data['THICKNESS 1 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 2 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 3 Collect Result_Dam']**2\n",
    "    )\n",
    "    # 기존 변수 삭제\n",
    "    data.drop(columns=[\n",
    "        'THICKNESS 1 Collect Result_Dam',\n",
    "        'THICKNESS 2 Collect Result_Dam',\n",
    "        'THICKNESS 3 Collect Result_Dam'\n",
    "    ], inplace=True)\n",
    "    return data\n",
    "\n",
    "train_data = create_total_thickness_dam(train_data)\n",
    "test_data = create_total_thickness_dam(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af96f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "Total_THICKNESS_Collect_Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4349a",
   "metadata": {},
   "source": [
    "### 6. AutoClave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27ac3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3c024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성\n",
    "train_data['1st_Pressure_x_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure Unit Time_AutoClave'] \n",
    "test_data['1st_Pressure_x_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['2nd_Pressure_x_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave'] \n",
    "test_data['2nd_Pressure_x_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['3rd_Pressure_x_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave'] \n",
    "test_data['3rd_Pressure_x_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['All_Pressure_x_AutoClave'] = train_data['1st_Pressure_x_AutoClave'] + train_data['2nd_Pressure_x_AutoClave'] + train_data['3rd_Pressure_x_AutoClave']\n",
    "test_data['All_Pressure_x_AutoClave'] = test_data['1st_Pressure_x_AutoClave'] + test_data['2nd_Pressure_x_AutoClave'] + test_data['3rd_Pressure_x_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_avg_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['All_Pressure_avg_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['Chamber_Temp_x_AutoClave'] = train_data['Chamber Temp. Collect Result_AutoClave'] * train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['Chamber_Temp_x_AutoClave'] = test_data['Chamber Temp. Collect Result_AutoClave'] * test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber_Temp_x_AutoClave']\n",
    "test_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber_Temp_x_AutoClave']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a69ad859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "# '1st Pressure Collect Result_AutoClave'\n",
    "'1st Pressure Unit Time_AutoClave'\n",
    "# , '2nd Pressure Collect Result_AutoClave'\n",
    ", '2nd Pressure Unit Time_AutoClave'\n",
    "# , '3rd Pressure Collect Result_AutoClave'\n",
    ", '3rd Pressure Unit Time_AutoClave'\n",
    "# , 'Chamber Temp. Collect Result_AutoClave'\n",
    "# , 'Chamber Temp. Unit Time_AutoClave'\n",
    "\n",
    "# , '1st_Pressure_x_AutoClave'\n",
    "# , '2nd_Pressure_x_AutoClave'\n",
    "# , '3rd_Pressure_x_AutoClave'\n",
    ", 'All_Pressure_x_AutoClave'\n",
    "# , 'All_Pressure_avg_AutoClave'\n",
    "# , 'Chamber_Temp_x_AutoClave'\n",
    "# , 'All_Pressure_frac_Chamber_Temp_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20ce50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69dcf",
   "metadata": {},
   "source": [
    "### 7. ETC.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b05ca",
   "metadata": {},
   "source": [
    "7-1. workorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e2e4240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수를 0과 1로 변환\n",
    "train_data['target_binary'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# Workorder 변수의 값에 대한 타겟 변수 비율 계산\n",
    "workorder_target_ratio = train_data.groupby('Workorder')['target_binary'].mean()\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_derived_variable(row, ratio_dict, threshold):\n",
    "    return 1 if ratio_dict.get(row['Workorder'], 0) >= threshold else 0\n",
    "\n",
    "# 파생 변수 생성\n",
    "train_data['Workorder_0.9'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "train_data['Workorder_0.7'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "train_data['Workorder_0.5'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "test_data['Workorder_0.9'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "test_data['Workorder_0.7'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "test_data['Workorder_0.5'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['target_binary'], axis=1, inplace=True)\n",
    "\n",
    "# train_data.drop(['Workorder', 'target_binary'], axis=1, inplace=True)\n",
    "# test_data.drop(['Workorder'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48c3f8",
   "metadata": {},
   "source": [
    "7-2. Machine Tact time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d866fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 총시간 대비 비율 변수\n",
    "def calculate_total_time_and_ratios(data):\n",
    "    data['total_time'] = (\n",
    "        data['Machine Tact time Collect Result_Dam'] +\n",
    "        data['Machine Tact time Collect Result_Fill1'] +\n",
    "        data['Machine Tact time Collect Result_Fill2'] +\n",
    "        data['Chamber Temp. Unit Time_AutoClave']\n",
    "    )\n",
    "    data['time_ratio_Dam'] = (data['Machine Tact time Collect Result_Dam'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill1'] = (data['Machine Tact time Collect Result_Fill1'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill2'] = (data['Machine Tact time Collect Result_Fill2'] / data['total_time']).round(3)\n",
    "    data['time_ratio_AutoClave'] = (data['Chamber Temp. Unit Time_AutoClave'] / data['total_time']).round(3)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 함수 적용\n",
    "train_data = calculate_total_time_and_ratios(train_data)\n",
    "test_data = calculate_total_time_and_ratios(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dec2a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 제거\n",
    "train_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)\n",
    "\n",
    "test_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49a7d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  object \n",
      " 1   Workorder                                              40506 non-null  object \n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(46), int64(14), object(3)\n",
      "memory usage: 19.5+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "769e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b20a3",
   "metadata": {},
   "source": [
    "## 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb37ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model.Suffix', 'Workorder', 'target'], dtype='object')  train_object_columns 갯수 : 3\n",
      "Index(['Set ID', 'Model.Suffix', 'Workorder', 'target'], dtype='object')  test_object_columns 갯수 : 4\n",
      "\n",
      "Train Data:\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 663\n",
      "target unique 값 갯수: 2\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 662\n",
      "target unique 값 갯수: 0\n"
     ]
    }
   ],
   "source": [
    "# 'target' 열의 변수 타입을 object로 변경\n",
    "# -> test 데이터는 float64 타입으로 되어있음 \n",
    "test_data['target'] = test_data['target'].astype('object')\n",
    "\n",
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "156c68be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model.Suffix  Workorder\n",
      "0      0.049336   0.158385\n",
      "1      0.049336   0.015314\n",
      "2      0.056712   0.009534\n",
      "   Model.Suffix  Workorder\n",
      "0      0.056712   0.091912\n",
      "1      0.056712   0.024247\n",
      "2      0.056712   0.091463\n",
      "--- train_data ---\n",
      "target  \n",
      "Normal      38156\n",
      "AbNormal     2350\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# 타겟 변수와 범주형 변수 지정\n",
    "## Target Encoding의 smoothing 파라미터는 default로 auto로 설정되어 있음\n",
    "target = 'target'  # 타겟 변수 이름으로 변경\n",
    "categorical_columns = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "]  # 범주형 변수 이름으로 변경\n",
    "\n",
    "# 타겟 값을 숫자로 변환\n",
    "target_mapping = {'Normal': 0, 'AbNormal': 1}\n",
    "train_data[target] = train_data[target].map(target_mapping)\n",
    "test_data[target] = test_data[target].map(target_mapping)\n",
    "\n",
    "# 열이 존재하는지 확인\n",
    "missing_columns = [col for col in categorical_columns if col not in train_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"train_data에 다음 열이 존재하지 않습니다: {missing_columns}\")\n",
    "\n",
    "# 타겟 인코더 생성 및 학습\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "train_data = encoder.fit_transform(train_data, train_data[target])\n",
    "\n",
    "# Set ID 열을 별도로 저장\n",
    "set_id = test_data['Set ID']\n",
    "\n",
    "# 테스트 데이터 인코딩 (Set ID 열 제외)\n",
    "test_data = test_data.drop(columns=['Set ID'])\n",
    "test_data = encoder.transform(test_data)\n",
    "\n",
    "# Set ID 열을 맨 앞에 추가\n",
    "test_data.insert(0, 'Set ID', set_id)\n",
    "\n",
    "# categorical_columns에 해당하는 열의 데이터 값만 확인\n",
    "print(train_data[categorical_columns].head(3))\n",
    "print(test_data[categorical_columns].head(3))\n",
    "\n",
    "# 역 매핑 딕셔너리 생성\n",
    "reverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "# 타겟 값을 원래대로 변환\n",
    "train_data[target] = train_data[target].map(reverse_target_mapping)\n",
    "test_data[target] = test_data[target].map(reverse_target_mapping)\n",
    "\n",
    "print(\"--- train_data ---\")\n",
    "\n",
    "# 변환된 타겟 값 확인\n",
    "print(train_data[[target]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a108490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(48), int64(14), object(1)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276e6df",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee950d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(\"target\", axis=1),\n",
    "    train_data[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de8996fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "def print_stats(df: pd.DataFrame):\n",
    "    num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "    num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "    print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  \\tAbnormal\\tNormal\")\n",
    "print_stats(df_train)\n",
    "print_stats(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1771a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(48), int64(14), object(1)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519265e7",
   "metadata": {},
   "source": [
    "공통 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67dbaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_variables = [\n",
    "    'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[com_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf966448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Variable 1               Variable 2  Correlation\n",
      "0              Dispenser_2  PalletID_Collect_Result     0.860274\n",
      "1  PalletID_Collect_Result              Dispenser_2     0.860274\n",
      "2            Workorder_0.9            Workorder_0.7     0.747407\n",
      "3            Workorder_0.7            Workorder_0.9     0.747407\n",
      "4            Workorder_0.7            Workorder_0.5     0.816325\n",
      "5            Workorder_0.5            Workorder_0.7     0.816325\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "105fe344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 삭제\n",
    "train_data.drop(['Workorder_0.7', 'PalletID_Collect_Result'], axis=1, inplace=True)\n",
    "test_data.drop(['Workorder_0.7', 'PalletID_Collect_Result'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "807ffaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 변수 리스트\n",
    "com_variables_train = [\n",
    "    'target'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    # , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]\n",
    "\n",
    "com_variables_test = [\n",
    "    'target'\n",
    "    , 'Set ID'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    # , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b5911a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dam 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "Head Clean Position Z Collect Result_Dam\n",
      "Head Purge Position Z Collect Result_Dam\n",
      "Head Zero Position Y Collect Result_Dam\n",
      "Head Zero Position Z Collect Result_Dam\n",
      "CURE_Time_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n",
      "Total_THICKNESS_Collect_Result_Dam\n",
      "time_ratio_Dam\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Dam 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d01ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\",\n",
    "    # \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\",\n",
    "    # \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Dam\",\n",
    "    # \"Dispense Volume(Stage3) Collect Result_Dam\",\n",
    "    \"Head Clean Position Z Collect Result_Dam\",\n",
    "    \"Head Purge Position Z Collect Result_Dam\",\n",
    "    \"Head Zero Position Y Collect Result_Dam\",\n",
    "    # \"Head Zero Position Z Collect Result_Dam\",\n",
    "    \"CURE_Time_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\",\n",
    "    # \"HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\",\n",
    "    \"Stage1_Distance_Speed_avg_Dam\",\n",
    "    \"Stage2_Distance_Speed_avg_Dam\",\n",
    "    # \"Stage3_Distance_Speed_avg_Dam\",\n",
    "    \"Total_THICKNESS_Collect_Result_Dam\",\n",
    "    \"time_ratio_Dam\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "749bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Dam\",\n",
    "    \"Head Zero Position Z Collect Result_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\",\n",
    "    \"Stage3_Distance_Speed_avg_Dam\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c4d0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f80651a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n",
      "time_ratio_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "566073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"1st Pressure Collect Result_AutoClave\",\n",
    "    \"2nd Pressure Collect Result_AutoClave\",\n",
    "    \"3rd Pressure Collect Result_AutoClave\",\n",
    "    \"Chamber Temp. Collect Result_AutoClave\",\n",
    "    \"Chamber_Temp_OKNG_AutoClave\",\n",
    "    \"1st_Pressure_x_AutoClave\",\n",
    "    # \"2nd_Pressure_x_AutoClave\",\n",
    "    \"3rd_Pressure_x_AutoClave\",\n",
    "    \"All_Pressure_avg_AutoClave\",\n",
    "    \"Chamber_Temp_x_AutoClave\",\n",
    "    \"All_Pressure_frac_Chamber_Temp_AutoClave\",\n",
    "    \"time_ratio_AutoClave\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fff17e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"2nd_Pressure_x_AutoClave\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebdcf265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a03bc6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n",
      "Head Purge Position Z Collect Result_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "time_ratio_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill1').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fa145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\",\n",
    "    # \"Dispense Volume(Stage1) Collect Result_Fill1\",\n",
    "    # \"Dispense Volume(Stage2) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Fill1\",\n",
    "    \"Head Purge Position Z Collect Result_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\",\n",
    "    # \"HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\",\n",
    "    \"time_ratio_Fill1\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e63aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Fill1\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b8ac77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04ce5f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "Head Purge Position Z Collect Result_Fill2\n",
      "CURE_Time_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n",
      "time_ratio_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill2').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfb13c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"Head Purge Position Z Collect Result_Fill2\",\n",
    "    \"CURE_Time_Fill2\",\n",
    "    # \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\",\n",
    "    # \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\",\n",
    "    \"time_ratio_Fill2\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7c533e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31aa87df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84f9c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dam 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "20e341d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill1 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Fill1').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d32ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill2 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Fill2').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fed0e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "### autoclave 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb9e8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred_proba, threshold=0.5):\n",
    "    # 확률을 기준으로 예측 레이블 생성\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)  # 0.5 이상의 확률을 양성으로 간주\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f28f07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e56224",
   "metadata": {},
   "source": [
    "optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ec04f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "# train_data['target'] = train_data['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 300, 5000),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 300, 4000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "#         'boosting': 'dart',  # dart 사용\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         'verbose': -1\n",
    "#     }\n",
    "       \n",
    "#     model = LGBMClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),\n",
    "#     train_data[\"target\"],\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=3000)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0d6d6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 정의\n",
    "# class_weights = {1: 1, 0: 5}  # 클래스의 비율에 따라 가중치 설정\n",
    "\n",
    "model_Dam = LGBMClassifier(\n",
    "    n_estimators=518\n",
    "    , num_leaves=2015\n",
    "    , max_depth=162\n",
    "    , learning_rate=0.06100652301906989\n",
    "    , min_child_samples=27\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_AutoClave = LGBMClassifier(\n",
    "    n_estimators=369\n",
    "    , num_leaves=1209\n",
    "    , max_depth=126\n",
    "    , learning_rate=0.08949706539380033\n",
    "    , min_child_samples=49\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_Fill1 = LGBMClassifier(\n",
    "    n_estimators=1087\n",
    "    , num_leaves=2329\n",
    "    , max_depth=142\n",
    "    , learning_rate=0.04621450707732194\n",
    "    , min_child_samples=8\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_Fill2 = LGBMClassifier(\n",
    "    n_estimators=1676\n",
    "    , num_leaves=2424\n",
    "    , max_depth=203\n",
    "    , learning_rate=0.019539999107710395\n",
    "    , min_child_samples=34\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1072be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dam, df_val_dam = train_test_split(\n",
    "    train_data_dam,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_fill1, df_val_fill1 = train_test_split(\n",
    "    train_data_fill1,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_fill2, df_val_fill2 = train_test_split(\n",
    "    train_data_fill2,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_autoclave, df_val_autoclave = train_test_split(\n",
    "    train_data_autoclave,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "abdfcbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.06100652301906989,\n",
       "               max_depth=162, min_child_samples=27, n_estimators=518,\n",
       "               num_leaves=2015, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_dam 데이터로 학습\n",
    "df_train_dam[\"target\"] = df_train_dam[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# features = df_train.columns.tolist()\n",
    "\n",
    "train_x = df_train_dam.drop(columns=[\"target\"])\n",
    "train_y = df_train_dam[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9343b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.04621450707732194,\n",
       "               max_depth=142, min_child_samples=8, n_estimators=1087,\n",
       "               num_leaves=2329, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_fill1 데이터로 학습\n",
    "df_train_fill1[\"target\"] = df_train_fill1[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# features = df_train.columns.tolist()\n",
    "\n",
    "train_x = df_train_fill1.drop(columns=[\"target\"])\n",
    "train_y = df_train_fill1[\"target\"]\n",
    "\n",
    "model_Fill1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "865d9538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.019539999107710395,\n",
       "               max_depth=203, min_child_samples=34, n_estimators=1676,\n",
       "               num_leaves=2424, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_fill2 데이터로 학습\n",
    "df_train_fill2[\"target\"] = df_train_fill2[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# features = df_train.columns.tolist()\n",
    "\n",
    "train_x = df_train_fill2.drop(columns=[\"target\"])\n",
    "train_y = df_train_fill2[\"target\"]\n",
    "\n",
    "model_Fill2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f7f2b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.08949706539380033,\n",
       "               max_depth=126, min_child_samples=49, n_estimators=369,\n",
       "               num_leaves=1209, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_autoclave 데이터로 학습\n",
    "df_train_autoclave[\"target\"] = df_train_autoclave[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# features = df_train.columns.tolist()\n",
    "\n",
    "train_x = df_train_autoclave.drop(columns=[\"target\"])\n",
    "train_y = df_train_autoclave[\"target\"]\n",
    "\n",
    "model_AutoClave.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6cf259cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7557   75]\n",
      " [ 415   55]]\n",
      "Accuracy: 0.9395\n",
      "Precision: 0.4231\n",
      "Recall: 0.1170\n",
      "F1 Score: 0.1833\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 준비\n",
    "df_val_dam[\"target\"] = df_val_dam[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "val_x_dam = df_val_dam.drop(columns=[\"target\"])\n",
    "val_y_dam = df_val_dam[\"target\"]\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_dam = model_Dam.predict_proba(val_x_dam)[:, 1]  # 양성 클래스에 대한 확률\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y_dam, y_pred_dam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dff66fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7503  129]\n",
      " [ 407   63]]\n",
      "Accuracy: 0.9338\n",
      "Precision: 0.3281\n",
      "Recall: 0.1340\n",
      "F1 Score: 0.1903\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 준비\n",
    "df_val_fill1[\"target\"] = df_val_fill1[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "val_x_fill1 = df_val_fill1.drop(columns=[\"target\"])\n",
    "val_y_fill1 = df_val_fill1[\"target\"]\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_fill1 = model_Fill1.predict_proba(val_x_fill1)[:, 1]  # 양성 클래스에 대한 확률\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y_fill1, y_pred_fill1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "76bf99c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7567   65]\n",
      " [ 410   60]]\n",
      "Accuracy: 0.9414\n",
      "Precision: 0.4800\n",
      "Recall: 0.1277\n",
      "F1 Score: 0.2017\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 준비\n",
    "df_val_fill2[\"target\"] = df_val_fill2[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "val_x_fill2 = df_val_fill2.drop(columns=[\"target\"])\n",
    "val_y_fill2 = df_val_fill2[\"target\"]\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_fill2 = model_Fill2.predict_proba(val_x_fill2)[:, 1]  # 양성 클래스에 대한 확률\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y_fill2, y_pred_fill2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1bd0121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7524  108]\n",
      " [ 406   64]]\n",
      "Accuracy: 0.9366\n",
      "Precision: 0.3721\n",
      "Recall: 0.1362\n",
      "F1 Score: 0.1994\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 준비\n",
    "df_val_autoclave[\"target\"] = df_val_autoclave[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "val_x_autoclave = df_val_autoclave.drop(columns=[\"target\"])\n",
    "val_y_autoclave = df_val_autoclave[\"target\"]\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_autoclave = model_AutoClave.predict_proba(val_x_autoclave)[:, 1]  # 양성 클래스에 대한 확률\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y_autoclave, y_pred_autoclave)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990d2c7",
   "metadata": {},
   "source": [
    "분할한 데이터 -> 원래의 데이터(train data)로 학습한 새 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fedb270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.06100652301906989,\n",
       "               max_depth=162, min_child_samples=27, n_estimators=518,\n",
       "               num_leaves=2015, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_dam 데이터로 학습\n",
    "train_data_dam[\"target\"] = train_data_dam[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "train_x_all_dam = train_data_dam.drop(columns=[\"target\"])\n",
    "train_y_all_dam = train_data_dam[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x_all_dam, train_y_all_dam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48bdb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.04621450707732194,\n",
       "               max_depth=142, min_child_samples=8, n_estimators=1087,\n",
       "               num_leaves=2329, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_fill1 데이터로 학습\n",
    "train_data_fill1[\"target\"] = train_data_fill1[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "train_x_all_fill1 = train_data_fill1.drop(columns=[\"target\"])\n",
    "train_y_all_fill1 = train_data_fill1[\"target\"]\n",
    "\n",
    "model_Fill1.fit(train_x_all_fill1, train_y_all_fill1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c0e05f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.019539999107710395,\n",
       "               max_depth=203, min_child_samples=34, n_estimators=1676,\n",
       "               num_leaves=2424, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_fill2 데이터로 학습\n",
    "train_data_fill2[\"target\"] = train_data_fill2[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "train_x_all_fill2 = train_data_fill2.drop(columns=[\"target\"])\n",
    "train_y_all_fill2 = train_data_fill2[\"target\"]\n",
    "\n",
    "model_Fill2.fit(train_x_all_fill2, train_y_all_fill2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7858df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.08949706539380033,\n",
       "               max_depth=126, min_child_samples=49, n_estimators=369,\n",
       "               num_leaves=1209, random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_autoclave 데이터로 학습\n",
    "train_data_autoclave[\"target\"] = train_data_autoclave[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "train_x_all_autoclave = train_data_autoclave.drop(columns=[\"target\"])\n",
    "train_y_all_autoclave = train_data_autoclave[\"target\"]\n",
    "\n",
    "model_AutoClave.fit(train_x_all_autoclave, train_y_all_autoclave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ed6558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 확률\n",
    "probs_dam = model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "probs_fill1 = model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "probs_fill2 = model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "probs_autoclave = model_AutoClave.predict_proba(x_test_autoclave)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "825c4a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145\n"
     ]
    }
   ],
   "source": [
    "# 스레스 홀드 설정\n",
    "threshold = 0.35\n",
    "\n",
    "# 예측 확률과 스레스 홀드 비교하여 1 또는 0 부여\n",
    "preds_dam = (probs_dam > threshold).astype(int)\n",
    "preds_fill1 = (probs_fill1 > threshold).astype(int)\n",
    "preds_fill2 = (probs_fill2 > threshold).astype(int)\n",
    "preds_autoclave = (probs_autoclave > threshold).astype(int)\n",
    "\n",
    "# 하나라도 스레스 홀드보다 높은 경우 1 부여\n",
    "all_preds = (preds_dam | preds_fill1 | preds_fill2 | preds_autoclave).astype(int)\n",
    "\n",
    "# 테스트 데이터에서 AbNormal로 예측된 개수 출력\n",
    "print(sum(all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea13ac4",
   "metadata": {},
   "source": [
    "Public Score : 0.22407407407407406"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = all_preds\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      16216\n",
       "AbNormal     1145\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9efee1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID    target\n",
       "0  0001be084fbc4aaa9d921f39e595961b    Normal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80    Normal\n",
       "2  000948934c4140d883d670adcb609584    Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7    Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95    Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2    Normal\n",
       "6  0020734a7b29472298358ad58645a0c9    Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135    Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  AbNormal\n",
       "9  002d904240d84b188d410d16383a9c3a    Normal"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
