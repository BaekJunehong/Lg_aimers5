{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbb1c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "db27ac9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 119 entries, Model.Suffix to Dispenser_num\n",
      "dtypes: float64(58), int64(51), object(10)\n",
      "memory usage: 36.8+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "9da11d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 120 entries, Set ID to Dispenser_num\n",
      "dtypes: float64(94), int64(16), object(10)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# train_data.info()\n",
    "print('---')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b91e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1412a",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "cf740cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam      29213\n",
      "WorkMode Collect Result_Dam                                24059\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave       29213\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave          29213\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1    29213\n",
      "WorkMode Collect Result_Fill1                              24059\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2    29213\n",
      "WorkMode Collect Result_Fill2                              24059\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a84e3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "OK    11293\n",
      "Name: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam, dtype: int64\n",
      "\n",
      "\n",
      "Column: WorkMode Collect Result_Dam\n",
      "7.0    16447\n",
      "Name: WorkMode Collect Result_Dam, dtype: int64\n",
      "\n",
      "\n",
      "Column: GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave\n",
      "OK    11293\n",
      "Name: GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave, dtype: int64\n",
      "\n",
      "\n",
      "Column: GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave\n",
      "OK    11293\n",
      "Name: GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave, dtype: int64\n",
      "\n",
      "\n",
      "Column: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1\n",
      "OK    11293\n",
      "Name: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1, dtype: int64\n",
      "\n",
      "\n",
      "Column: WorkMode Collect Result_Fill1\n",
      "7.0    16447\n",
      "Name: WorkMode Collect Result_Fill1, dtype: int64\n",
      "\n",
      "\n",
      "Column: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2\n",
      "OK    11293\n",
      "Name: HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2, dtype: int64\n",
      "\n",
      "\n",
      "Column: WorkMode Collect Result_Fill2\n",
      "0.0    16447\n",
      "Name: WorkMode Collect Result_Fill2, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측값이 존재하는 변수들의 value_counts 계산\n",
    "for column in missing_columns:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(train_data[column].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "640d3090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "드롭할 변수명:\n",
      "['HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam', 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave']\n",
      "['GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave', 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1']\n",
      "['HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2']\n"
     ]
    }
   ],
   "source": [
    "# \"OK\" 값을 가진 변수를 찾고 제거\n",
    "columns_to_drop = [column for column in missing_columns if train_data[column].apply(lambda x: np.any(x == \"OK\")).any()]\n",
    "\n",
    "# 드롭할 변수명 출력 (한 줄에 2개씩)\n",
    "print(\"드롭할 변수명:\")\n",
    "for i in range(0, len(columns_to_drop), 2):\n",
    "    print(columns_to_drop[i:i+2])\n",
    "\n",
    "# 변수 드롭\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "9fa36a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkMode Collect Result_Dam      24059\n",
      "WorkMode Collect Result_Fill1    24059\n",
      "WorkMode Collect Result_Fill2    24059\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "5d4d04c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                                                     AbNormal    Normal\n",
      "WorkMode Collect Result_Dam WorkMode Collect Result_Fill2                    \n",
      "7.0                         0.0                            0.073326  0.926674\n"
     ]
    }
   ],
   "source": [
    "# 그룹화할 변수들\n",
    "groupby_columns = [\n",
    "    \"WorkMode Collect Result_Dam\"\n",
    "    , \"WorkMode Collect Result_Fill2\"\n",
    "    ]\n",
    "\n",
    "# 그룹화하여 target 변수 값의 비율을 계산\n",
    "grouped = train_data.groupby(groupby_columns)[\"target\"].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# 결과 출력\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "b4cab4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "349653f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "d1e3724b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10349\n",
       "1.0     7012\n",
       "Name: WorkMode Collect Result, dtype: int64"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['WorkMode Collect Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "90fbb6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n",
      "결측값이 존재하는 변수명: []\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "85b9d49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target    17361\n",
      "dtype: int64\n",
      "결측값이 존재하는 변수명: ['target']\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = test_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ac234b",
   "metadata": {},
   "source": [
    "### 문자형(object) 변수 -> 수치형 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "b1f0fd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      38156\n",
       "AbNormal     2350\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "653350fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 112 entries, Model.Suffix to Dispenser_num\n",
      "dtypes: float64(56), int64(51), object(5)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b0505b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(test_data['target'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896131a9",
   "metadata": {},
   "source": [
    "### 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "eebeda92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model.Suffix', 'Workorder', 'Chamber Temp. Judge Value_AutoClave',\n",
      "       'target', 'Dispenser_num'],\n",
      "      dtype='object')  train_object_columns 갯수 : 5\n",
      "Index(['Set ID', 'Model.Suffix', 'Workorder',\n",
      "       'Chamber Temp. Judge Value_AutoClave', 'target', 'Dispenser_num'],\n",
      "      dtype='object')  test_object_columns 갯수 : 6\n",
      "\n",
      "Train Data:\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 663\n",
      "Chamber Temp. Judge Value_AutoClave unique 값 갯수: 2\n",
      "target unique 값 갯수: 2\n",
      "Dispenser_num unique 값 갯수: 3\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 662\n",
      "Chamber Temp. Judge Value_AutoClave unique 값 갯수: 2\n",
      "target unique 값 갯수: 0\n",
      "Dispenser_num unique 값 갯수: 3\n"
     ]
    }
   ],
   "source": [
    "# 'target' 열의 변수 타입을 object로 변경\n",
    "# -> test 데이터는 float64 타입으로 되어있음 \n",
    "test_data['target'] = test_data['target'].astype('object')\n",
    "\n",
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "4af20ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model.Suffix  Workorder  Chamber Temp. Judge Value_AutoClave  Dispenser_num\n",
      "0      0.049336   0.158385                             0.058361       0.058614\n",
      "1      0.049336   0.015314                             0.058361       0.058614\n",
      "2      0.056712   0.009534                             0.058361       0.054977\n",
      "   Model.Suffix  Workorder  Chamber Temp. Judge Value_AutoClave  Dispenser_num\n",
      "0      0.056712   0.091912                             0.058361       0.054977\n",
      "1      0.056712   0.024247                             0.058361       0.054977\n",
      "2      0.056712   0.091463                             0.058361       0.058614\n",
      "--- train_data ---\n",
      "target  \n",
      "Normal      38156\n",
      "AbNormal     2350\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# 타겟 변수와 범주형 변수 지정\n",
    "## Target Encoding의 smoothing 파라미터는 default로 auto로 설정되어 있음\n",
    "target = 'target'  # 타겟 변수 이름으로 변경\n",
    "categorical_columns = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "    'Chamber Temp. Judge Value_AutoClave',\n",
    "    'Dispenser_num'\n",
    "\n",
    "]  # 범주형 변수 이름으로 변경\n",
    "\n",
    "# 타겟 값을 숫자로 변환\n",
    "target_mapping = {'Normal': 0, 'AbNormal': 1}\n",
    "train_data[target] = train_data[target].map(target_mapping)\n",
    "test_data[target] = test_data[target].map(target_mapping)\n",
    "\n",
    "# 열이 존재하는지 확인\n",
    "missing_columns = [col for col in categorical_columns if col not in train_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"train_data에 다음 열이 존재하지 않습니다: {missing_columns}\")\n",
    "\n",
    "# 타겟 인코더 생성 및 학습\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "train_data = encoder.fit_transform(train_data, train_data[target])\n",
    "\n",
    "# Set ID 열을 별도로 저장\n",
    "set_id = test_data['Set ID']\n",
    "\n",
    "# 테스트 데이터 인코딩 (Set ID 열 제외)\n",
    "test_data = test_data.drop(columns=['Set ID'])\n",
    "test_data = encoder.transform(test_data)\n",
    "\n",
    "# Set ID 열을 맨 앞에 추가\n",
    "test_data.insert(0, 'Set ID', set_id)\n",
    "\n",
    "# categorical_columns에 해당하는 열의 데이터 값만 확인\n",
    "print(train_data[categorical_columns].head(3))\n",
    "print(test_data[categorical_columns].head(3))\n",
    "\n",
    "# 역 매핑 딕셔너리 생성\n",
    "reverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "# 타겟 값을 원래대로 변환\n",
    "train_data[target] = train_data[target].map(reverse_target_mapping)\n",
    "test_data[target] = test_data[target].map(reverse_target_mapping)\n",
    "\n",
    "print(\"--- train_data ---\")\n",
    "\n",
    "# 변환된 타겟 값 확인\n",
    "print(train_data[[target]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "17e56874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 112 entries, Model.Suffix to Dispenser_num\n",
      "dtypes: float64(60), int64(51), object(1)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "c06bcb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 113 entries, Set ID to Dispenser_num\n",
      "dtypes: float64(95), int64(16), object(2)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9921acc",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "2fd8eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dam Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "AutoClave Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "Fill1 Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "Fill2 Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# '_Dam', '_AutoClave', '_Fill1', '_Fill2'를 포함하는 열 이름 필터링 함수\n",
    "def filter_columns(df, is_test=False):\n",
    "    dam_columns = df.filter(like='_Dam').columns.tolist()\n",
    "    autoclave_columns = df.filter(like='_AutoClave').columns.tolist()\n",
    "    fill1_columns = df.filter(like='_Fill1').columns.tolist()\n",
    "    fill2_columns = df.filter(like='_Fill2').columns.tolist()\n",
    "\n",
    "    # 추가적으로 불러올 열 이름\n",
    "    additional_cols = ['Model.Suffix', 'Workorder', 'target', 'Dispenser_num']\n",
    "    if is_test:\n",
    "        additional_cols.append('Set ID')\n",
    "\n",
    "    # 각 그룹별로 새로운 데이터프레임 생성\n",
    "    df_dam = df[dam_columns + additional_cols]\n",
    "    df_autoclave = df[autoclave_columns + additional_cols]\n",
    "    df_fill1 = df[fill1_columns + additional_cols]\n",
    "    df_fill2 = df[fill2_columns + additional_cols]\n",
    "\n",
    "    return df_dam, df_autoclave, df_fill1, df_fill2\n",
    "\n",
    "# train_data에 적용\n",
    "df_train_dam, df_train_autoclave, df_train_fill1, df_train_fill2 = filter_columns(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "df_test_dam, df_test_autoclave, df_test_fill1, df_test_fill2 = filter_columns(test_data, is_test=True)\n",
    "\n",
    "# 데이터 분할 및 통계 출력 함수\n",
    "def split_and_print_stats(df, name):\n",
    "    df_train, df_val = train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        stratify=df[\"target\"],\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    def print_stats(df: pd.DataFrame):\n",
    "        num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "        num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "        print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "    # 통계 출력\n",
    "    print(f\"{name} Columns:\")\n",
    "    print(f\"  \\tAbnormal\\tNormal\")\n",
    "    print_stats(df_train)\n",
    "    print_stats(df_val)\n",
    "\n",
    "    return df_train, df_val\n",
    "\n",
    "# 각 데이터프레임에 대해 데이터 분할 및 통계 출력\n",
    "df_train_dam_split, df_val_dam_split = split_and_print_stats(df_train_dam, \"Dam\")\n",
    "df_train_autoclave_split, df_val_autoclave_split = split_and_print_stats(df_train_autoclave, \"AutoClave\")\n",
    "df_train_fill1_split, df_val_fill1_split = split_and_print_stats(df_train_fill1, \"Fill1\")\n",
    "df_train_fill2_split, df_val_fill2_split = split_and_print_stats(df_train_fill2, \"Fill2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0f960",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "27f29a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred=None):\n",
    "    confusion = confusion_matrix(y_test, y_pred, labels=[True, False])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, labels=[True, False])\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred, labels=[True, False])\n",
    "    weighted_F1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    metrics = pd.DataFrame({\n",
    "        '정확도': [accuracy],\n",
    "        '정밀도': [precision],\n",
    "        '재현율': [recall],\n",
    "        'F1 Score': [F1],\n",
    "        'Weighted F1': [weighted_F1]\n",
    "    })\n",
    "\n",
    "    confusion_df = pd.DataFrame(confusion, index=['True', 'False'], columns=['True', 'False'])\n",
    "\n",
    "    print(\"\\n오차행렬:\")\n",
    "    display(confusion_df)\n",
    "    print(\"평가 지표:\")\n",
    "    display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aab8ce",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "1f0f76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dam = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "model_AutoClave = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "model_Fill1 = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "model_Fill2 = RandomForestClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27dca27",
   "metadata": {},
   "source": [
    "### 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "983bdedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32404 entries, 24811 to 12593\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                                    Non-Null Count  Dtype  \n",
      "---  ------                                                    --------------  -----  \n",
      " 0   CURE END POSITION X Collect Result_Dam                    32404 non-null  int64  \n",
      " 1   CURE END POSITION Z Collect Result_Dam                    32404 non-null  float64\n",
      " 2   CURE END POSITION Θ Collect Result_Dam                    32404 non-null  int64  \n",
      " 3   CURE SPEED Collect Result_Dam                             32404 non-null  int64  \n",
      " 4   CURE START POSITION X Collect Result_Dam                  32404 non-null  int64  \n",
      " 5   CURE START POSITION Θ Collect Result_Dam                  32404 non-null  int64  \n",
      " 6   DISCHARGED SPEED OF RESIN Collect Result_Dam              32404 non-null  int64  \n",
      " 7   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam       32404 non-null  float64\n",
      " 8   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam       32404 non-null  float64\n",
      " 9   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam       32404 non-null  float64\n",
      " 10  Dispense Volume(Stage1) Collect Result_Dam                32404 non-null  float64\n",
      " 11  Dispense Volume(Stage2) Collect Result_Dam                32404 non-null  float64\n",
      " 12  Dispense Volume(Stage3) Collect Result_Dam                32404 non-null  float64\n",
      " 13  HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam  32404 non-null  float64\n",
      " 14  HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam  32404 non-null  float64\n",
      " 15  HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam  32404 non-null  float64\n",
      " 16  HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam  32404 non-null  float64\n",
      " 17  HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam  32404 non-null  float64\n",
      " 18  HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam  32404 non-null  float64\n",
      " 19  HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam  32404 non-null  float64\n",
      " 20  HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam  32404 non-null  float64\n",
      " 21  HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam  32404 non-null  float64\n",
      " 22  Head Clean Position Z Collect Result_Dam                  32404 non-null  float64\n",
      " 23  Head Purge Position Z Collect Result_Dam                  32404 non-null  float64\n",
      " 24  Head Zero Position Y Collect Result_Dam                   32404 non-null  float64\n",
      " 25  Head Zero Position Z Collect Result_Dam                   32404 non-null  float64\n",
      " 26  Machine Tact time Collect Result_Dam                      32404 non-null  float64\n",
      " 27  PalletID Collect Result_Dam                               32404 non-null  int64  \n",
      " 28  Production Qty Collect Result_Dam                         32404 non-null  int64  \n",
      " 29  Receip No Collect Result_Dam                              32404 non-null  int64  \n",
      " 30  Stage1 Circle1 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 31  Stage1 Circle2 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 32  Stage1 Circle3 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 33  Stage1 Circle4 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 34  Stage1 Line1 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 35  Stage1 Line2 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 36  Stage1 Line3 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 37  Stage1 Line4 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 38  Stage2 Circle1 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 39  Stage2 Circle2 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 40  Stage2 Circle3 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 41  Stage2 Circle4 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 42  Stage2 Line1 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 43  Stage2 Line2 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 44  Stage2 Line3 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 45  Stage2 Line4 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 46  Stage3 Circle1 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 47  Stage3 Circle2 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 48  Stage3 Circle3 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 49  Stage3 Circle4 Distance Speed Collect Result_Dam          32404 non-null  int64  \n",
      " 50  Stage3 Line1 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 51  Stage3 Line2 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 52  Stage3 Line3 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 53  Stage3 Line4 Distance Speed Collect Result_Dam            32404 non-null  int64  \n",
      " 54  THICKNESS 1 Collect Result_Dam                            32404 non-null  float64\n",
      " 55  THICKNESS 2 Collect Result_Dam                            32404 non-null  float64\n",
      " 56  THICKNESS 3 Collect Result_Dam                            32404 non-null  float64\n",
      " 57  Model.Suffix                                              32404 non-null  float64\n",
      " 58  Workorder                                                 32404 non-null  float64\n",
      " 59  target                                                    32404 non-null  object \n",
      " 60  Dispenser_num                                             32404 non-null  float64\n",
      "dtypes: float64(27), int64(33), object(1)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_dam_split.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "bfcbd3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CURE END POSITION X Collect Result_Dam',\n",
       " 'CURE END POSITION Z Collect Result_Dam',\n",
       " 'CURE END POSITION Θ Collect Result_Dam',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'CURE START POSITION X Collect Result_Dam',\n",
       " 'CURE START POSITION Θ Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage1) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage2) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Head Zero Position Z Collect Result_Dam',\n",
       " 'Machine Tact time Collect Result_Dam',\n",
       " 'PalletID Collect Result_Dam',\n",
       " 'Production Qty Collect Result_Dam',\n",
       " 'Receip No Collect Result_Dam',\n",
       " 'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
       " 'THICKNESS 1 Collect Result_Dam',\n",
       " 'THICKNESS 2 Collect Result_Dam',\n",
       " 'THICKNESS 3 Collect Result_Dam',\n",
       " 'Model.Suffix',\n",
       " 'Workorder',\n",
       " 'target',\n",
       " 'Dispenser_num']"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_dam.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "58080396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dam Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "AutoClave Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "Fill1 Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n",
      "Fill2 Columns:\n",
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "df_train_dam_split, df_val_dam_split = split_and_print_stats(df_train_dam, \"Dam\")\n",
    "df_train_autoclave_split, df_val_autoclave_split = split_and_print_stats(df_train_autoclave, \"AutoClave\")\n",
    "df_train_fill1_split, df_val_fill1_split = split_and_print_stats(df_train_fill1, \"Fill1\")\n",
    "df_train_fill2_split, df_val_fill2_split = split_and_print_stats(df_train_fill2, \"Fill2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "dcf2a7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_dam_split.columns:\n",
    "    try:\n",
    "        df_train_dam_split[col] = df_train_dam_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_dam_split[features]\n",
    "train_y = df_train_dam_split[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "53cb99be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_autoclave_split.columns:\n",
    "    try:\n",
    "        df_train_autoclave_split[col] = df_train_autoclave_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_autoclave_split[features]\n",
    "train_y = df_train_autoclave_split[\"target\"]\n",
    "\n",
    "model_AutoClave.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "5b4bc0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_fill1_split.columns:\n",
    "    try:\n",
    "        df_train_fill1_split[col] = df_train_fill1_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_fill1_split[features]\n",
    "train_y = df_train_fill1_split[\"target\"]\n",
    "\n",
    "model_Fill1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "82887dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_fill2_split.columns:\n",
    "    try:\n",
    "        df_train_fill2_split[col] = df_train_fill2_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_fill2_split[features]\n",
    "train_y = df_train_fill2_split[\"target\"]\n",
    "\n",
    "model_Fill2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "cf15b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오차행렬:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>427</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7310</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True    427     43\n",
       "False  7310    322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 지표:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092446</td>\n",
       "      <td>0.055189</td>\n",
       "      <td>0.908511</td>\n",
       "      <td>0.104058</td>\n",
       "      <td>0.081895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        정확도       정밀도       재현율  F1 Score  Weighted F1\n",
       "0  0.092446  0.055189  0.908511  0.104058     0.081895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_val에서 y_val과 x_val 추출\n",
    "y_val = df_val_dam_split['target'] \n",
    "x_val = df_val_dam_split.drop(columns=['target']) \n",
    "\n",
    "# y_val 레이블을 정수로 변환\n",
    "y_val_int = [1 if label == 'AbNormal' else 0 for label in y_val]\n",
    "\n",
    "# 확률 예측\n",
    "soft_voting_probs = model_Dam.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# 스레시홀드 적용(일반 모델의 경우 default로 0.5)\n",
    "soft_voting_preds = [1 if prob > 0.7 else 0 for prob in soft_voting_probs]\n",
    "\n",
    "# 평가\n",
    "get_clf_eval(y_val_int, soft_voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "8a4a2371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오차행렬:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>413</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7165</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True    413     57\n",
       "False  7165    467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 지표:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108615</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.878723</td>\n",
       "      <td>0.102634</td>\n",
       "      <td>0.113828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        정확도     정밀도       재현율  F1 Score  Weighted F1\n",
       "0  0.108615  0.0545  0.878723  0.102634     0.113828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_val에서 y_val과 x_val 추출\n",
    "y_val = df_val_autoclave_split['target'] \n",
    "x_val = df_val_autoclave_split.drop(columns=['target']) \n",
    "\n",
    "# y_val 레이블을 정수로 변환\n",
    "y_val_int = [1 if label == 'AbNormal' else 0 for label in y_val]\n",
    "\n",
    "# 확률 예측\n",
    "soft_voting_probs = model_AutoClave.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# 스레시홀드 적용(일반 모델의 경우 default로 0.5)\n",
    "soft_voting_preds = [1 if prob > 0.9 else 0 for prob in soft_voting_probs]\n",
    "\n",
    "# 평가\n",
    "get_clf_eval(y_val_int, soft_voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "35f4564d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오차행렬:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>405</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>6770</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True    405     65\n",
       "False  6770    862"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 지표:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.156381</td>\n",
       "      <td>0.056446</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.105952</td>\n",
       "      <td>0.195887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        정확도       정밀도       재현율  F1 Score  Weighted F1\n",
       "0  0.156381  0.056446  0.861702  0.105952     0.195887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_val에서 y_val과 x_val 추출\n",
    "y_val = df_val_fill1_split['target'] \n",
    "x_val = df_val_fill1_split.drop(columns=['target']) \n",
    "\n",
    "# y_val 레이블을 정수로 변환\n",
    "y_val_int = [1 if label == 'AbNormal' else 0 for label in y_val]\n",
    "\n",
    "# 확률 예측\n",
    "soft_voting_probs = model_Fill1.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# 스레시홀드 적용(일반 모델의 경우 default로 0.5)\n",
    "soft_voting_preds = [1 if prob > 0.7 else 0 for prob in soft_voting_probs]\n",
    "\n",
    "# 평가\n",
    "get_clf_eval(y_val_int, soft_voting_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "1aee39fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오차행렬:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>422</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>7095</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       True  False\n",
       "True    422     48\n",
       "False  7095    537"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 지표:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118366</td>\n",
       "      <td>0.056139</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>0.105672</td>\n",
       "      <td>0.129252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        정확도       정밀도       재현율  F1 Score  Weighted F1\n",
       "0  0.118366  0.056139  0.897872  0.105672     0.129252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_val에서 y_val과 x_val 추출\n",
    "y_val = df_val_fill2_split['target'] \n",
    "x_val = df_val_fill2_split.drop(columns=['target']) \n",
    "\n",
    "# y_val 레이블을 정수로 변환\n",
    "y_val_int = [1 if label == 'AbNormal' else 0 for label in y_val]\n",
    "\n",
    "# 확률 예측\n",
    "soft_voting_probs = model_Fill2.predict_proba(x_val)[:, 1]\n",
    "\n",
    "# 스레시홀드 적용(일반 모델의 경우 default로 0.5)\n",
    "soft_voting_preds = [1 if prob > 0.7 else 0 for prob in soft_voting_probs]\n",
    "\n",
    "# 평가\n",
    "get_clf_eval(y_val_int, soft_voting_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04f8eb",
   "metadata": {},
   "source": [
    "분할한 데이터 -> 원래의 데이터(train data)로 학습한 새 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "359db963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_dam_split.columns:\n",
    "    try:\n",
    "        df_train_dam_split[col] = df_train_dam_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_dam_split[features]\n",
    "train_y = df_train_dam_split[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "f69f329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_autoclave_split.columns:\n",
    "    try:\n",
    "        df_train_autoclave_split[col] = df_train_autoclave_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_autoclave_split[features]\n",
    "train_y = df_train_autoclave_split[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "6a903904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_fill1_split.columns:\n",
    "    try:\n",
    "        df_train_fill1_split[col] = df_train_fill1_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_fill1_split[features]\n",
    "train_y = df_train_fill1_split[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "65f4c8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data 데이터로 학습\n",
    "features = []\n",
    "\n",
    "for col in df_train_fill2_split.columns:\n",
    "    try:\n",
    "        df_train_fill2_split[col] = df_train_fill2_split[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train_fill2_split[features]\n",
    "train_y = df_train_fill2_split[\"target\"]\n",
    "\n",
    "model_Dam.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "4fcf4f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17361\n"
     ]
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 피처 이름 일치 확인 및 수정\n",
    "expected_features = model_Dam.feature_names_in_\n",
    "x_test = x_test.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "# 변경된 스레시홀드 적용하여 테스트 데이터에 대한 예측\n",
    "soft_voting_preds_dam = model_Dam.predict_proba(x_test)[:, 1]\n",
    "soft_voting_preds_dam = [1 if prob > 0.7 else 0 for prob in soft_voting_preds_dam]\n",
    "\n",
    "# 테스트 데이터에서 True로 예측된 개수 출력\n",
    "print(sum(soft_voting_preds_dam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "716d31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8645\n"
     ]
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 피처 이름 일치 확인 및 수정\n",
    "expected_features = model_AutoClave.feature_names_in_\n",
    "x_test = x_test.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "# 변경된 스레시홀드 적용하여 테스트 데이터에 대한 예측\n",
    "soft_voting_preds_autoclave = model_AutoClave.predict_proba(x_test)[:, 1]\n",
    "soft_voting_preds_autoclave = [1 if prob > 0.95 else 0 for prob in soft_voting_preds_autoclave]\n",
    "\n",
    "# 테스트 데이터에서 True로 예측된 개수 출력\n",
    "print(sum(soft_voting_preds_autoclave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "53df14f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15377\n"
     ]
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 피처 이름 일치 확인 및 수정\n",
    "expected_features = model_Fill1.feature_names_in_\n",
    "x_test = x_test.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "# 변경된 스레시홀드 적용하여 테스트 데이터에 대한 예측\n",
    "soft_voting_preds_Fill1 = model_Fill1.predict_proba(x_test)[:, 1]\n",
    "soft_voting_preds_Fill1 = [1 if prob > 0.7 else 0 for prob in soft_voting_preds_Fill1]\n",
    "\n",
    "# 테스트 데이터에서 True로 예측된 개수 출력\n",
    "print(sum(soft_voting_preds_Fill1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "278e2296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16130\n"
     ]
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = df_test_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 피처 이름 일치 확인 및 수정\n",
    "expected_features = model_Fill2.feature_names_in_\n",
    "x_test = x_test.reindex(columns=expected_features, fill_value=0)\n",
    "\n",
    "# 변경된 스레시홀드 적용하여 테스트 데이터에 대한 예측\n",
    "soft_voting_preds_Fill2 = model_Fill2.predict_proba(x_test)[:, 1]\n",
    "soft_voting_preds_Fill2 = [1 if prob > 0.7 else 0 for prob in soft_voting_preds_Fill2]\n",
    "\n",
    "# 테스트 데이터에서 True로 예측된 개수 출력\n",
    "print(sum(soft_voting_preds_Fill2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62bd70",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62fd18",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "3e1e11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = [1 if any(x) else 0 for x in zip(soft_voting_preds_dam, \n",
    "                                        soft_voting_preds_autoclave, \n",
    "                                        soft_voting_preds_Fill1, \n",
    "                                        soft_voting_preds_Fill2)]\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "# pred 값을 df_sub[\"target\"]에 할당\n",
    "df_sub[\"target\"] = pred\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "676ad00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbNormal    17361\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "118326f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID    target\n",
       "0  0001be084fbc4aaa9d921f39e595961b  AbNormal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80  AbNormal\n",
       "2  000948934c4140d883d670adcb609584  AbNormal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7  AbNormal\n",
       "4  0018e78ce91343678716e2ea27a51c95  AbNormal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2  AbNormal\n",
       "6  0020734a7b29472298358ad58645a0c9  AbNormal\n",
       "7  00234c5914cd4c4a888d13f8b3773135  AbNormal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  AbNormal\n",
       "9  002d904240d84b188d410d16383a9c3a  AbNormal"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f37ed",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
