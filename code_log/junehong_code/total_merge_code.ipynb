{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/trim_train_data.csv\")\n",
    "test_data = pd.read_csv(\"../../data/trim_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbb1c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866c077",
   "metadata": {},
   "source": [
    "공통 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "2f49aa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns with only NaN values have been removed, except for the target column.\n"
     ]
    }
   ],
   "source": [
    "# target 열을 임시로 분리\n",
    "target_train = train_data['target']\n",
    "target_test = test_data['target']\n",
    "\n",
    "# 모든 값이 NaN인 열 제거\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "\n",
    "# target 열을 다시 결합\n",
    "train_data['target'] = target_train\n",
    "test_data['target'] = target_test\n",
    "\n",
    "# 제거 후 데이터 확인\n",
    "print(\"All columns with only NaN values have been removed, except for the target column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d423473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wip Line_Dam  Wip Line_AutoClave  Wip Line_Fill1  Wip Line_Fill2\n",
       "IVI-OB6       IVI-OB6             IVI-OB6         IVI-OB6           40506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wip_line_columns = train_data.filter(like='Wip Line').columns\n",
    "\n",
    "new_df = train_data.filter(items=wip_line_columns)\n",
    "\n",
    "new_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "7a2b0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=wip_line_columns, inplace=True)\n",
    "test_data.drop(columns=wip_line_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "651ad853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process Desc._Dam  Process Desc._AutoClave  Process Desc._Fill1  Process Desc._Fill2\n",
       "Dam Dispenser      Auto Clave Out           Fill1 Dispenser      Fill2 Dispenser        40506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Process_Desc_col = train_data.filter(like='Process Desc').columns\n",
    "\n",
    "new2_df = train_data.filter(items=Process_Desc_col)\n",
    "\n",
    "new2_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "59e36ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Process Desc._Dam', 'Process Desc._AutoClave', 'Process Desc._Fill1', 'Process Desc._Fill2'])\n",
    "test_data = test_data.drop(columns=['Process Desc._Dam', 'Process Desc._AutoClave', 'Process Desc._Fill1', 'Process Desc._Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "b39666b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 그룹의 abnormal_ratio:\n",
      "Equipment_Dam     Equipment_AutoClave  Equipment_Fill1     Equipment_Fill2   \n",
      "Dam dispenser #1  Auto Clave Out       Fill1 dispenser #1  Fill2 dispenser #1    0.058614\n",
      "                                                           Fill2 dispenser #2    1.000000\n",
      "                                       Fill1 dispenser #2  Fill2 dispenser #2    1.000000\n",
      "Dam dispenser #2  Auto Clave Out       Fill1 dispenser #1  Fill2 dispenser #1    1.000000\n",
      "                                       Fill1 dispenser #2  Fill2 dispenser #1    1.000000\n",
      "                                                           Fill2 dispenser #2    0.054977\n",
      "Name: AbNormal, dtype: float64\n",
      "각 그룹의 값의 갯수:\n",
      "Equipment_Dam     Equipment_AutoClave  Equipment_Fill1     Equipment_Fill2   \n",
      "Dam dispenser #1  Auto Clave Out       Fill1 dispenser #1  Fill2 dispenser #1    25011\n",
      "                                                           Fill2 dispenser #2        6\n",
      "                                       Fill1 dispenser #2  Fill2 dispenser #2       13\n",
      "Dam dispenser #2  Auto Clave Out       Fill1 dispenser #1  Fill2 dispenser #1       10\n",
      "                                       Fill1 dispenser #2  Fill2 dispenser #1        5\n",
      "                                                           Fill2 dispenser #2    15461\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Equipment로 시작하는 열 필터링\n",
    "Equipment_col = train_data.filter(like='Equipment').columns\n",
    "new3_df = train_data.filter(items=Equipment_col)\n",
    "\n",
    "# target 변수 추가\n",
    "new3_df['target'] = train_data['target']\n",
    "\n",
    "# 그룹별로 target 변수의 비율 계산\n",
    "target_ratio = new3_df.groupby(list(Equipment_col))['target'].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# AbNormal 비율 출력\n",
    "abnormal_ratio = target_ratio.get('AbNormal', 0)\n",
    "print(\"각 그룹의 abnormal_ratio:\")\n",
    "print(abnormal_ratio)\n",
    "\n",
    "# 각 그룹에 값의 갯수 출력\n",
    "group_counts = new3_df.groupby(list(Equipment_col)).size()\n",
    "print(\"각 그룹의 값의 갯수:\")\n",
    "print(group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c8fcfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment로 시작하는 열 필터링\n",
    "Equipment_col = train_data.filter(like='Equipment').columns\n",
    "Equipment_col2 = test_data.filter(like='Equipment').columns\n",
    "\n",
    "new3_df = train_data.filter(items=Equipment_col)\n",
    "new3_df2 = test_data.filter(items=Equipment_col2)\n",
    "\n",
    "# Equipment_same_num 파생변수 생성\n",
    "def determine_equipment_same_num(row):\n",
    "    if (row['Equipment_Dam'] == 'Dam dispenser #1' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #1' and row['Equipment_Fill2'] == 'Fill2 dispenser #1') or \\\n",
    "       (row['Equipment_Dam'] == 'Dam dispenser #2' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #2' and row['Equipment_Fill2'] == 'Fill2 dispenser #2'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data['Equipment_same_num'] = new3_df.apply(determine_equipment_same_num, axis=1)\n",
    "test_data['Equipment_same_num'] = new3_df2.apply(determine_equipment_same_num, axis=1)\n",
    "\n",
    "train_data = train_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])\n",
    "test_data = test_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4183f6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model.Suffix_Dam  Model.Suffix_AutoClave  Model.Suffix_Fill1  Model.Suffix_Fill2\n",
       "AJX75334501       AJX75334501             AJX75334501         AJX75334501           33820\n",
       "AJX75334502       AJX75334502             AJX75334502         AJX75334502            3390\n",
       "AJX75334505       AJX75334505             AJX75334505         AJX75334505            2635\n",
       "AJX75334507       AJX75334507             AJX75334507         AJX75334507             310\n",
       "AJX75334503       AJX75334503             AJX75334503         AJX75334503             162\n",
       "AJX75334506       AJX75334506             AJX75334506         AJX75334506             129\n",
       "AJX75334508       AJX75334508             AJX75334508         AJX75334508              60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Process_Desc_col = train_data.filter(like='Model.Suffix').columns\n",
    "\n",
    "new2_df = train_data.filter(items=Process_Desc_col)\n",
    "\n",
    "new2_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9b925a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.Suffix_Dam의 이름을 Model.Suffix로 변경\n",
    "train_data = train_data.rename(columns={'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "test_data = test_data.rename(columns={'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "\n",
    "# Model.Suffix_AutoClave, Model.Suffix_Fill1, Model.Suffix_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])\n",
    "test_data = test_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "7b8310a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4개의 변수의 값이 모두 동일하지 않은 경우:\n",
      "Empty DataFrame\n",
      "Columns: [Workorder_Dam, Workorder_AutoClave, Workorder_Fill1, Workorder_Fill2]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Workorder로 시작하는 열 필터링\n",
    "workorder_cols = ['Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2']\n",
    "\n",
    "# Workorder 열들로 이루어진 데이터프레임 생성\n",
    "workorder_df = train_data[workorder_cols]\n",
    "\n",
    "# 4개의 변수의 값이 모두 동일하지 않은 행 필터링\n",
    "different_workorders = workorder_df[\n",
    "    (workorder_df['Workorder_Dam'] != workorder_df['Workorder_AutoClave']) |\n",
    "    (workorder_df['Workorder_Dam'] != workorder_df['Workorder_Fill1']) |\n",
    "    (workorder_df['Workorder_Dam'] != workorder_df['Workorder_Fill2']) |\n",
    "    (workorder_df['Workorder_AutoClave'] != workorder_df['Workorder_Fill1']) |\n",
    "    (workorder_df['Workorder_AutoClave'] != workorder_df['Workorder_Fill2']) |\n",
    "    (workorder_df['Workorder_Fill1'] != workorder_df['Workorder_Fill2'])\n",
    "]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"4개의 변수의 값이 모두 동일하지 않은 경우:\")\n",
    "print(different_workorders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "07645d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.Suffix_Dam의 이름을 Model.Suffix로 변경\n",
    "train_data = train_data.rename(columns={'Workorder_Dam': 'Workorder'})\n",
    "test_data = test_data.rename(columns={'Workorder_Dam': 'Workorder'})\n",
    "\n",
    "# Model.Suffix_AutoClave, Model.Suffix_Fill1, Model.Suffix_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])\n",
    "test_data = test_data.drop(columns=['Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d84a77fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40506"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "1e036171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Insp. Seq No._Dam  Insp. Seq No._AutoClave  Insp. Seq No._Fill1  Insp. Seq No._Fill2\n",
       "1                  1                        1                    1                      40506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Process_Desc_col = train_data.filter(like='Insp. Seq No.').columns\n",
    "\n",
    "new2_df = train_data.filter(items=Process_Desc_col)\n",
    "\n",
    "new2_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b411f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Insp. Seq No._Dam', 'Insp. Seq No._AutoClave', 'Insp. Seq No._Fill1', 'Insp. Seq No._Fill2'])\n",
    "test_data = test_data.drop(columns=['Insp. Seq No._Dam', 'Insp. Seq No._AutoClave', 'Insp. Seq No._Fill1', 'Insp. Seq No._Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7ecdf3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Insp Judge Code_Dam  Insp Judge Code_AutoClave  Insp Judge Code_Fill1  Insp Judge Code_Fill2\n",
       "OK                   OK                         OK                     OK                       40506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Process_Desc_col = train_data.filter(like='Insp Judge Code').columns\n",
    "\n",
    "new2_df = train_data.filter(items=Process_Desc_col)\n",
    "\n",
    "new2_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4c9e1b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Insp Judge Code_Dam', 'Insp Judge Code_AutoClave', 'Insp Judge Code_Fill1', 'Insp Judge Code_Fill2'])\n",
    "test_data = test_data.drop(columns=['Insp Judge Code_Dam', 'Insp Judge Code_AutoClave', 'Insp Judge Code_Fill1', 'Insp Judge Code_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "32721777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 161 entries, Model.Suffix to Equipment_same_num\n",
      "dtypes: float64(64), int64(85), object(12)\n",
      "memory usage: 49.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 162 entries, Set ID to Equipment_same_num\n",
      "dtypes: float64(122), int64(28), object(12)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "03f8f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 train_data 열 이름: ['CURE STANDBY POSITION X Collect Result_Dam', 'CURE STANDBY POSITION Z Collect Result_Dam', 'CURE STANDBY POSITION ? Collect Result_Dam', 'CURE START POSITION Z Collect Result_Dam', 'HEAD Standby Position X Collect Result_Dam', 'HEAD Standby Position Y Collect Result_Dam', 'HEAD Standby Position Z Collect Result_Dam', 'Head Clean Position X Collect Result_Dam', 'Head Clean Position Y Collect Result_Dam', 'Head Purge Position X Collect Result_Dam', 'Head Purge Position Y Collect Result_Dam', 'Head Zero Position X Collect Result_Dam', '1st Pressure Judge Value_AutoClave', '2nd Pressure Judge Value_AutoClave', '3rd Pressure Judge Value_AutoClave', 'HEAD Standby Position X Collect Result_Fill1', 'HEAD Standby Position Y Collect Result_Fill1', 'HEAD Standby Position Z Collect Result_Fill1', 'Head Clean Position X Collect Result_Fill1', 'Head Clean Position Y Collect Result_Fill1', 'Head Clean Position Z Collect Result_Fill1', 'Head Purge Position X Collect Result_Fill1', 'Head Purge Position Y Collect Result_Fill1', 'CURE END POSITION ? Collect Result_Fill2', 'CURE STANDBY POSITION X Collect Result_Fill2', 'CURE STANDBY POSITION ? Collect Result_Fill2', 'CURE START POSITION ? Collect Result_Fill2', 'DISCHARGED SPEED OF RESIN Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2', 'Dispense Volume(Stage1) Collect Result_Fill2', 'Dispense Volume(Stage2) Collect Result_Fill2', 'Dispense Volume(Stage3) Collect Result_Fill2', 'HEAD Standby Position X Collect Result_Fill2', 'HEAD Standby Position Y Collect Result_Fill2', 'HEAD Standby Position Z Collect Result_Fill2', 'Head Clean Position X Collect Result_Fill2', 'Head Clean Position Y Collect Result_Fill2', 'Head Clean Position Z Collect Result_Fill2', 'Head Purge Position X Collect Result_Fill2', 'Head Purge Position Y Collect Result_Fill2']\n",
      "삭제된 train_data 열 개수: 42\n",
      "삭제된 test_data 열 이름: ['CURE STANDBY POSITION X Collect Result_Dam', 'CURE STANDBY POSITION Z Collect Result_Dam', 'CURE STANDBY POSITION Θ Collect Result_Dam', 'CURE START POSITION Z Collect Result_Dam', 'HEAD Standby Position X Collect Result_Dam', 'HEAD Standby Position Y Collect Result_Dam', 'HEAD Standby Position Z Collect Result_Dam', 'Head Clean Position X Collect Result_Dam', 'Head Clean Position Y Collect Result_Dam', 'Head Purge Position X Collect Result_Dam', 'Head Purge Position Y Collect Result_Dam', 'Head Zero Position X Collect Result_Dam', '1st Pressure Judge Value_AutoClave', '2nd Pressure Judge Value_AutoClave', '3rd Pressure Judge Value_AutoClave', 'HEAD Standby Position X Collect Result_Fill1', 'HEAD Standby Position Y Collect Result_Fill1', 'HEAD Standby Position Z Collect Result_Fill1', 'Head Clean Position X Collect Result_Fill1', 'Head Clean Position Y Collect Result_Fill1', 'Head Clean Position Z Collect Result_Fill1', 'Head Purge Position X Collect Result_Fill1', 'Head Purge Position Y Collect Result_Fill1', 'CURE END POSITION Θ Collect Result_Fill2', 'CURE STANDBY POSITION X Collect Result_Fill2', 'CURE STANDBY POSITION Θ Collect Result_Fill2', 'CURE START POSITION Θ Collect Result_Fill2', 'DISCHARGED SPEED OF RESIN Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill2', 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill2', 'Dispense Volume(Stage1) Collect Result_Fill2', 'Dispense Volume(Stage2) Collect Result_Fill2', 'Dispense Volume(Stage3) Collect Result_Fill2', 'HEAD Standby Position X Collect Result_Fill2', 'HEAD Standby Position Y Collect Result_Fill2', 'HEAD Standby Position Z Collect Result_Fill2', 'Head Clean Position X Collect Result_Fill2', 'Head Clean Position Y Collect Result_Fill2', 'Head Clean Position Z Collect Result_Fill2', 'Head Purge Position X Collect Result_Fill2', 'Head Purge Position Y Collect Result_Fill2']\n",
      "삭제된 test_data 열 개수: 42\n"
     ]
    }
   ],
   "source": [
    "# 값의 종류가 1개이고 결측값이 없는 열을 제거하는 함수\n",
    "def drop_single_value_columns(df):\n",
    "    cols_to_drop = [col for col in df.columns if col != 'target' and df[col].nunique() == 1 and df[col].isnull().sum() == 0]\n",
    "    df_dropped = df.drop(columns=cols_to_drop)\n",
    "    return df_dropped, cols_to_drop\n",
    "\n",
    "# train_data와 test_data에서 해당 열 제거 및 삭제된 열 이름과 개수 출력\n",
    "train_data, train_cols_dropped = drop_single_value_columns(train_data)\n",
    "test_data, test_cols_dropped = drop_single_value_columns(test_data)\n",
    "\n",
    "print(\"삭제된 train_data 열 이름:\", train_cols_dropped)\n",
    "print(\"삭제된 train_data 열 개수:\", len(train_cols_dropped))\n",
    "\n",
    "print(\"삭제된 test_data 열 이름:\", test_cols_dropped)\n",
    "print(\"삭제된 test_data 열 개수:\", len(test_cols_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "26ec226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 119 entries, Model.Suffix to Equipment_same_num\n",
      "dtypes: float64(58), int64(52), object(9)\n",
      "memory usage: 36.8+ MB\n",
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 120 entries, Set ID to Equipment_same_num\n",
      "dtypes: float64(94), int64(17), object(9)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07606c9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70554ff6",
   "metadata": {},
   "source": [
    "개별 공정별 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7346a",
   "metadata": {},
   "source": [
    "## Dam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0906cc5f",
   "metadata": {},
   "source": [
    "## AutoClave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ce64980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 변경\n",
    "train_data = train_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})\n",
    "test_data = test_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "ec5d1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['2nd_Pressure_Greater_Than_0.6'] = train_data['2nd Pressure Collect Result_AutoClave'].apply(lambda x: 1 if x >= 0.6 else 0)\n",
    "test_data['2nd_Pressure_Greater_Than_0.6'] = test_data['2nd Pressure Collect Result_AutoClave'].apply(lambda x: 1 if x >= 0.6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ab366b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['3rd_Pressure_Greater_Than_0.7'] = train_data['3rd Pressure Collect Result_AutoClave'].apply(lambda x: 1 if x >= 0.7 else 0)\n",
    "test_data['3rd_Pressure_Greater_Than_0.7'] = test_data['3rd Pressure Collect Result_AutoClave'].apply(lambda x: 1 if x >= 0.7 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3c12bbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 121 entries, Model.Suffix to 3rd_Pressure_Greater_Than_0.7\n",
      "dtypes: float64(58), int64(54), object(9)\n",
      "memory usage: 37.4+ MB\n",
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 122 entries, Set ID to 3rd_Pressure_Greater_Than_0.7\n",
      "dtypes: float64(94), int64(19), object(9)\n",
      "memory usage: 16.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0164e69",
   "metadata": {},
   "source": [
    "## Fill1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70759e80",
   "metadata": {},
   "source": [
    "## Fill2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4cc6b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118ae22",
   "metadata": {},
   "source": [
    "### 언더 샘플링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97966549",
   "metadata": {},
   "source": [
    "데이타 불균형을 해결하기 위해 언더 샘플링을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f3c0db61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      38156\n",
       "AbNormal     2350\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "be3d675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total: Normal: 38156, AbNormal: 2350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "AbNormal    2350\n",
       "Normal      2350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_ratio = 1.0  # 1.0 means 1:1 ratio\n",
    "\n",
    "df_normal = train_data[train_data[\"target\"] == \"Normal\"]\n",
    "df_abnormal = train_data[train_data[\"target\"] == \"AbNormal\"]\n",
    "\n",
    "num_normal = len(df_normal)\n",
    "num_abnormal = len(df_abnormal)\n",
    "print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\")\n",
    "\n",
    "df_normal = df_normal.sample(n=int(num_abnormal * normal_ratio), replace=False, random_state=RANDOM_STATE)\n",
    "df_concat = pd.concat([df_normal, df_abnormal], axis=0).reset_index(drop=True)\n",
    "df_concat.value_counts(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeaabc1",
   "metadata": {},
   "source": [
    "### 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d01194fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 1880, AbNormal: 1880 ratio: 1.0\n",
      "  Total: Normal: 470, AbNormal: 470 ratio: 1.0\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    df_concat,\n",
    "    test_size=0.2,\n",
    "    stratify=df_concat[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "\n",
    "def print_stats(df: pd.DataFrame):\n",
    "    num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "    num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "    print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  \\tAbnormal\\tNormal\")\n",
    "print_stats(df_train)\n",
    "print_stats(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecfa9b",
   "metadata": {},
   "source": [
    "## 3. 모델 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf257b",
   "metadata": {},
   "source": [
    "### 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "e4509af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5ed8",
   "metadata": {},
   "source": [
    "### 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "766d1980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=110)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "for col in df_train.columns:\n",
    "    try:\n",
    "        df_train[col] = df_train[col].astype(int)\n",
    "        features.append(col)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "train_x = df_train[features]\n",
    "train_y = df_train[\"target\"]\n",
    "\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf8300",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b6e17",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda16350",
   "metadata": {},
   "source": [
    "테스트 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ae1ad75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data에 존재하는 열만 선택\n",
    "valid_features = [col for col in features if col in test_data.columns]\n",
    "\n",
    "df_test_x = test_data.loc[:, valid_features]\n",
    "\n",
    "for col in df_test_x.columns:\n",
    "    try:\n",
    "        df_test_x.loc[:, col] = df_test_x[col].astype(int)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "d13f7a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AbNormal', 'Normal', 'AbNormal', ..., 'AbNormal', 'Normal',\n",
       "       'AbNormal'], dtype=object)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 시 사용된 피처 이름을 저장합니다.\n",
    "train_features = model.feature_names_in_\n",
    "\n",
    "# 예측 시 동일한 피처를 사용하도록 데이터프레임을 조정합니다.\n",
    "df_test_x = df_test_x.reindex(columns=train_features, fill_value=0)\n",
    "\n",
    "# 예측을 수행합니다.\n",
    "test_pred = model.predict(df_test_x)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f18e6a",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3128a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7867ce",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
