{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2340621",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a199baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a4ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM_STATE = 110\n",
    "\n",
    "# train_data = pd.read_csv(\"../../data/train_data.csv\")\n",
    "# test_data = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003e2fc",
   "metadata": {},
   "source": [
    "### 0. 결측값 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c953fc",
   "metadata": {},
   "source": [
    "밀린행 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf17763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def shift_row_values(row, start_col_index, move_limit, total_columns):\n",
    "#     move_count = 0  # 이동 카운터 초기화\n",
    "#     for col_index in range(start_col_index, total_columns):  # 모든 열을 대상으로\n",
    "#         if pd.isna(row[col_index]) or row[col_index] == \"OK\":  # 빈값 또는 \"OK\" 확인\n",
    "#             # 빈값 또는 \"OK\"가 발견되면 현재 위치부터 이후 3칸 간격의 변수 값을 앞으로 이동\n",
    "#             for shift_index in range(col_index, total_columns - 3, 3):  # 3칸씩 이동\n",
    "#                 # 값을 이동\n",
    "#                 row[shift_index] = row[shift_index + 3]\n",
    "#                 row[shift_index + 3] = None  # 원래 자리 비우기\n",
    "#                 move_count += 1  # 이동 카운트 증가\n",
    "\n",
    "#                 if move_count >= move_limit:  # 설정된 횟수에 도달하면 중지\n",
    "#                     break\n",
    "#         if move_count >= move_limit:  # 외부 루프에서도 체크\n",
    "#             break\n",
    "#     return row\n",
    "\n",
    "# def shift_values(data, start_col_index, move_limit):\n",
    "#     total_columns = data.shape[1]\n",
    "#     data = data.apply(shift_row_values, axis=1, args=(start_col_index, move_limit, total_columns))\n",
    "#     return data\n",
    "\n",
    "# # 변수 이름 설정 및 시작 열 인덱스 및 이동 횟수 설정\n",
    "# variables_with_limits = [\n",
    "#     ('HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam', 52),\n",
    "#     ('HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', 22),\n",
    "#     ('HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2', 22)\n",
    "# ]\n",
    "\n",
    "# # 각 변수에 대해 함수 호출\n",
    "# def process_data(data, variables_with_limits, output_file):\n",
    "#     for start_var, move_limit in variables_with_limits:\n",
    "#         start_col_index = data.columns.get_loc(start_var)  # 각 변수의 시작 열 인덱스 찾기\n",
    "#         data = shift_values(data, start_col_index, move_limit)\n",
    "#     data.to_csv(output_file, index=False)\n",
    "#     print(f'데이터가 성공적으로 수정되고 저장되었습니다: {output_file}')\n",
    "\n",
    "# # 데이터 처리\n",
    "# process_data(train_data, variables_with_limits, '../../data/clean_train_data.csv')\n",
    "# process_data(test_data, variables_with_limits, '../../data/clean_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3352387-f469-4a46-a648-1a6b5eb353ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 불러오기\n",
    "train_data = pd.read_csv('../../data/clean_train_data.csv')\n",
    "test_data = pd.read_csv('../../data/clean_test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6f25e-68c6-45b2-8888-d762a4199bb5",
   "metadata": {},
   "source": [
    "### 1. 기본 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef282a8f-1717-4582-9abb-b064b243bac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 열을 임시로 분리\n",
    "target_train = train_data['target']\n",
    "target_test = test_data['target']\n",
    "\n",
    "# 모든 값이 NaN인 열 제거\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "\n",
    "# target 열을 다시 결합\n",
    "train_data['target'] = target_train\n",
    "test_data['target'] = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f245f17-b82f-4406-8f9d-cccf488bf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wip Line 열 제거\n",
    "wip_line_columns = train_data.filter(like='Wip Line').columns\n",
    "\n",
    "train_data.drop(columns=wip_line_columns, inplace=True)\n",
    "test_data.drop(columns=wip_line_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a4af25-3399-4762-be4e-7c77d67e677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Desc 열 제거\n",
    "Process_Desc_col = train_data.filter(like='Process Desc').columns\n",
    "\n",
    "train_data.drop(columns=Process_Desc_col, inplace=True)\n",
    "test_data.drop(columns=Process_Desc_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75a3e26-5efa-420e-998f-b0df0040df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insp. Seq No 열 제거\n",
    "Insp_Seq_No_col = train_data.filter(like='Insp. Seq No').columns\n",
    "\n",
    "train_data.drop(columns=Insp_Seq_No_col, inplace=True)\n",
    "test_data.drop(columns=Insp_Seq_No_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2a9ca83-eca1-4a22-b0c9-027f1960239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insp Judge Code 열 제거\n",
    "Insp_Judge_Code_col = train_data.filter(like='Insp Judge Code').columns\n",
    "\n",
    "train_data.drop(columns=Insp_Judge_Code_col, inplace=True)\n",
    "test_data.drop(columns=Insp_Judge_Code_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e2803-88fe-4d64-9f9d-fa60b6bb5299",
   "metadata": {},
   "source": [
    "### 2. 제품 구분"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546e33e3-9684-4c66-b33a-db13c3ca21e0",
   "metadata": {},
   "source": [
    "- receip no, workorder, model.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba667da8-fe3c-4eb2-87de-bd10d7300815",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Receip_No\n",
    "# 파생변수 생성: Receip_No 3개의 컬럼 값이 모두 동일하면 해당 값을 저장, 아니면 diff\n",
    "train_data['Receip_No'] = train_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "test_data['Receip_No'] = test_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# receip_no 열을 object 타입으로 변경\n",
    "train_data['Receip_No'] = train_data['Receip_No'].astype('object')\n",
    "test_data['Receip_No'] = test_data['Receip_No'].astype('object')\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train_data = train_data.drop(columns=['Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1', 'Receip No Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['Receip No Collect Result_Dam', 'Receip No Collect Result_Fill1', 'Receip No Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25be280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### model_receip\n",
    "# 열 이름 변경\n",
    "train_data.rename(columns={'Model.Suffix_Dam': 'model_suffix'}, inplace=True)\n",
    "test_data.rename(columns={'Model.Suffix_Dam': 'model_suffix'}, inplace=True)\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train_data = train_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])\n",
    "test_data = test_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d83525c-04c8-4dd7-a62c-28c70c182f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### workorder_receip\n",
    "# Workorder -뒤의 번호 구분을 제거\n",
    "train_data['cleaned_workorder'] = train_data['Workorder_Dam'].str.split('-').str[0]\n",
    "test_data['cleaned_workorder'] = test_data['Workorder_Dam'].str.split('-').str[0]\n",
    "\n",
    "# 필요없는 변수 삭제\n",
    "train_data = train_data.drop(columns=['Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])\n",
    "test_data = test_data.drop(columns=['Workorder_Dam', 'Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c6ca4-45bd-4c39-8af6-7fd0d61e103c",
   "metadata": {},
   "source": [
    "### 3. 공통 변수 (dam, fill1, fill2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4651eb9-eb1a-44a4-8979-2a38a8b9c532",
   "metadata": {},
   "source": [
    "- workmode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a33f774-81d7-4716-9176-79eaee466ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58781314-726c-42d1-a34f-cc12ce092852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f80682-b12e-4f8a-8ff8-39423a35e2d7",
   "metadata": {},
   "source": [
    "- equipment\n",
    "<br>(dispenser1 & dispenser2 변수를 만들 경우 다른 변수들에 의해 이미 설명이 되는 변수라 상관계수가 너무 높아서 제거하게 됨. 따라서 equipment가 같은지만 판단하는 파생변수 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8140b28a-2781-4356-9fe5-ac8d50beb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment로 시작하는 열 필터링\n",
    "Equipment_col = train_data.filter(like='Equipment').columns\n",
    "Equipment_col2 = test_data.filter(like='Equipment').columns\n",
    "\n",
    "new_train = train_data.filter(items=Equipment_col)\n",
    "new_test = test_data.filter(items=Equipment_col2)\n",
    "\n",
    "# Equipment_same_num 파생변수 생성\n",
    "def determine_equipment_same_num(row):\n",
    "    if (row['Equipment_Dam'] == 'Dam dispenser #1' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #1' and row['Equipment_Fill2'] == 'Fill2 dispenser #1') or \\\n",
    "       (row['Equipment_Dam'] == 'Dam dispenser #2' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #2' and row['Equipment_Fill2'] == 'Fill2 dispenser #2'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data['Equipment_same_num'] = new_train.apply(determine_equipment_same_num, axis=1)\n",
    "test_data['Equipment_same_num'] = new_test.apply(determine_equipment_same_num, axis=1)\n",
    "\n",
    "train_data = train_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])\n",
    "test_data = test_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07a545-9df9-488c-a27a-4104a8336fb0",
   "metadata": {},
   "source": [
    "- palletID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d399216f-b736-4190-be4b-3108366606c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 diff의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['PalletID_Collect_Result'] = df.apply(\n",
    "        lambda row: row['PalletID Collect Result_Dam'] \n",
    "                    if (row['PalletID Collect Result_Dam'] == row['PalletID Collect Result_Fill1'] == row['PalletID Collect Result_Fill2']) \n",
    "                    else 'diff', \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f91f21e-89f3-4b69-afc1-6d5ab6d820f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5310e-3d7e-4765-b902-91172707ff5a",
   "metadata": {},
   "source": [
    "- production Qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c478d82f-a486-471a-a12e-3ef6e9bc875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['Production_Qty_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Production Qty Collect Result_Dam'] \n",
    "                    if (row['Production Qty Collect Result_Dam'] == row['Production Qty Collect Result_Fill1'] == row['Production Qty Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd7b99c2-4d0a-40cc-8ec4-6a31b2862bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de023c44-9098-4852-8650-f30408ded1dd",
   "metadata": {},
   "source": [
    "### 4. CURE 변수\n",
    "- dam -> distance 파생변수 (standby는 단일값, start와 end는 값은 여러개지만 distance 파생변수를 만들었을 때 더 의미있었음)\n",
    "- fill2 -> 변수값 범주화 (start, end, standby를 각각 범주화했을 때가 합쳐서 distance 만들었을 때보다 더 의미있었음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ec88825-bef2-443c-8722-6c3f3867a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dam\n",
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Dam'\n",
    "start_z_col = 33.5\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Dam'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372b636c-6dff-42db-a9c8-f4abdb726159",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill2\n",
    "# UV 경화 좌표 합치기\n",
    "def create_coordinate_columns(data):\n",
    "    # Fill2\n",
    "    # cure end\n",
    "    data['cure_end_position_XZ_Fill2'] = (\n",
    "        data['CURE END POSITION X Collect Result_Fill2'].astype(str) + ',' +\n",
    "        data['CURE END POSITION Z Collect Result_Fill2'].astype(str) \n",
    "    )\n",
    "\n",
    "    # cure start\n",
    "    data['cure_start_position_XZ_Fill2'] = (\n",
    "        data['CURE START POSITION X Collect Result_Fill2'].astype(str) + ',' +\n",
    "        data['CURE START POSITION Z Collect Result_Fill2'].astype(str) \n",
    "    )\n",
    "\n",
    "    # cure standby\n",
    "    data['cure_standby_position_XZ_Fill2'] = (\n",
    "        data['CURE STANDBY POSITION X Collect Result_Fill2'].astype(str) + ',' +\n",
    "        data['CURE STANDBY POSITION Z Collect Result_Fill2'].astype(str) \n",
    "    )\n",
    "\n",
    "# train_data와 test_data에 대해 함수 호출\n",
    "create_coordinate_columns(train_data)\n",
    "create_coordinate_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb7f394f-640b-4bef-b01e-008310aa2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION X Collect Result_Dam',\n",
    "    'CURE END POSITION Z Collect Result_Dam',\n",
    "    'CURE END POSITION Θ Collect Result_Dam',\n",
    "    'CURE START POSITION X Collect Result_Dam',\n",
    "    'CURE START POSITION Z Collect Result_Dam',\n",
    "    'CURE START POSITION Θ Collect Result_Dam',\n",
    "\n",
    "    'CURE END POSITION X Collect Result_Fill2',\n",
    "    'CURE END POSITION Z Collect Result_Fill2',\n",
    "    'CURE END POSITION Θ Collect Result_Fill2',\n",
    "    'CURE START POSITION X Collect Result_Fill2',\n",
    "    'CURE START POSITION Z Collect Result_Fill2',\n",
    "    'CURE START POSITION Θ Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION X Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
    "    'CURE STANDBY POSITION Θ Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a4b1b-3e7b-4413-9704-d35f02fac78a",
   "metadata": {},
   "source": [
    "### 5. HEAD 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6fe5f-96d8-450c-9ef6-ae8c17a7901c",
   "metadata": {},
   "source": [
    "- dam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bda1832-ce60-4c22-abb7-a760df286801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db711e9-4ca2-4076-b689-241d786d968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Dam'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Dam'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16669b71-e0b1-46de-b64c-4b014010aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb6bf635-6060-4fd1-ac71-d057fae56513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dam 노즐 zero 위치 Z좌표 드롭\n",
    "train_data.drop(columns='Head Zero Position Z Collect Result_Dam', inplace=True)\n",
    "test_data.drop(columns='Head Zero Position Z Collect Result_Dam', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bffb86-f2cc-44ad-a495-a107d3b9c98a",
   "metadata": {},
   "source": [
    "- fill1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53e42711-b516-492c-a89a-2358839af5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76c1438e-9ead-47dd-80fd-b08faa85f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa31162e-094d-47fd-bef2-9e55bc4f9dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be5165-b1d0-412f-b293-1207d90e433b",
   "metadata": {},
   "source": [
    "- fill2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "836359e0-e3f3-487d-92d8-61869849bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53a7041f-8fe0-4e57-8559-115828424a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a64bf1-d745-47da-aedf-02361f2f2329",
   "metadata": {},
   "source": [
    "### 6. Resin 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3106d-63d0-411b-a83b-9baeedfa874a",
   "metadata": {},
   "source": [
    "- dam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9857a16-8c84-4381-a5bd-ecc78aa2ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume*time 파생변수 - Dam\n",
    "train_data['volume_time_multip_stage1_Dam'] = train_data['Dispense Volume(Stage1) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "train_data['volume_time_multip_stage2_Dam'] = train_data['Dispense Volume(Stage2) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "train_data['volume_time_multip_stage3_Dam'] = train_data['Dispense Volume(Stage3) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "\n",
    "train_data['volume_time_multip_avg_Dam'] = (train_data['volume_time_multip_stage1_Dam'] + \n",
    "                                            train_data['volume_time_multip_stage2_Dam'] + \n",
    "                                            train_data['volume_time_multip_stage3_Dam']) / 3\n",
    "\n",
    "# volume*time 파생변수 - Dam\n",
    "test_data['volume_time_multip_stage1_Dam'] = test_data['Dispense Volume(Stage1) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "test_data['volume_time_multip_stage2_Dam'] = test_data['Dispense Volume(Stage2) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "test_data['volume_time_multip_stage3_Dam'] = test_data['Dispense Volume(Stage3) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "\n",
    "test_data['volume_time_multip_avg_Dam'] = (test_data['volume_time_multip_stage1_Dam'] + \n",
    "                                            test_data['volume_time_multip_stage2_Dam'] + \n",
    "                                            test_data['volume_time_multip_stage3_Dam']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e0ebd5c-6fd7-4c5b-89cd-042b3a3671e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 목록 추가\n",
    "columns_to_drop = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage1) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage2) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage3) Collect Result_Dam',\n",
    "    #'volume_time_multip_stage1_Dam',\n",
    "    #'volume_time_multip_stage2_Dam',\n",
    "    #'volume_time_multip_stage3_Dam'\n",
    "]\n",
    "\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9986f1-a251-430e-bbd9-705bdd0cfbda",
   "metadata": {},
   "source": [
    "- fill1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2b05f8b-7a55-40be-aa70-02faa32cffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume*time 파생변수 - Fill1\n",
    "train_data['volume_time_multip_stage1_Fill1'] = train_data['Dispense Volume(Stage1) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "train_data['volume_time_multip_stage2_Fill1'] = train_data['Dispense Volume(Stage2) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "train_data['volume_time_multip_stage3_Fill1'] = train_data['Dispense Volume(Stage3) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "\n",
    "train_data['volume_time_multip_avg_Fill1'] = (train_data['volume_time_multip_stage1_Fill1'] + \n",
    "                                            train_data['volume_time_multip_stage2_Fill1'] + \n",
    "                                            train_data['volume_time_multip_stage3_Fill1']) / 3\n",
    "\n",
    "# volume*time 파생변수 - Fill1\n",
    "test_data['volume_time_multip_stage1_Fill1'] = test_data['Dispense Volume(Stage1) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "test_data['volume_time_multip_stage2_Fill1'] = test_data['Dispense Volume(Stage2) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "test_data['volume_time_multip_stage3_Fill1'] = test_data['Dispense Volume(Stage3) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "\n",
    "test_data['volume_time_multip_avg_Fill1'] = (test_data['volume_time_multip_stage1_Fill1'] + \n",
    "                                            test_data['volume_time_multip_stage2_Fill1'] + \n",
    "                                            test_data['volume_time_multip_stage3_Fill1']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bff6cf24-453d-4bba-a5e3-bddededfb17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 목록 추가\n",
    "columns_to_drop = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1',\n",
    "    #'volume_time_multip_stage1_Fill1',\n",
    "    #'volume_time_multip_stage2_Fill1',\n",
    "    #'volume_time_multip_stage3_Fill1'\n",
    "]\n",
    "\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56006cb7-66fa-4757-816c-260e12d6555e",
   "metadata": {},
   "source": [
    "### 7. Circle, Line 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d445887-0bf3-4a31-956b-bdc711c606c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### circle\n",
    "# 열 이름 변경\n",
    "train_data.rename(columns={\n",
    "    'Stage1 Circle1 Distance Speed Collect Result_Dam': 'Stage1_Circle_Distance_Speed_Dam',\n",
    "    'Stage2 Circle1 Distance Speed Collect Result_Dam': 'Stage2_Circle_Distance_Speed_Dam',\n",
    "    'Stage3 Circle1 Distance Speed Collect Result_Dam': 'Stage3_Circle_Distance_Speed_Dam'\n",
    "}, inplace=True)\n",
    "\n",
    "test_data.rename(columns={\n",
    "    'Stage1 Circle1 Distance Speed Collect Result_Dam': 'Stage1_Circle_Distance_Speed_Dam',\n",
    "    'Stage2 Circle1 Distance Speed Collect Result_Dam': 'Stage2_Circle_Distance_Speed_Dam',\n",
    "    'Stage3 Circle1 Distance Speed Collect Result_Dam': 'Stage3_Circle_Distance_Speed_Dam'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61d337af-f8b5-4a00-a32a-8f23936a5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
    "    \n",
    "    'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
    "    \n",
    "    'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "635f16a4-2bc5-43c2-8d71-0c25dc28fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "### line\n",
    "# line1&3과 line2&4를 합친 파생변수 생성 함수\n",
    "def check_distance_speed(data, stage):\n",
    "    # 단계에 따라 라인 번호 정의\n",
    "    line_pairs = [(1, 3), (2, 4)]\n",
    "    \n",
    "    # 각 라인 쌍에 대해 반복\n",
    "    for line1, line2 in line_pairs:\n",
    "        line1_name = f'Stage{stage} Line{line1} Distance Speed Collect Result_Dam'\n",
    "        line2_name = f'Stage{stage} Line{line2} Distance Speed Collect Result_Dam'\n",
    "        \n",
    "        # 새로운 열 이름 설정\n",
    "        new_col_name = f'stage{stage}_line{line1}{line2}_distance_speed_Dam'\n",
    "        \n",
    "        # 조건에 따라 값 설정\n",
    "        data[new_col_name] = data.apply(\n",
    "            lambda row: row[line1_name] if row[line1_name] == row[line2_name] else 'diff', axis=1\n",
    "        )\n",
    "\n",
    "# train_data와 test_data 모두에 대해 함수 호출\n",
    "for stage in range(1, 4):\n",
    "    check_distance_speed(train_data, stage)\n",
    "    check_distance_speed(test_data, stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba83e4f4-f481-468c-9b97-e0cbe31ad381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에서 변수들을 object 타입으로 변환\n",
    "train_data['stage1_line24_distance_speed_Dam'] = train_data['stage1_line24_distance_speed_Dam'].astype(object)\n",
    "train_data['stage2_line24_distance_speed_Dam'] = train_data['stage2_line24_distance_speed_Dam'].astype(object)\n",
    "train_data['stage3_line24_distance_speed_Dam'] = train_data['stage3_line24_distance_speed_Dam'].astype(object)\n",
    "\n",
    "# test_data에서 변수들을 object 타입으로 변환\n",
    "test_data['stage1_line24_distance_speed_Dam'] = test_data['stage1_line24_distance_speed_Dam'].astype(object)\n",
    "test_data['stage2_line24_distance_speed_Dam'] = test_data['stage2_line24_distance_speed_Dam'].astype(object)\n",
    "test_data['stage3_line24_distance_speed_Dam'] = test_data['stage3_line24_distance_speed_Dam'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbe85479-dc33-4121-a8ab-5cc3bd6b5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
    "    \n",
    "    'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
    "    \n",
    "    'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80796e-f6ac-434a-9ab6-e967ca205fe5",
   "metadata": {},
   "source": [
    "### 8. Thickness 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "769fdc40-d747-4671-b611-bab9d874055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 개 컬럼의 평균을 계산하여 새로운 컬럼 생성\n",
    "train_data['average_thickness_Dam'] = train_data[['THICKNESS 1 Collect Result_Dam', \n",
    "                                                  'THICKNESS 2 Collect Result_Dam', \n",
    "                                                  'THICKNESS 3 Collect Result_Dam']].mean(axis=1)\n",
    "\n",
    "test_data['average_thickness_Dam'] = test_data[['THICKNESS 1 Collect Result_Dam', \n",
    "                                                'THICKNESS 2 Collect Result_Dam', \n",
    "                                                'THICKNESS 3 Collect Result_Dam']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bb9b4ca-e018-4b75-aa27-eb85bd990683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    'THICKNESS 1 Collect Result_Dam',\n",
    "    'THICKNESS 2 Collect Result_Dam',\n",
    "    'THICKNESS 3 Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c7b4d-1be0-431c-ab45-ff09a5e96f0f",
   "metadata": {},
   "source": [
    "### 9. Autoclave 관련 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1f89fb6-59bd-4203-8c2d-0b68548b1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 압력과 시간의 곱을 담은 새로운 컬럼 생성\n",
    "train_data['1st_pressure_time_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure 1st Pressure Unit Time_AutoClave']\n",
    "train_data['2nd_pressure_time_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave']\n",
    "train_data['3rd_pressure_time_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave']\n",
    "\n",
    "train_data['avg_pressure_time_AutoClave'] = (train_data['1st_pressure_time_AutoClave'] +\n",
    "                                             train_data['2nd_pressure_time_AutoClave'] +\n",
    "                                             train_data['3rd_pressure_time_AutoClave']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f53849fa-07d1-4d3e-a25d-79fa1a9525c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 압력과 시간의 곱을 담은 새로운 컬럼 생성\n",
    "test_data['1st_pressure_time_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure 1st Pressure Unit Time_AutoClave']\n",
    "test_data['2nd_pressure_time_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave']\n",
    "test_data['3rd_pressure_time_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave']\n",
    "\n",
    "test_data['avg_pressure_time_AutoClave'] = (test_data['1st_pressure_time_AutoClave'] +\n",
    "                                             test_data['2nd_pressure_time_AutoClave'] +\n",
    "                                             test_data['3rd_pressure_time_AutoClave']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cf9e13a-fada-448a-b045-3400cb9467e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    '1st Pressure Collect Result_AutoClave',\n",
    "    '1st Pressure 1st Pressure Unit Time_AutoClave',\n",
    "    '2nd Pressure Collect Result_AutoClave',\n",
    "    '2nd Pressure Unit Time_AutoClave',\n",
    "    '3rd Pressure Collect Result_AutoClave',\n",
    "    '3rd Pressure Unit Time_AutoClave',\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e41272-4e95-40f2-832e-c7a4ad1d5460",
   "metadata": {},
   "source": [
    "### 10. Time 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9923c80-82b6-45e6-a2f0-032cb54c6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총시간 대비 비율 변수\n",
    "def calculate_total_time_and_ratios(data):\n",
    "    data['total_time'] = (\n",
    "        data['Machine Tact time Collect Result_Dam'] +\n",
    "        data['Machine Tact time Collect Result_Fill1'] +\n",
    "        data['Machine Tact time Collect Result_Fill2'] +\n",
    "        data['Chamber Temp. Unit Time_AutoClave']\n",
    "    )\n",
    "    data['time_ratio_Dam'] = (data['Machine Tact time Collect Result_Dam'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill1'] = (data['Machine Tact time Collect Result_Fill1'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill2'] = (data['Machine Tact time Collect Result_Fill2'] / data['total_time']).round(3)\n",
    "    data['time_ratio_AutoClave'] = (data['Chamber Temp. Unit Time_AutoClave'] / data['total_time']).round(3)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 함수 적용\n",
    "train_data = calculate_total_time_and_ratios(train_data)\n",
    "test_data = calculate_total_time_and_ratios(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71df6a7f-21bf-4b8d-9def-75dd8a376b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 제거\n",
    "train_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)\n",
    "\n",
    "test_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407c0d4-c6a4-4b05-9f23-6d5bbbd9eb0f",
   "metadata": {},
   "source": [
    "### 11. 변수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "037c7017-2c2c-41d7-a126-0435efac77d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 변수 리스트\n",
    "columns_to_drop = [\n",
    "    'Chamber Temp. Judge Value_AutoClave', \n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave', \n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "]\n",
    "\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f949535-f844-493c-84df-48fe1bf57930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 train_data 열 개수: 37\n",
      "삭제된 test_data 열 개수: 37\n"
     ]
    }
   ],
   "source": [
    "# 값의 종류가 1개이고 결측값이 없는 열을 제거하는 함수\n",
    "def drop_single_value_columns(df):\n",
    "    cols_to_drop = [col for col in df.columns if col != 'target' and df[col].nunique() == 1 and df[col].isnull().sum() == 0]\n",
    "    df_dropped = df.drop(columns=cols_to_drop)\n",
    "    return df_dropped, cols_to_drop\n",
    "\n",
    "# train_data와 test_data에서 해당 열 제거 및 삭제된 열 이름과 개수 출력\n",
    "train_data, train_cols_dropped = drop_single_value_columns(train_data)\n",
    "test_data, test_cols_dropped = drop_single_value_columns(test_data)\n",
    "\n",
    "# print(\"삭제된 train_data 열 이름:\", train_cols_dropped)\n",
    "print(\"삭제된 train_data 열 개수:\", len(train_cols_dropped))\n",
    "\n",
    "# print(\"삭제된 test_data 열 이름:\", test_cols_dropped)\n",
    "print(\"삭제된 test_data 열 개수:\", len(test_cols_dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88801ff-c9a9-45dd-825d-005dbf75943f",
   "metadata": {},
   "source": [
    "### 12. target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b040b33-0137-4968-b99b-c632d1e8473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['model_suffix', 'target', 'Receip_No', 'cleaned_workorder',\n",
      "       'PalletID_Collect_Result', 'cure_end_position_XZ_Fill2',\n",
      "       'cure_start_position_XZ_Fill2', 'cure_standby_position_XZ_Fill2',\n",
      "       'stage1_line13_distance_speed_Dam', 'stage1_line24_distance_speed_Dam',\n",
      "       'stage2_line13_distance_speed_Dam', 'stage2_line24_distance_speed_Dam',\n",
      "       'stage3_line13_distance_speed_Dam', 'stage3_line24_distance_speed_Dam'],\n",
      "      dtype='object')  train_object_columns 갯수 : 14\n",
      "Index(['Set ID', 'model_suffix', 'Receip_No', 'cleaned_workorder',\n",
      "       'PalletID_Collect_Result', 'cure_end_position_XZ_Fill2',\n",
      "       'cure_start_position_XZ_Fill2', 'cure_standby_position_XZ_Fill2',\n",
      "       'stage1_line13_distance_speed_Dam', 'stage1_line24_distance_speed_Dam',\n",
      "       'stage2_line13_distance_speed_Dam', 'stage2_line24_distance_speed_Dam',\n",
      "       'stage3_line13_distance_speed_Dam', 'stage3_line24_distance_speed_Dam'],\n",
      "      dtype='object')  test_object_columns 갯수 : 14\n",
      "\n",
      "Train Data:\n",
      "model_suffix unique 값 갯수: 7\n",
      "target unique 값 갯수: 2\n",
      "Receip_No unique 값 갯수: 6\n",
      "cleaned_workorder unique 값 갯수: 568\n",
      "PalletID_Collect_Result unique 값 갯수: 17\n",
      "cure_end_position_XZ_Fill2 unique 값 갯수: 4\n",
      "cure_start_position_XZ_Fill2 unique 값 갯수: 5\n",
      "cure_standby_position_XZ_Fill2 unique 값 갯수: 4\n",
      "stage1_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage1_line24_distance_speed_Dam unique 값 갯수: 7\n",
      "stage2_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage2_line24_distance_speed_Dam unique 값 갯수: 10\n",
      "stage3_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage3_line24_distance_speed_Dam unique 값 갯수: 7\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "model_suffix unique 값 갯수: 7\n",
      "Receip_No unique 값 갯수: 5\n",
      "cleaned_workorder unique 값 갯수: 566\n",
      "PalletID_Collect_Result unique 값 갯수: 17\n",
      "cure_end_position_XZ_Fill2 unique 값 갯수: 4\n",
      "cure_start_position_XZ_Fill2 unique 값 갯수: 5\n",
      "cure_standby_position_XZ_Fill2 unique 값 갯수: 4\n",
      "stage1_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage1_line24_distance_speed_Dam unique 값 갯수: 7\n",
      "stage2_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage2_line24_distance_speed_Dam unique 값 갯수: 10\n",
      "stage3_line13_distance_speed_Dam unique 값 갯수: 9\n",
      "stage3_line24_distance_speed_Dam unique 값 갯수: 7\n"
     ]
    }
   ],
   "source": [
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e9822a2-42bc-499f-9c46-cc5e0289731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 평균 타겟 값 계산 (abnormal 전체 비율)\n",
    "train_data['target_01'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "global_mean = train_data['target_01'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6c17701-dd06-4dcd-93ac-47558ef7f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적용할 열 리스트\n",
    "columns_to_encode = [\n",
    "    'Receip_No',\n",
    "    'model_suffix',\n",
    "    'cleaned_workorder',\n",
    "    'PalletID_Collect_Result',\n",
    "    'cure_end_position_XZ_Fill2',\n",
    "    'cure_start_position_XZ_Fill2',\n",
    "    'cure_standby_position_XZ_Fill2',\n",
    "    'stage1_line13_distance_speed_Dam',\n",
    "    'stage1_line24_distance_speed_Dam',\n",
    "    'stage2_line13_distance_speed_Dam',\n",
    "    'stage2_line24_distance_speed_Dam',\n",
    "    'stage3_line13_distance_speed_Dam',\n",
    "    'stage3_line24_distance_speed_Dam'\n",
    "]\n",
    "\n",
    "# 전체 데이터의 평균 타겟값\n",
    "global_mean = train_data['target_01'].mean()\n",
    "\n",
    "for column in columns_to_encode:\n",
    "    # 각 column에 대한 평균 타겟값과 카운트 계산\n",
    "    target_mean = train_data.groupby(column)['target_01'].mean()\n",
    "    count = train_data.groupby(column)['target_01'].count()\n",
    "\n",
    "    # 스무딩 적용\n",
    "    '''\n",
    "    추천 알파 값:\n",
    "    0.5: 일반적으로 많이 사용되는 값으로, 기존 데이터와 전체 평균 간의 균형을 잘 맞춰줍니다.\n",
    "    0.3: 데이터가 충분히 많고 각 카테고리의 타겟 값이 잘 분포되어 있을 때 사용.\n",
    "    0.7: 데이터가 적거나 특정 카테고리가 상대적으로 적을 때 사용.\n",
    "    '''\n",
    "    alpha = 0.5\n",
    "    smoothed_values = (target_mean * count + global_mean * alpha) / (count + alpha)\n",
    "\n",
    "    # 인코딩된 값을 데이터프레임에 추가\n",
    "    train_data[f'{column}_encoded'] = train_data[column].map(smoothed_values)\n",
    "\n",
    "    # test_data에 동일한 인코딩 값을 추가\n",
    "    encoding_dict = train_data.groupby(column)[f'{column}_encoded'].first().to_dict()\n",
    "    test_data[f'{column}_encoded'] = test_data[column].map(encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0326880b-fcdd-493f-8bda-b53932d5313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 리스트\n",
    "columns_to_drop = [\n",
    "    'target_01',\n",
    "    'Receip_No',\n",
    "    'model_suffix',\n",
    "    'cleaned_workorder',\n",
    "    'PalletID_Collect_Result',\n",
    "    'cure_end_position_XZ_Fill2',\n",
    "    'cure_start_position_XZ_Fill2',\n",
    "    'cure_standby_position_XZ_Fill2',\n",
    "    'stage1_line13_distance_speed_Dam',\n",
    "    'stage1_line24_distance_speed_Dam',\n",
    "    'stage2_line13_distance_speed_Dam',\n",
    "    'stage2_line24_distance_speed_Dam',\n",
    "    'stage3_line13_distance_speed_Dam',\n",
    "    'stage3_line24_distance_speed_Dam'\n",
    "]\n",
    "\n",
    "# train_data와 test_data에서 열 드랍\n",
    "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_data = test_data.drop(columns=columns_to_drop, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22bf67fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 열을 제외한 나머지 열의 결측치를 0.05로 채우기\n",
    "test_data.fillna(value={col: 0.05 for col in test_data.columns if col != 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25c940cd-54ae-4277-b259-dee92b98f837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 57 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   CURE SPEED Collect Result_Dam                   40506 non-null  int64  \n",
      " 1   DISCHARGED SPEED OF RESIN Collect Result_Dam    40506 non-null  int64  \n",
      " 2   Head Clean Position Z Collect Result_Dam        40506 non-null  float64\n",
      " 3   Head Purge Position Z Collect Result_Dam        40506 non-null  float64\n",
      " 4   Head Zero Position Y Collect Result_Dam         40506 non-null  float64\n",
      " 5   Stage1_Circle_Distance_Speed_Dam                40506 non-null  int64  \n",
      " 6   Stage2_Circle_Distance_Speed_Dam                40506 non-null  int64  \n",
      " 7   Stage3_Circle_Distance_Speed_Dam                40506 non-null  int64  \n",
      " 8   WorkMode Collect Result                         40506 non-null  float64\n",
      " 9   Chamber Temp. Collect Result_AutoClave          40506 non-null  int64  \n",
      " 10  DISCHARGED SPEED OF RESIN Collect Result_Fill1  40506 non-null  float64\n",
      " 11  Head Purge Position Z Collect Result_Fill1      40506 non-null  float64\n",
      " 12  CURE SPEED Collect Result_Fill2                 40506 non-null  int64  \n",
      " 13  Head Purge Position Z Collect Result_Fill2      40506 non-null  float64\n",
      " 14  target                                          40506 non-null  object \n",
      " 15  Equipment_same_num                              40506 non-null  int64  \n",
      " 16  Production_Qty_Collect_Result                   40506 non-null  int64  \n",
      " 17  CURE_DISTANCE_Dam                               40506 non-null  float64\n",
      " 18  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam          40506 non-null  float64\n",
      " 19  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam          40506 non-null  float64\n",
      " 20  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam        40506 non-null  float64\n",
      " 21  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1        40506 non-null  float64\n",
      " 22  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1        40506 non-null  float64\n",
      " 23  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1      40506 non-null  float64\n",
      " 24  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2        40506 non-null  float64\n",
      " 25  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2        40506 non-null  float64\n",
      " 26  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2        40506 non-null  float64\n",
      " 27  volume_time_multip_stage1_Dam                   40506 non-null  float64\n",
      " 28  volume_time_multip_stage2_Dam                   40506 non-null  float64\n",
      " 29  volume_time_multip_stage3_Dam                   40506 non-null  float64\n",
      " 30  volume_time_multip_avg_Dam                      40506 non-null  float64\n",
      " 31  volume_time_multip_stage1_Fill1                 40506 non-null  float64\n",
      " 32  volume_time_multip_stage2_Fill1                 40506 non-null  float64\n",
      " 33  volume_time_multip_stage3_Fill1                 40506 non-null  float64\n",
      " 34  volume_time_multip_avg_Fill1                    40506 non-null  float64\n",
      " 35  average_thickness_Dam                           40506 non-null  float64\n",
      " 36  1st_pressure_time_AutoClave                     40506 non-null  float64\n",
      " 37  2nd_pressure_time_AutoClave                     40506 non-null  float64\n",
      " 38  3rd_pressure_time_AutoClave                     40506 non-null  float64\n",
      " 39  avg_pressure_time_AutoClave                     40506 non-null  float64\n",
      " 40  time_ratio_Dam                                  40506 non-null  float64\n",
      " 41  time_ratio_Fill1                                40506 non-null  float64\n",
      " 42  time_ratio_Fill2                                40506 non-null  float64\n",
      " 43  time_ratio_AutoClave                            40506 non-null  float64\n",
      " 44  Receip_No_encoded                               40506 non-null  float64\n",
      " 45  model_suffix_encoded                            40506 non-null  float64\n",
      " 46  cleaned_workorder_encoded                       40506 non-null  float64\n",
      " 47  PalletID_Collect_Result_encoded                 40506 non-null  float64\n",
      " 48  cure_end_position_XZ_Fill2_encoded              40506 non-null  float64\n",
      " 49  cure_start_position_XZ_Fill2_encoded            40506 non-null  float64\n",
      " 50  cure_standby_position_XZ_Fill2_encoded          40506 non-null  float64\n",
      " 51  stage1_line13_distance_speed_Dam_encoded        40506 non-null  float64\n",
      " 52  stage1_line24_distance_speed_Dam_encoded        40506 non-null  float64\n",
      " 53  stage2_line13_distance_speed_Dam_encoded        40506 non-null  float64\n",
      " 54  stage2_line24_distance_speed_Dam_encoded        40506 non-null  float64\n",
      " 55  stage3_line13_distance_speed_Dam_encoded        40506 non-null  float64\n",
      " 56  stage3_line24_distance_speed_Dam_encoded        40506 non-null  float64\n",
      "dtypes: float64(47), int64(9), object(1)\n",
      "memory usage: 17.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# info 잘리지 않게 출력\n",
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae3dd21b-7dcb-4150-9eb4-37fe114ba4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Set ID                                          17361 non-null  object \n",
      " 1   CURE SPEED Collect Result_Dam                   17361 non-null  int64  \n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam    17361 non-null  int64  \n",
      " 3   Head Clean Position Z Collect Result_Dam        17361 non-null  float64\n",
      " 4   Head Purge Position Z Collect Result_Dam        17361 non-null  float64\n",
      " 5   Head Zero Position Y Collect Result_Dam         17361 non-null  float64\n",
      " 6   Stage1_Circle_Distance_Speed_Dam                17361 non-null  int64  \n",
      " 7   Stage2_Circle_Distance_Speed_Dam                17361 non-null  int64  \n",
      " 8   Stage3_Circle_Distance_Speed_Dam                17361 non-null  int64  \n",
      " 9   WorkMode Collect Result                         17361 non-null  float64\n",
      " 10  Chamber Temp. Collect Result_AutoClave          17361 non-null  int64  \n",
      " 11  DISCHARGED SPEED OF RESIN Collect Result_Fill1  17361 non-null  float64\n",
      " 12  Head Purge Position Z Collect Result_Fill1      17361 non-null  float64\n",
      " 13  CURE SPEED Collect Result_Fill2                 17361 non-null  int64  \n",
      " 14  Head Purge Position Z Collect Result_Fill2      17361 non-null  float64\n",
      " 15  target                                          0 non-null      float64\n",
      " 16  Equipment_same_num                              17361 non-null  int64  \n",
      " 17  Production_Qty_Collect_Result                   17361 non-null  int64  \n",
      " 18  CURE_DISTANCE_Dam                               17361 non-null  float64\n",
      " 19  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam          17361 non-null  float64\n",
      " 20  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam          17361 non-null  float64\n",
      " 21  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam        17361 non-null  float64\n",
      " 22  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1        17361 non-null  float64\n",
      " 23  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1        17361 non-null  float64\n",
      " 24  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1      17361 non-null  float64\n",
      " 25  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2        17361 non-null  float64\n",
      " 26  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2        17361 non-null  float64\n",
      " 27  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2        17361 non-null  float64\n",
      " 28  volume_time_multip_stage1_Dam                   17361 non-null  float64\n",
      " 29  volume_time_multip_stage2_Dam                   17361 non-null  float64\n",
      " 30  volume_time_multip_stage3_Dam                   17361 non-null  float64\n",
      " 31  volume_time_multip_avg_Dam                      17361 non-null  float64\n",
      " 32  volume_time_multip_stage1_Fill1                 17361 non-null  float64\n",
      " 33  volume_time_multip_stage2_Fill1                 17361 non-null  float64\n",
      " 34  volume_time_multip_stage3_Fill1                 17361 non-null  float64\n",
      " 35  volume_time_multip_avg_Fill1                    17361 non-null  float64\n",
      " 36  average_thickness_Dam                           17361 non-null  float64\n",
      " 37  1st_pressure_time_AutoClave                     17361 non-null  float64\n",
      " 38  2nd_pressure_time_AutoClave                     17361 non-null  float64\n",
      " 39  3rd_pressure_time_AutoClave                     17361 non-null  float64\n",
      " 40  avg_pressure_time_AutoClave                     17361 non-null  float64\n",
      " 41  time_ratio_Dam                                  17361 non-null  float64\n",
      " 42  time_ratio_Fill1                                17361 non-null  float64\n",
      " 43  time_ratio_Fill2                                17361 non-null  float64\n",
      " 44  time_ratio_AutoClave                            17361 non-null  float64\n",
      " 45  Receip_No_encoded                               17361 non-null  float64\n",
      " 46  model_suffix_encoded                            17361 non-null  float64\n",
      " 47  cleaned_workorder_encoded                       17361 non-null  float64\n",
      " 48  PalletID_Collect_Result_encoded                 17361 non-null  float64\n",
      " 49  cure_end_position_XZ_Fill2_encoded              17361 non-null  float64\n",
      " 50  cure_start_position_XZ_Fill2_encoded            17361 non-null  float64\n",
      " 51  cure_standby_position_XZ_Fill2_encoded          17361 non-null  float64\n",
      " 52  stage1_line13_distance_speed_Dam_encoded        17361 non-null  float64\n",
      " 53  stage1_line24_distance_speed_Dam_encoded        17361 non-null  float64\n",
      " 54  stage2_line13_distance_speed_Dam_encoded        17361 non-null  float64\n",
      " 55  stage2_line24_distance_speed_Dam_encoded        17361 non-null  float64\n",
      " 56  stage3_line13_distance_speed_Dam_encoded        17361 non-null  float64\n",
      " 57  stage3_line24_distance_speed_Dam_encoded        17361 non-null  float64\n",
      "dtypes: float64(48), int64(9), object(1)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# info 잘리지 않게 출력\n",
    "test_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877efc6-7851-408a-99b4-a0f8bc9bcad1",
   "metadata": {},
   "source": [
    "### 13. correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca33a0a4-7be6-4244-85ad-019d5807eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45924c5c-f6be-4b17-87ff-9c414a6c8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b5986-ccde-4df4-bc02-c9812daeaaf4",
   "metadata": {},
   "source": [
    "- dam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccc357da-1f9b-45ca-a63c-66530ad718ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Receip_No_encoded',\n",
       " 'Equipment_same_num',\n",
       " 'PalletID_Collect_Result_encoded',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'WorkMode Collect Result',\n",
       " 'model_suffix_encoded',\n",
       " 'cleaned_workorder_encoded',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Stage1_Circle_Distance_Speed_Dam',\n",
       " 'Stage2_Circle_Distance_Speed_Dam',\n",
       " 'Stage3_Circle_Distance_Speed_Dam',\n",
       " 'CURE_DISTANCE_Dam',\n",
       " 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam',\n",
       " 'HEAD NORMAL DISTANCE_TRIANGLE_area_Dam',\n",
       " 'HEAD NORMAL DISTANCE_TRIANGLE_height_Dam',\n",
       " 'volume_time_multip_stage1_Dam',\n",
       " 'volume_time_multip_stage2_Dam',\n",
       " 'volume_time_multip_stage3_Dam',\n",
       " 'volume_time_multip_avg_Dam',\n",
       " 'average_thickness_Dam',\n",
       " 'time_ratio_Dam',\n",
       " 'stage1_line13_distance_speed_Dam_encoded',\n",
       " 'stage1_line24_distance_speed_Dam_encoded',\n",
       " 'stage2_line13_distance_speed_Dam_encoded',\n",
       " 'stage2_line24_distance_speed_Dam_encoded',\n",
       " 'stage3_line13_distance_speed_Dam_encoded',\n",
       " 'stage3_line24_distance_speed_Dam_encoded']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계를 확인할 데이터셋\n",
    "combined_variables = var_dam_fill + var_all_corr + [var for var in train_data.columns if '_Dam' in var]\n",
    "combined_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f3b4213-f3cd-4b1b-a443-33f0ef7c116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Receip_No_encoded',\n",
    " 'Equipment_same_num',   \n",
    " 'PalletID_Collect_Result_encoded',\n",
    " 'Production_Qty_Collect_Result',\n",
    " 'WorkMode Collect Result',\n",
    " 'model_suffix_encoded',\n",
    " 'cleaned_workorder_encoded',\n",
    " 'CURE SPEED Collect Result_Dam',\n",
    " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
    " 'Head Clean Position Z Collect Result_Dam',\n",
    " 'Head Purge Position Z Collect Result_Dam',\n",
    " 'Head Zero Position Y Collect Result_Dam',\n",
    " #'Stage1_Circle_Distance_Speed_Dam',\n",
    " 'Stage2_Circle_Distance_Speed_Dam',\n",
    " #'Stage3_Circle_Distance_Speed_Dam',\n",
    " 'CURE_DISTANCE_Dam',\n",
    " #'HEAD NORMAL DISTANCE_TRIANGLE_area_Dam',\n",
    " 'HEAD NORMAL DISTANCE_TRIANGLE_height_Dam',\n",
    " 'volume_time_multip_stage1_Dam',\n",
    " 'volume_time_multip_stage2_Dam',\n",
    " #'volume_time_multip_stage3_Dam',\n",
    " #'volume_time_multip_avg_Dam',\n",
    " 'average_thickness_Dam',\n",
    " 'time_ratio_Dam',\n",
    " #'stage1_line13_distance_speed_Dam_encoded',\n",
    " 'stage1_line24_distance_speed_Dam_encoded',\n",
    " #'stage2_line13_distance_speed_Dam_encoded',\n",
    " 'stage2_line24_distance_speed_Dam_encoded',\n",
    " #'stage3_line13_distance_speed_Dam_encoded',\n",
    " #'stage3_line24_distance_speed_Dam_encoded',\n",
    " 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam']\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "191577f3-3bf0-40c3-a84c-17a36794e491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 자기자신을 제외하고 상관관계 절댓값이 0.9 이상인 조합 찾기\n",
    "correlation_matrix = filtered_data.corr()\n",
    "strong_correlations = correlation_matrix[(correlation_matrix.abs() >= 0.9) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e46e96d2-e4ce-4700-accf-ee19b5c8a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    'Stage1_Circle_Distance_Speed_Dam',\n",
    "    'Stage3_Circle_Distance_Speed_Dam',\n",
    "    'HEAD NORMAL DISTANCE_TRIANGLE_area_Dam',\n",
    "    'stage1_line24_distance_speed_Dam_encoded',\n",
    "    'stage2_line13_distance_speed_Dam_encoded',\n",
    "    'stage3_line13_distance_speed_Dam_encoded',\n",
    "    'stage3_line24_distance_speed_Dam_encoded',\n",
    "    'volume_time_multip_stage3_Dam',\n",
    "    'volume_time_multip_avg_Dam'\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "546c8eb3-b124-4668-a421-3d80a4614070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06ebb3fc-5dca-467b-a339-10dc195f6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 23 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Receip_No_encoded                             40506 non-null  float64\n",
      " 1   Equipment_same_num                            40506 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded               40506 non-null  float64\n",
      " 3   Production_Qty_Collect_Result                 40506 non-null  int64  \n",
      " 4   WorkMode Collect Result                       40506 non-null  float64\n",
      " 5   target                                        40506 non-null  object \n",
      " 6   model_suffix_encoded                          40506 non-null  float64\n",
      " 7   cleaned_workorder_encoded                     40506 non-null  float64\n",
      " 8   CURE SPEED Collect Result_Dam                 40506 non-null  int64  \n",
      " 9   DISCHARGED SPEED OF RESIN Collect Result_Dam  40506 non-null  int64  \n",
      " 10  Head Clean Position Z Collect Result_Dam      40506 non-null  float64\n",
      " 11  Head Purge Position Z Collect Result_Dam      40506 non-null  float64\n",
      " 12  Head Zero Position Y Collect Result_Dam       40506 non-null  float64\n",
      " 13  Stage2_Circle_Distance_Speed_Dam              40506 non-null  int64  \n",
      " 14  CURE_DISTANCE_Dam                             40506 non-null  float64\n",
      " 15  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam        40506 non-null  float64\n",
      " 16  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam      40506 non-null  float64\n",
      " 17  volume_time_multip_stage1_Dam                 40506 non-null  float64\n",
      " 18  volume_time_multip_stage2_Dam                 40506 non-null  float64\n",
      " 19  average_thickness_Dam                         40506 non-null  float64\n",
      " 20  time_ratio_Dam                                40506 non-null  float64\n",
      " 21  stage1_line13_distance_speed_Dam_encoded      40506 non-null  float64\n",
      " 22  stage2_line24_distance_speed_Dam_encoded      40506 non-null  float64\n",
      "dtypes: float64(17), int64(5), object(1)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_dam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55af86b5-3648-403e-a628-5f9338d2b558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 24 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Receip_No_encoded                             17361 non-null  float64\n",
      " 1   Equipment_same_num                            17361 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded               17361 non-null  float64\n",
      " 3   Production_Qty_Collect_Result                 17361 non-null  int64  \n",
      " 4   WorkMode Collect Result                       17361 non-null  float64\n",
      " 5   Set ID                                        17361 non-null  object \n",
      " 6   target                                        0 non-null      float64\n",
      " 7   model_suffix_encoded                          17361 non-null  float64\n",
      " 8   cleaned_workorder_encoded                     17361 non-null  float64\n",
      " 9   CURE SPEED Collect Result_Dam                 17361 non-null  int64  \n",
      " 10  DISCHARGED SPEED OF RESIN Collect Result_Dam  17361 non-null  int64  \n",
      " 11  Head Clean Position Z Collect Result_Dam      17361 non-null  float64\n",
      " 12  Head Purge Position Z Collect Result_Dam      17361 non-null  float64\n",
      " 13  Head Zero Position Y Collect Result_Dam       17361 non-null  float64\n",
      " 14  Stage2_Circle_Distance_Speed_Dam              17361 non-null  int64  \n",
      " 15  CURE_DISTANCE_Dam                             17361 non-null  float64\n",
      " 16  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam        17361 non-null  float64\n",
      " 17  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam      17361 non-null  float64\n",
      " 18  volume_time_multip_stage1_Dam                 17361 non-null  float64\n",
      " 19  volume_time_multip_stage2_Dam                 17361 non-null  float64\n",
      " 20  average_thickness_Dam                         17361 non-null  float64\n",
      " 21  time_ratio_Dam                                17361 non-null  float64\n",
      " 22  stage1_line13_distance_speed_Dam_encoded      17361 non-null  float64\n",
      " 23  stage2_line24_distance_speed_Dam_encoded      17361 non-null  float64\n",
      "dtypes: float64(18), int64(5), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_dam.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7ec95-7c4b-4dd3-a4ee-071014866652",
   "metadata": {},
   "source": [
    "- fill1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "954ac003-7985-46ce-bfda-ab7faf341348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Receip_No_encoded',\n",
       " 'Equipment_same_num',\n",
       " 'PalletID_Collect_Result_encoded',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'WorkMode Collect Result',\n",
       " 'model_suffix_encoded',\n",
       " 'cleaned_workorder_encoded',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
       " 'Head Purge Position Z Collect Result_Fill1',\n",
       " 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1',\n",
       " 'HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1',\n",
       " 'HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1',\n",
       " 'volume_time_multip_stage1_Fill1',\n",
       " 'volume_time_multip_stage2_Fill1',\n",
       " 'volume_time_multip_stage3_Fill1',\n",
       " 'volume_time_multip_avg_Fill1',\n",
       " 'time_ratio_Fill1']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계를 확인할 데이터셋\n",
    "combined_variables = var_dam_fill + var_all_corr + [var for var in train_data.columns if '_Fill1' in var]\n",
    "combined_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12fb0b0a-ebf3-42a5-9d69-8032db061a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Receip_No_encoded',\n",
    " 'Equipment_same_num',\n",
    " 'PalletID_Collect_Result_encoded',\n",
    " 'Production_Qty_Collect_Result',\n",
    " 'WorkMode Collect Result',\n",
    " 'model_suffix_encoded',\n",
    " 'cleaned_workorder_encoded',\n",
    " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
    " 'Head Purge Position Z Collect Result_Fill1',\n",
    " 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1',\n",
    " #'HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1',\n",
    " 'HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1',\n",
    " #'volume_time_multip_avg_Fill1',\n",
    " 'volume_time_multip_stage1_Fill1',\n",
    " #'volume_time_multip_stage2_Fill1',\n",
    " #'volume_time_multip_stage3_Fill1',\n",
    " 'time_ratio_Fill1']\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99c6f69f-b57e-4c54-a42b-7f81a9fb3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 자기자신을 제외하고 상관관계 절댓값이 0.9 이상인 조합 찾기\n",
    "correlation_matrix = filtered_data.corr()\n",
    "strong_correlations = correlation_matrix[(correlation_matrix.abs() >= 0.9) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d308bfe8-5f8d-4943-b8b7-2476ac8977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1',\n",
    "    'volume_time_multip_avg_Fill1',\n",
    "    'volume_time_multip_stage2_Fill1',\n",
    "    'volume_time_multip_stage3_Fill1'\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10e0b1bb-f000-49c2-8432-d595149766a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fface952-5ca0-4d5b-9184-71de30e02084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Receip_No_encoded                               40506 non-null  float64\n",
      " 1   Equipment_same_num                              40506 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded                 40506 non-null  float64\n",
      " 3   Production_Qty_Collect_Result                   40506 non-null  int64  \n",
      " 4   WorkMode Collect Result                         40506 non-null  float64\n",
      " 5   target                                          40506 non-null  object \n",
      " 6   model_suffix_encoded                            40506 non-null  float64\n",
      " 7   cleaned_workorder_encoded                       40506 non-null  float64\n",
      " 8   DISCHARGED SPEED OF RESIN Collect Result_Fill1  40506 non-null  float64\n",
      " 9   Head Purge Position Z Collect Result_Fill1      40506 non-null  float64\n",
      " 10  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1        40506 non-null  float64\n",
      " 11  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1      40506 non-null  float64\n",
      " 12  volume_time_multip_stage1_Fill1                 40506 non-null  float64\n",
      " 13  time_ratio_Fill1                                40506 non-null  float64\n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_fill1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55dedb1b-a829-4dc4-aaf7-960a5e66725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Receip_No_encoded                               17361 non-null  float64\n",
      " 1   Equipment_same_num                              17361 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded                 17361 non-null  float64\n",
      " 3   Production_Qty_Collect_Result                   17361 non-null  int64  \n",
      " 4   WorkMode Collect Result                         17361 non-null  float64\n",
      " 5   Set ID                                          17361 non-null  object \n",
      " 6   target                                          0 non-null      float64\n",
      " 7   model_suffix_encoded                            17361 non-null  float64\n",
      " 8   cleaned_workorder_encoded                       17361 non-null  float64\n",
      " 9   DISCHARGED SPEED OF RESIN Collect Result_Fill1  17361 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Fill1      17361 non-null  float64\n",
      " 11  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1        17361 non-null  float64\n",
      " 12  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1      17361 non-null  float64\n",
      " 13  volume_time_multip_stage1_Fill1                 17361 non-null  float64\n",
      " 14  time_ratio_Fill1                                17361 non-null  float64\n",
      "dtypes: float64(12), int64(2), object(1)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_fill1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9feaf-2d9e-48e6-ac73-0b2643b5f1ad",
   "metadata": {},
   "source": [
    "- fill2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24b711c3-9126-4c06-bf22-a2d9a6c6f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Receip_No_encoded',\n",
       " 'Equipment_same_num',\n",
       " 'PalletID_Collect_Result_encoded',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'WorkMode Collect Result',\n",
       " 'model_suffix_encoded',\n",
       " 'cleaned_workorder_encoded',\n",
       " 'CURE SPEED Collect Result_Fill2',\n",
       " 'Head Purge Position Z Collect Result_Fill2',\n",
       " 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2',\n",
       " 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2',\n",
       " 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2',\n",
       " 'time_ratio_Fill2',\n",
       " 'cure_end_position_XZ_Fill2_encoded',\n",
       " 'cure_start_position_XZ_Fill2_encoded',\n",
       " 'cure_standby_position_XZ_Fill2_encoded']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계를 확인할 데이터셋\n",
    "combined_variables = var_dam_fill + var_all_corr + [var for var in train_data.columns if '_Fill2' in var]\n",
    "combined_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "724c38f3-162a-40b8-9d89-16e60a4352a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Receip_No_encoded',\n",
    " 'Equipment_same_num',\n",
    " 'PalletID_Collect_Result_encoded',\n",
    " 'Production_Qty_Collect_Result',\n",
    " 'WorkMode Collect Result',\n",
    " 'model_suffix_encoded',\n",
    " 'cleaned_workorder_encoded',\n",
    " 'CURE SPEED Collect Result_Fill2',\n",
    " 'Head Purge Position Z Collect Result_Fill2',\n",
    " 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2',\n",
    " #'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2',\n",
    " #'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2',\n",
    " 'time_ratio_Fill2',\n",
    " 'cure_end_position_XZ_Fill2_encoded',\n",
    " 'cure_start_position_XZ_Fill2_encoded']\n",
    " #'cure_standby_position_XZ_Fill2_encoded']\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d073348d-b1f7-4c87-b50b-29c2f134ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 자기자신을 제외하고 상관관계 절댓값이 0.9 이상인 조합 찾기\n",
    "correlation_matrix = filtered_data.corr()\n",
    "strong_correlations = correlation_matrix[(correlation_matrix.abs() >= 0.9) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa5ccf89-2670-4213-a96e-8df0f8696147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2',\n",
    "    'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2',\n",
    "    'cure_standby_position_XZ_Fill2_encoded'\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52952fee-4bfa-4e5a-a2af-c78c32ccd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7764523-db87-4736-b96c-cbab7cce7e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Receip_No_encoded                           40506 non-null  float64\n",
      " 1   Equipment_same_num                          40506 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded             40506 non-null  float64\n",
      " 3   Production_Qty_Collect_Result               40506 non-null  int64  \n",
      " 4   WorkMode Collect Result                     40506 non-null  float64\n",
      " 5   target                                      40506 non-null  object \n",
      " 6   model_suffix_encoded                        40506 non-null  float64\n",
      " 7   cleaned_workorder_encoded                   40506 non-null  float64\n",
      " 8   CURE SPEED Collect Result_Fill2             40506 non-null  int64  \n",
      " 9   Head Purge Position Z Collect Result_Fill2  40506 non-null  float64\n",
      " 10  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2    40506 non-null  float64\n",
      " 11  time_ratio_Fill2                            40506 non-null  float64\n",
      " 12  cure_end_position_XZ_Fill2_encoded          40506 non-null  float64\n",
      " 13  cure_start_position_XZ_Fill2_encoded        40506 non-null  float64\n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_fill2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7513b854-2823-4494-a669-fa552fdfe5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 15 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   Receip_No_encoded                           17361 non-null  float64\n",
      " 1   Equipment_same_num                          17361 non-null  int64  \n",
      " 2   PalletID_Collect_Result_encoded             17361 non-null  float64\n",
      " 3   Production_Qty_Collect_Result               17361 non-null  int64  \n",
      " 4   WorkMode Collect Result                     17361 non-null  float64\n",
      " 5   Set ID                                      17361 non-null  object \n",
      " 6   target                                      0 non-null      float64\n",
      " 7   model_suffix_encoded                        17361 non-null  float64\n",
      " 8   cleaned_workorder_encoded                   17361 non-null  float64\n",
      " 9   CURE SPEED Collect Result_Fill2             17361 non-null  int64  \n",
      " 10  Head Purge Position Z Collect Result_Fill2  17361 non-null  float64\n",
      " 11  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2    17361 non-null  float64\n",
      " 12  time_ratio_Fill2                            17361 non-null  float64\n",
      " 13  cure_end_position_XZ_Fill2_encoded          17361 non-null  float64\n",
      " 14  cure_start_position_XZ_Fill2_encoded        17361 non-null  float64\n",
      "dtypes: float64(11), int64(3), object(1)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_fill2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8510d04-48c5-42c2-9a0c-10532decda68",
   "metadata": {},
   "source": [
    "- autoclave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d43c5ca3-0bff-4ee1-b35d-488abb63f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_suffix_encoded',\n",
       " 'cleaned_workorder_encoded',\n",
       " 'Chamber Temp. Collect Result_AutoClave',\n",
       " '1st_pressure_time_AutoClave',\n",
       " '2nd_pressure_time_AutoClave',\n",
       " '3rd_pressure_time_AutoClave',\n",
       " 'avg_pressure_time_AutoClave',\n",
       " 'time_ratio_AutoClave']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상관관계를 확인할 데이터셋\n",
    "combined_variables = var_all_corr + [var for var in train_data.columns if '_AutoClave' in var]\n",
    "combined_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2bc07fd-d3f7-4fae-9794-6851cad4d945",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['model_suffix_encoded',\n",
    " 'cleaned_workorder_encoded',\n",
    " 'Chamber Temp. Collect Result_AutoClave',\n",
    " '1st_pressure_time_AutoClave',\n",
    " '2nd_pressure_time_AutoClave',\n",
    " '3rd_pressure_time_AutoClave',\n",
    " #'avg_pressure_time_AutoClave',\n",
    " 'time_ratio_AutoClave']\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54d4680e-9f74-40dc-b876-5c5cd3f275cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 자기자신을 제외하고 상관관계 절댓값이 0.9 이상인 조합 찾기\n",
    "correlation_matrix = filtered_data.corr()\n",
    "strong_correlations = correlation_matrix[(correlation_matrix.abs() >= 0.9) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bacd287-b6e1-445a-9aee-91a671ff689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = ['avg_pressure_time_AutoClave']\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1eaf9215-077b-48c3-960b-e529c7d4fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4c87f106-0c6f-4ef8-a0d2-66b248bc6558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   target                                  40506 non-null  object \n",
      " 1   model_suffix_encoded                    40506 non-null  float64\n",
      " 2   cleaned_workorder_encoded               40506 non-null  float64\n",
      " 3   Chamber Temp. Collect Result_AutoClave  40506 non-null  int64  \n",
      " 4   1st_pressure_time_AutoClave             40506 non-null  float64\n",
      " 5   2nd_pressure_time_AutoClave             40506 non-null  float64\n",
      " 6   3rd_pressure_time_AutoClave             40506 non-null  float64\n",
      " 7   time_ratio_AutoClave                    40506 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_autoclave.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dda67180-a829-40cf-8eb8-ed5300d19730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Set ID                                  17361 non-null  object \n",
      " 1   target                                  0 non-null      float64\n",
      " 2   model_suffix_encoded                    17361 non-null  float64\n",
      " 3   cleaned_workorder_encoded               17361 non-null  float64\n",
      " 4   Chamber Temp. Collect Result_AutoClave  17361 non-null  int64  \n",
      " 5   1st_pressure_time_AutoClave             17361 non-null  float64\n",
      " 6   2nd_pressure_time_AutoClave             17361 non-null  float64\n",
      " 7   3rd_pressure_time_AutoClave             17361 non-null  float64\n",
      " 8   time_ratio_AutoClave                    17361 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data_autoclave.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ba56836-3c51-4db5-88a6-f40690691927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 CSV 파일로 저장\n",
    "train_data.to_csv('./data/train_data_0827.csv', index=False)\n",
    "test_data.to_csv('./data/test_data_0827.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61f88",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7109eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992abeb2",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "263a0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train_data_0827.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_data_0827.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09519b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1921b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65fce5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "39761840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67f200d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a737fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a21881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3bb4e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e62b83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "db275bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 40\n",
      "train_data_dam DataFrame의 칼럼 수: 23\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 41\n",
      "test_data_dam DataFrame의 칼럼 수: 24\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948dcc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bb821",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb07f26",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f9553c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, weight_dam, weight_autoclave, weight_fill1, weight_fill2, weight_all, method='soft'):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    \n",
    "    weights_sum = weight_dam + weight_autoclave + weight_fill1 + weight_fill2 + weight_all\n",
    "    \n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.sum(preds_or_probs, axis=0)/weights_sum\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "#         final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return soft_voting_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a6b1e",
   "metadata": {},
   "source": [
    "### 공정별 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472385f",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95fd9240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_dam 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill1 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill2 데이터로 학습 완료\n",
      "lgbm 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'lgbm', train_data_dam\n",
    "    , n_estimators=2470\n",
    "    , num_leaves=2454\n",
    "    , max_depth=26\n",
    "    , learning_rate=0.06067228197373452\n",
    "    , min_child_samples=134\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'lgbm', train_data_autoclave\n",
    "    , n_estimators=731\n",
    "    , num_leaves=996\n",
    "    , max_depth=273\n",
    "    , learning_rate=0.0912254393922836\n",
    "    , min_child_samples=195\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill1\n",
    "    , n_estimators=821\n",
    "    , num_leaves=1400\n",
    "    , max_depth=52\n",
    "    , learning_rate=0.002743887584386348\n",
    "    , min_child_samples=231\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill2\n",
    "    , n_estimators=1005\n",
    "    , num_leaves=2304\n",
    "    , max_depth=293\n",
    "    , learning_rate=0.08460539739469425\n",
    "    , min_child_samples=272\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'lgbm', train_data\n",
    "    , n_estimators=1496\n",
    "    , num_leaves=1611\n",
    "    , max_depth=148\n",
    "    , learning_rate=0.0822880159816304\n",
    "    , min_child_samples=194\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "lgbm_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]*1.016326\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]*1.068247\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]*1.024997\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]*1.094063\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0652f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10994719 0.0578246  0.10638045 ... 0.11771606 0.08341797 0.04803441]\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(lgbm_probs, 1.016326, 1.068247, 1.024997, 1, 1.094063, method='soft')\n",
    "print(final_predictions)\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "50adb1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습 완료\n",
      "xgb 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill1 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill2 데이터로 학습 완료\n",
      "xgb 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1244\n",
    "    , learning_rate = 0.1258535425769987\n",
    "    , max_depth = 26\n",
    "    , alpha = 2.1820842842359597e-06\n",
    "    , gamma = 0.00010809657684921935\n",
    "    , reg_alpha = 0.5844029076359536\n",
    "    , reg_lambda = 0.4748752246073433\n",
    "    , colsample_bytree = 0.9607659760060685\n",
    "    , subsample = 0.7147741317935203\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1152, \n",
    "    learning_rate = 0.02466611382982541, \n",
    "    max_depth = 29, \n",
    "    alpha = 2.9180083404308157e-05, \n",
    "    gamma = 0.00012667501319666823, \n",
    "    reg_alpha = 0.6903592486292155, \n",
    "    reg_lambda = 0.5638873235014423, \n",
    "    colsample_bytree = 0.9432782030604233, \n",
    "    subsample = 0.19192246128663584,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1899, \n",
    "    learning_rate = 0.011878583548993711, \n",
    "    max_depth = 12, \n",
    "    alpha = 0.004515243354832891,\n",
    "    gamma = 0.0015693650802180896,\n",
    "    reg_alpha = 0.7484424912256998, \n",
    "    reg_lambda = 0.27164326303977143, \n",
    "    colsample_bytree = 0.7901385059430825,\n",
    "    subsample = 0.9924662032617025,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1162, \n",
    "    learning_rate = 0.014523070494025153, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.00012198482017902725, \n",
    "    gamma = 0.001236902841680112, \n",
    "    reg_alpha = 0.7331637000614692, \n",
    "    reg_lambda = 0.5237223061096699, \n",
    "    colsample_bytree = 0.8250374170841293, \n",
    "    subsample = 0.31906427054137687,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'xgb', train_data,\n",
    "    n_estimators = 2427,\n",
    "    learning_rate = 0.010774204513905965, \n",
    "    max_depth = 17, \n",
    "    alpha = 0.0005233654110538582, \n",
    "    gamma = 5.551445919277608e-05, \n",
    "    reg_alpha = 0.9652805882189326, \n",
    "    reg_lambda = 0.3542856398135083, \n",
    "    colsample_bytree = 0.9094884645797131, \n",
    "    subsample = 0.1733751790853043,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "xgb_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]*1.046498\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]*1.181753\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]*1.040247\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]*1.248720\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bbf40ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817.6145165890048\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(xgb_probs, 1.046498, 1.181753, 1, 1.040247, 1.248720, method='soft')\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9bce67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 모델이 train_data_dam 데이터로 학습 완료\n",
      "cat 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill1 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill2 데이터로 학습 완료\n",
      "cat 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'cat', train_data_dam,\n",
    "    iterations = 1478, \n",
    "    learning_rate = 0.009068953796649421, \n",
    "    depth = 11, \n",
    "    min_data_in_leaf = 2,\n",
    "    l2_leaf_reg = 1.187291687951122,\n",
    "    random_strength = 0.43102541391012816, \n",
    "    bagging_temperature = 3.1790702578164853, \n",
    "    border_count = 155, \n",
    "    scale_pos_weight = 1.4418307437388553,\n",
    "    grow_policy = 'Depthwise',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'cat', train_data_autoclave,\n",
    "    iterations = 1299, \n",
    "    learning_rate =  0.03808793470493637, \n",
    "    depth = 9, \n",
    "    min_data_in_leaf = 5,\n",
    "    l2_leaf_reg = 4.942829707223811, \n",
    "    random_strength = 3.804933757402697, \n",
    "    bagging_temperature = 1.3151583440997139, \n",
    "    border_count = 286, \n",
    "    scale_pos_weight = 1.9749286362629779,\n",
    "    grow_policy = 'SymmetricTree',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill1,\n",
    "    iterations = 2842, \n",
    "    learning_rate = 0.01099464761153367, \n",
    "    depth = 4, \n",
    "    min_data_in_leaf = 3,\n",
    "    l2_leaf_reg = 3.7373183252945945, \n",
    "    random_strength = 9.3675281753561, \n",
    "    bagging_temperature = 4.750112155842117, \n",
    "    border_count = 160, \n",
    "    scale_pos_weight = 2.53860325765727,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill2,\n",
    "    iterations = 1458, \n",
    "    learning_rate = 0.004706507801075929, \n",
    "    depth = 13, \n",
    "    min_data_in_leaf = 4,\n",
    "    l2_leaf_reg = 1.909987690181427, \n",
    "    random_strength = 9.047942432889677, \n",
    "    bagging_temperature = 3.545210494821586, \n",
    "    border_count = 300, \n",
    "    scale_pos_weight = 3.4781865667208467,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'cat', train_data,\n",
    "    iterations=1349,\n",
    "    learning_rate=0.012526639112437014,\n",
    "    depth=9,\n",
    "    min_data_in_leaf=4,\n",
    "    l2_leaf_reg=2.245006704049574,\n",
    "    random_strength=0.6922797458293842,\n",
    "    bagging_temperature=8.230635636022027,\n",
    "    border_count=211,\n",
    "    scale_pos_weight=2.0709015241138236,\n",
    "    grow_policy='Depthwise',\n",
    "    \n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='F1',\n",
    "    logging_level='Silent',\n",
    "    boosting_type='Plain'\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "cat_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]*1.046879\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]*1.033952\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]*1.015782\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]*1.018504\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "56a7a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796.276563443661\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(cat_probs, 1.046879, 1.033952, 1.015782, 1.018504, 1, method='soft')\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_cat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "725d2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm = pd.read_csv('./data/data0827_lgbm.csv')\n",
    "df_xgb = pd.read_csv('./data/data0827_xgb.csv')\n",
    "df_cat = pd.read_csv('./data/data0827_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c80d0487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "32941fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['target'] = df_lgbm['target'] + df_xgb['target'] + df_cat['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "17c37d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_value = df_sub['target'].quantile(0.965)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "db32c02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725200611460201"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "48ed63e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x >= quantile_value else 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "35a9cfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      16753\n",
       "AbNormal      608\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6b8015a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f2457dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fda1af6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      16753\n",
       "AbNormal      608\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0d3cf",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
