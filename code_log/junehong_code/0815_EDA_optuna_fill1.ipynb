{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a6bbc",
   "metadata": {},
   "source": [
    "기본 전처리 할것들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1367da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Workorder_AutoClave' 열에서 '-' 다음 숫자 값 추출 및 '000' 제거\n",
    "train_data['Workorder'] = train_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)\n",
    "test_data['Workorder'] = test_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispenser_num 값에 따라 새로운 변수 생성\n",
    "train_data['Dispenser_1'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "train_data['Dispenser_2'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "test_data['Dispenser_1'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "test_data['Dispenser_2'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['Dispenser_num'], axis=1, inplace=True)\n",
    "test_data.drop(['Dispenser_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2e5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ab6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_receip_no_collect_result(df):\n",
    "    df['Receip_No_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Receip No Collect Result_Dam'] \n",
    "                    if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_receip_no_collect_result(train_data)\n",
    "create_receip_no_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60cd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Receip No Collect Result_Dam',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f9a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['PalletID_Collect_Result'] = df.apply(\n",
    "        lambda row: row['PalletID Collect Result_Dam'] \n",
    "                    if (row['PalletID Collect Result_Dam'] == row['PalletID Collect Result_Fill1'] == row['PalletID Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f7c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['Production_Qty_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Production Qty Collect Result_Dam'] \n",
    "                    if (row['Production Qty Collect Result_Dam'] == row['Production Qty Collect Result_Fill1'] == row['Production Qty Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fdec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Chamber Temp. Judge Value_AutoClave\" 변수의 값을 기준으로 파생 변수 생성 함수\n",
    "def create_judge_value_binary(df):\n",
    "    df['Chamber_Temp_OKNG_AutoClave'] = df['Chamber Temp. Judge Value_AutoClave'].apply(\n",
    "        lambda x: 1 if x == 'OK' else 0\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_binary(train_data)\n",
    "create_judge_value_binary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd9ccf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Judge Value 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "Chamber Temp. Judge Value_AutoClave\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'Judge Value'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Judge Value').columns\n",
    "\n",
    "print(\"\\n Judge Value 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 변수 목록\n",
    "judge_value_columns = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_judge_value_feature(df):\n",
    "    df['Judge_Value_OK'] = df[judge_value_columns].apply(\n",
    "        lambda row: 1 if any(row == 'OK') else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_feature(train_data)\n",
    "create_judge_value_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Chamber Temp. Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb1e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 변경\n",
    "train_data = train_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})\n",
    "test_data = test_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cdd01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 108 entries, Model.Suffix to Judge_Value_OK\n",
      "dtypes: float64(56), int64(49), object(3)\n",
      "memory usage: 33.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c4b1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 109 entries, Set ID to Judge_Value_OK\n",
      "dtypes: float64(86), int64(20), object(3)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d3595",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54df9c3",
   "metadata": {},
   "source": [
    "반복적으로 쓰는 툴 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d2efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, col_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 열 이름에 대해 박스 플롯을 그리는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.boxplot(df[col_name], vert=False)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.title(f'Box Plot of {col_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7515da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_ratio(df, col_name, target_name='target'):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 비율과 갯수, 총 갯수를 출력하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 데이터프레임\n",
    "    col_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    \"\"\"\n",
    "    # 각 값마다 타겟 변수의 비율 계산\n",
    "    value_counts = df.groupby(col_name)[target_name].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 타겟 변수의 갯수 계산\n",
    "    counts = df.groupby(col_name)[target_name].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 총 갯수 계산\n",
    "    total_counts = df[col_name].value_counts().rename('Total_Count')\n",
    "    \n",
    "    # 비율과 갯수를 합침\n",
    "    result = value_counts.join(counts, lsuffix='_ratio', rsuffix='_count')\n",
    "    \n",
    "    # 총 갯수를 합침\n",
    "    result = result.join(total_counts, on=col_name)\n",
    "    \n",
    "    # 출력 형식 조정\n",
    "    result.index.name = 'variable'\n",
    "    print(f\"\\n{col_name}별 {target_name} 비율 및 갯수\\n\")\n",
    "    print(result.rename(columns=lambda x: x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eed238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_group(df, group_by_columns):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_columns)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AdNormal' 비율과 갯수 계산\n",
    "        adnormal_count = group['target'].value_counts().get('AbNormal', 0)\n",
    "        adnormal_ratio = adnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, adnormal_count, adnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', \"'AdNormal' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그룹화된 변수들의 이름을 제목행으로 출력\n",
    "    print(f\"Grouped by: {', '.join(group_by_columns)}\")\n",
    "    print()\n",
    "    # 데이터프레임 출력\n",
    "    print(results_df)\n",
    "\n",
    "# 예시코드\n",
    "# summarize_grouped_data(train_data, ['1st Pressure Collect Result_AutoClave', '1st Pressure Unit Time_AutoClave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4bfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio(df, group_by_column, target_column='target', abnormal_value='AbNormal'):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_column)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AbNormal' 비율과 갯수 계산\n",
    "        abnormal_count = group[target_column].value_counts().get(abnormal_value, 0)\n",
    "        abnormal_ratio = abnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, abnormal_count, abnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', f\"'{abnormal_value}' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # 막대 그래프 생성\n",
    "    ax = results_df.plot(kind='bar', x='group', y='ratio', legend=False)\n",
    "    \n",
    "    # 각 막대 위에 AbNormal 갯수와 총 갯수 표시\n",
    "    for i, (abnormal_count, total) in enumerate(zip(results_df[f\"'{abnormal_value}' count\"], results_df['Total'])):\n",
    "        ax.text(i, results_df['ratio'][i], f'{abnormal_count} ({total})', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "     # 그래프 제목 및 축 레이블 설정\n",
    "    ax.set_title(f'{abnormal_value} Ratio by {group_by_column}')\n",
    "    ax.set_xlabel(group_by_column)\n",
    "    ax.set_ylabel(f'{abnormal_value} Ratio')\n",
    "   \n",
    "    # 그래프 출력\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aad45361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_ratio_boxplot(data, time_ratio_column, target_column='target'):\n",
    "    # 그래프 스타일 설정\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=time_ratio_column, y=target_column, data=data)\n",
    "\n",
    "    # 그래프 제목 및 레이블 설정\n",
    "    plt.title(f'{time_ratio_column} vs {target_column}')\n",
    "    plt.xlabel(time_ratio_column)\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    # 그래프 출력\n",
    "    plt.show()\n",
    "\n",
    "# 함수 호출 예제\n",
    "#plot_time_ratio_vs_target(train_data, 'time_ratio_Dam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8a90c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e84bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model.Suffix',\n",
       " 'Workorder',\n",
       " 'CURE END POSITION X Collect Result_Dam',\n",
       " 'CURE END POSITION Z Collect Result_Dam',\n",
       " 'CURE END POSITION Θ Collect Result_Dam',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'CURE START POSITION X Collect Result_Dam',\n",
       " 'CURE START POSITION Θ Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage1) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage2) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Head Zero Position Z Collect Result_Dam',\n",
       " 'Machine Tact time Collect Result_Dam',\n",
       " 'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
       " 'THICKNESS 1 Collect Result_Dam',\n",
       " 'THICKNESS 2 Collect Result_Dam',\n",
       " 'THICKNESS 3 Collect Result_Dam',\n",
       " 'WorkMode Collect Result',\n",
       " '1st Pressure Collect Result_AutoClave',\n",
       " '1st Pressure Unit Time_AutoClave',\n",
       " '2nd Pressure Collect Result_AutoClave',\n",
       " '2nd Pressure Unit Time_AutoClave',\n",
       " '3rd Pressure Collect Result_AutoClave',\n",
       " '3rd Pressure Unit Time_AutoClave',\n",
       " 'Chamber Temp. Collect Result_AutoClave',\n",
       " 'Chamber Temp. Unit Time_AutoClave',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage1) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage2) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
       " 'Head Purge Position Z Collect Result_Fill1',\n",
       " 'Machine Tact time Collect Result_Fill1',\n",
       " 'CURE END POSITION X Collect Result_Fill2',\n",
       " 'CURE END POSITION Z Collect Result_Fill2',\n",
       " 'CURE SPEED Collect Result_Fill2',\n",
       " 'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
       " 'CURE START POSITION X Collect Result_Fill2',\n",
       " 'CURE START POSITION Z Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2',\n",
       " 'Head Purge Position Z Collect Result_Fill2',\n",
       " 'Machine Tact time Collect Result_Fill2',\n",
       " 'target',\n",
       " 'Dispenser_1',\n",
       " 'Dispenser_2',\n",
       " 'Receip_No_Collect_Result',\n",
       " 'PalletID_Collect_Result',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'Chamber_Temp_OKNG_AutoClave',\n",
       " 'Judge_Value_OK']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9465e",
   "metadata": {},
   "source": [
    "### 1. CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45bdcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'와 '_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33dc2f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION Θ Collect Result_Dam, CURE START POSITION Θ Collect Result_Dam\n",
      "\n",
      "              group  'AdNormal' count     ratio  Total\n",
      "0  (0, 0, -90, -90)                19  1.000000     19\n",
      "1    (0, 0, 90, 90)                15  1.000000     15\n",
      "2    (0, 1, 90, 90)               850  0.054977  15461\n",
      "3  (1, 0, -90, -90)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE START POSITION X Collect Result_Dam'\n",
    ", 'CURE START POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aff796",
   "metadata": {},
   "source": [
    "dispenser 종류에 따라 POSITION Θ 값이 따라감  \n",
    "-> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2bcdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION Θ Collect Result_Dam'\n",
    "    , 'CURE START POSITION Θ Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b7aff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61cf9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION X Collect Result_Dam, CURE END POSITION Z Collect Result_Dam, CURE START POSITION X Collect Result_Dam\n",
      "\n",
      "                     group  'AdNormal' count     ratio  Total\n",
      "0   (0, 0, 240, 2.5, 1030)                19  1.000000     19\n",
      "1  (0, 0, 1000, 12.5, 280)                15  1.000000     15\n",
      "2  (0, 1, 1000, 12.5, 280)               850  0.054977  15461\n",
      "3   (1, 0, 240, 2.5, 1030)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    ", 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Z Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    ", 'CURE START POSITION X Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d641dc",
   "metadata": {},
   "source": [
    "좌표값을 통해 좌표간의 거리를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d3ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Dam'\n",
    "start_z_col = 33.5\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Dam'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5fa846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Fill2'\n",
    "start_z_col = 'CURE START POSITION Z Collect Result_Fill2'\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Fill2'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Fill2'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbe2fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE START POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "    , 'CURE START POSITION X Collect Result_Fill2'\n",
    "    , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "    , 'CURE END POSITION X Collect Result_Fill2'\n",
    "    , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b9efd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46e713c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "\n",
      "   group  'AdNormal' count     ratio  Total\n",
      "0     22                34  0.072495    469\n",
      "1     23                22  0.107843    204\n",
      "2     32               421  0.085866   4903\n",
      "3     33              1873  0.053622  34930\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    " 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE_DISTANCE_Dam'\n",
    "# , 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b3d80",
   "metadata": {},
   "source": [
    "'CURE STANDBY POSITION Z Collect Result_Fill2' 변수의 유의미함을 찾을수 x  \n",
    "다른 변수와 연결된만한것도 찾지 못함 -> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc313406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = ['CURE STANDBY POSITION Z Collect Result_Fill2']\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50fe7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18af7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE_DISTANCE_Dam, CURE_DISTANCE_Fill2\n",
      "\n",
      "                                          group  'AdNormal' count     ratio  \\\n",
      "0              (0, 0, 720.3061848963953, 780.0)                15  1.000000   \n",
      "1               (0, 0, 790.607993888248, 780.0)                19  1.000000   \n",
      "2              (0, 1, 720.3061848963953, 780.0)               827  0.054645   \n",
      "3  (0, 1, 720.3061848963953, 780.0006410253776)                23  0.070552   \n",
      "4  (0, 1, 720.3061848963953, 780.0775602464155)                 0  0.000000   \n",
      "5               (1, 0, 790.607993888248, 780.0)              1129  0.054418   \n",
      "6   (1, 0, 790.607993888248, 780.0006410253776)               286  0.077591   \n",
      "7   (1, 0, 790.607993888248, 780.0640999302557)                51  0.088235   \n",
      "\n",
      "   Total  \n",
      "0     15  \n",
      "1     19  \n",
      "2  15134  \n",
      "3    326  \n",
      "4      1  \n",
      "5  20747  \n",
      "6   3686  \n",
      "7    578  \n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    ", 'CURE_DISTANCE_Dam'\n",
    ", 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dbf40",
   "metadata": {},
   "source": [
    "거리의 차이에 따라 ratio 값 변화 크지 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c26ff29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 / 속도 -> 시간 파생 변수 생성\n",
    "train_data['CURE_Time_Dam']  = train_data['CURE_DISTANCE_Dam'] / train_data['CURE SPEED Collect Result_Dam']\n",
    "test_data['CURE_Time_Dam']  = test_data['CURE_DISTANCE_Dam'] / test_data['CURE SPEED Collect Result_Dam']\n",
    "\n",
    "train_data['CURE_Time_Fill2']  = train_data['CURE_DISTANCE_Fill2'] / train_data['CURE SPEED Collect Result_Fill2']\n",
    "test_data['CURE_Time_Fill2']  = test_data['CURE_DISTANCE_Fill2'] / test_data['CURE SPEED Collect Result_Fill2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48b4c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4195b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE_DISTANCE_Dam'\n",
    "    , 'CURE SPEED Collect Result_Dam'\n",
    "    , 'CURE_DISTANCE_Fill2'\n",
    "    , 'CURE SPEED Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d0840f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caac149",
   "metadata": {},
   "source": [
    "### 2. HEAD NORMAL COORDINATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39a38fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL COORDINATE 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL COORDINATE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL COORDINATE').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL COORDINATE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "287f0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Dam'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Dam'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efb87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd662cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9fb0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0df37c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac6abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c4cf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9688a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47c86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fa789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a2e0",
   "metadata": {},
   "source": [
    "### 3. RESIN(처리x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91c64cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'RESIN' 또는 'Dispense Volume' 포함 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4652063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispense Volume(Stage1) Collect Result_Dam, Dispense Volume(Stage2) Collect Result_Dam, Dispense Volume(Stage3) Collect Result_Dam\n",
      "\n",
      "                  group  'AdNormal' count     ratio  Total\n",
      "0    (0.67, 0.26, 1.49)                 8  0.075472    106\n",
      "1    (0.67, 0.27, 1.49)               277  0.086293   3210\n",
      "2    (0.67, 0.28, 1.49)                 0  0.000000      2\n",
      "3    (0.67, 0.33, 1.49)                51  0.099415    513\n",
      "4    (0.67, 0.34, 1.49)               467  0.082276   5676\n",
      "..                  ...               ...       ...    ...\n",
      "155  (1.63, 0.92, 1.49)                41  0.048810    840\n",
      "156  (1.63, 0.93, 1.49)                46  0.080844    569\n",
      "157  (1.63, 0.94, 1.49)                34  0.068273    498\n",
      "158  (2.34, 0.71, 1.49)                 0  0.000000      1\n",
      "159  (2.34, 0.72, 1.49)                 0  0.000000      3\n",
      "\n",
      "[160 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    " 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    ", 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1d5d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_time_speed_product(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         speed_col = 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Time_x_Speed_{stage}_Dam'\n",
    "#         df[new_col_name] = df[time_col] * df[speed_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_time_speed_product(train_data)\n",
    "# create_time_speed_product(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ebb3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd57994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파생 변수 생성 함수\n",
    "# def create_volume_time_ratio(df):\n",
    "#     stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "#     for stage in stages:\n",
    "#         time_col = f'DISCHARGED TIME OF RESIN({stage}) Collect Result_Dam'\n",
    "#         volume_col = f'Dispense Volume({stage}) Collect Result_Dam'\n",
    "#         new_col_name = f'RESIN Volume_Time_Ratio_{stage}_Dam'\n",
    "#         df[new_col_name] = df[volume_col] / df[time_col]\n",
    "\n",
    "# # 함수 적용\n",
    "# create_volume_time_ratio(train_data)\n",
    "# create_volume_time_ratio(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b42b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 출력 옵션을 설정\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# # 출력 옵션을 원래대로\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df4ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "# , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    "# , 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "# # , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "# # , 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "# # , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "# # , 'RESIN Time_x_Speed_Stage1_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage2_Dam'\n",
    "# # , 'RESIN Time_x_Speed_Stage3_Dam'\n",
    "# #  'RESIN Volume_Time_Ratio_Stage1_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage2_Dam'\n",
    "# # , 'RESIN Volume_Time_Ratio_Stage3_Dam'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6643f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "# Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "# print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "# for col in Process_Desc_col:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac6aad",
   "metadata": {},
   "source": [
    "### 4. Distance Speed Collect Result_Dam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6a2ba",
   "metadata": {},
   "source": [
    "Dam 공정의 Circle, Line 길이 변수들 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f1ca6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance Speed Collect Result_Dam 포함 변수>\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance Speed Collect Result_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance Speed Collect Result_Dam').columns\n",
    "\n",
    "print(\"\\n Distance Speed Collect Result_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ac6dc",
   "metadata": {},
   "source": [
    "Stage 별 Speed 값들의 평균 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74dc87f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stage_totals(data, stages, suffix='_Distance_Speed_avg_Dam'):\n",
    "    for stage in stages:\n",
    "        stage_cols = data.filter(like=stage).columns\n",
    "        data[f'{stage}{suffix}'] = data[stage_cols].sum(axis=1) / 8\n",
    "\n",
    "stages = ['Stage1', 'Stage2', 'Stage3']\n",
    "\n",
    "# train_data에 대해 파생변수 추가\n",
    "add_stage_totals(train_data, stages)\n",
    "\n",
    "# test_data에 대해 파생변수 추가\n",
    "add_stage_totals(test_data, stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a453df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Stage1 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d2c9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance_Speed_avg_Dam 포함 변수>\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance_Speed_avg_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance_Speed_avg_Dam').columns\n",
    "\n",
    "print(\"\\n Distance_Speed_avg_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a4274",
   "metadata": {},
   "source": [
    "### 5. THICKNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1907522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "THICKNESS 1 Collect Result_Dam\n",
      "THICKNESS 2 Collect Result_Dam\n",
      "THICKNESS 3 Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3ae04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 파생변수 생성 함수\n",
    "def create_total_thickness_dam(data):\n",
    "    data['Total_THICKNESS_Collect_Result_Dam'] = (\n",
    "        data['THICKNESS 1 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 2 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 3 Collect Result_Dam']**2\n",
    "    )\n",
    "    # 기존 변수 삭제\n",
    "    data.drop(columns=[\n",
    "        'THICKNESS 1 Collect Result_Dam',\n",
    "        'THICKNESS 2 Collect Result_Dam',\n",
    "        'THICKNESS 3 Collect Result_Dam'\n",
    "    ], inplace=True)\n",
    "    return data\n",
    "\n",
    "train_data = create_total_thickness_dam(train_data)\n",
    "test_data = create_total_thickness_dam(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af96f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "Total_THICKNESS_Collect_Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4349a",
   "metadata": {},
   "source": [
    "### 6. AutoClave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27ac3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3c024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성\n",
    "train_data['1st_Pressure_x_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure Unit Time_AutoClave'] \n",
    "test_data['1st_Pressure_x_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['2nd_Pressure_x_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave'] \n",
    "test_data['2nd_Pressure_x_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['3rd_Pressure_x_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave'] \n",
    "test_data['3rd_Pressure_x_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['All_Pressure_x_AutoClave'] = train_data['1st_Pressure_x_AutoClave'] + train_data['2nd_Pressure_x_AutoClave'] + train_data['3rd_Pressure_x_AutoClave']\n",
    "test_data['All_Pressure_x_AutoClave'] = test_data['1st_Pressure_x_AutoClave'] + test_data['2nd_Pressure_x_AutoClave'] + test_data['3rd_Pressure_x_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_avg_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['All_Pressure_avg_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['Chamber_Temp_x_AutoClave'] = train_data['Chamber Temp. Collect Result_AutoClave'] * train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['Chamber_Temp_x_AutoClave'] = test_data['Chamber Temp. Collect Result_AutoClave'] * test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber_Temp_x_AutoClave']\n",
    "test_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber_Temp_x_AutoClave']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a69ad859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "# '1st Pressure Collect Result_AutoClave'\n",
    "'1st Pressure Unit Time_AutoClave'\n",
    "# , '2nd Pressure Collect Result_AutoClave'\n",
    ", '2nd Pressure Unit Time_AutoClave'\n",
    "# , '3rd Pressure Collect Result_AutoClave'\n",
    ", '3rd Pressure Unit Time_AutoClave'\n",
    "# , 'Chamber Temp. Collect Result_AutoClave'\n",
    "# , 'Chamber Temp. Unit Time_AutoClave'\n",
    "\n",
    "# , '1st_Pressure_x_AutoClave'\n",
    "# , '2nd_Pressure_x_AutoClave'\n",
    "# , '3rd_Pressure_x_AutoClave'\n",
    ", 'All_Pressure_x_AutoClave'\n",
    "# , 'All_Pressure_avg_AutoClave'\n",
    "# , 'Chamber_Temp_x_AutoClave'\n",
    "# , 'All_Pressure_frac_Chamber_Temp_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20ce50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69dcf",
   "metadata": {},
   "source": [
    "### 7. ETC.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b05ca",
   "metadata": {},
   "source": [
    "7-1. workorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e2e4240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수를 0과 1로 변환\n",
    "train_data['target_binary'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# Workorder 변수의 값에 대한 타겟 변수 비율 계산\n",
    "workorder_target_ratio = train_data.groupby('Workorder')['target_binary'].mean()\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_derived_variable(row, ratio_dict, threshold):\n",
    "    return 1 if ratio_dict.get(row['Workorder'], 0) >= threshold else 0\n",
    "\n",
    "# 파생 변수 생성\n",
    "train_data['Workorder_0.9'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "train_data['Workorder_0.7'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "train_data['Workorder_0.5'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "test_data['Workorder_0.9'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "test_data['Workorder_0.7'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "test_data['Workorder_0.5'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['target_binary'], axis=1, inplace=True)\n",
    "\n",
    "# train_data.drop(['Workorder', 'target_binary'], axis=1, inplace=True)\n",
    "# test_data.drop(['Workorder'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48c3f8",
   "metadata": {},
   "source": [
    "7-2. Machine Tact time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d866fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 총시간 대비 비율 변수\n",
    "def calculate_total_time_and_ratios(data):\n",
    "    data['total_time'] = (\n",
    "        data['Machine Tact time Collect Result_Dam'] +\n",
    "        data['Machine Tact time Collect Result_Fill1'] +\n",
    "        data['Machine Tact time Collect Result_Fill2'] +\n",
    "        data['Chamber Temp. Unit Time_AutoClave']\n",
    "    )\n",
    "    data['time_ratio_Dam'] = (data['Machine Tact time Collect Result_Dam'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill1'] = (data['Machine Tact time Collect Result_Fill1'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill2'] = (data['Machine Tact time Collect Result_Fill2'] / data['total_time']).round(3)\n",
    "    data['time_ratio_AutoClave'] = (data['Chamber Temp. Unit Time_AutoClave'] / data['total_time']).round(3)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 함수 적용\n",
    "train_data = calculate_total_time_and_ratios(train_data)\n",
    "test_data = calculate_total_time_and_ratios(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dec2a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 제거\n",
    "train_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)\n",
    "\n",
    "test_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49a7d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  object \n",
      " 1   Workorder                                              40506 non-null  object \n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(46), int64(14), object(3)\n",
      "memory usage: 19.5+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "769e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b20a3",
   "metadata": {},
   "source": [
    "## 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb37ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model.Suffix', 'Workorder', 'target'], dtype='object')  train_object_columns 갯수 : 3\n",
      "Index(['Set ID', 'Model.Suffix', 'Workorder', 'target'], dtype='object')  test_object_columns 갯수 : 4\n",
      "\n",
      "Train Data:\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 663\n",
      "target unique 값 갯수: 2\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 662\n",
      "target unique 값 갯수: 0\n"
     ]
    }
   ],
   "source": [
    "# 'target' 열의 변수 타입을 object로 변경\n",
    "# -> test 데이터는 float64 타입으로 되어있음 \n",
    "test_data['target'] = test_data['target'].astype('object')\n",
    "\n",
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "156c68be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model.Suffix  Workorder\n",
      "0      0.049336   0.158385\n",
      "1      0.049336   0.015314\n",
      "2      0.056712   0.009534\n",
      "   Model.Suffix  Workorder\n",
      "0      0.056712   0.091912\n",
      "1      0.056712   0.024247\n",
      "2      0.056712   0.091463\n",
      "--- train_data ---\n",
      "target  \n",
      "Normal      38156\n",
      "AbNormal     2350\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# 타겟 변수와 범주형 변수 지정\n",
    "## Target Encoding의 smoothing 파라미터는 default로 auto로 설정되어 있음\n",
    "target = 'target'  # 타겟 변수 이름으로 변경\n",
    "categorical_columns = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "]  # 범주형 변수 이름으로 변경\n",
    "\n",
    "# 타겟 값을 숫자로 변환\n",
    "target_mapping = {'Normal': 0, 'AbNormal': 1}\n",
    "train_data[target] = train_data[target].map(target_mapping)\n",
    "test_data[target] = test_data[target].map(target_mapping)\n",
    "\n",
    "# 열이 존재하는지 확인\n",
    "missing_columns = [col for col in categorical_columns if col not in train_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"train_data에 다음 열이 존재하지 않습니다: {missing_columns}\")\n",
    "\n",
    "# 타겟 인코더 생성 및 학습\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "train_data = encoder.fit_transform(train_data, train_data[target])\n",
    "\n",
    "# Set ID 열을 별도로 저장\n",
    "set_id = test_data['Set ID']\n",
    "\n",
    "# 테스트 데이터 인코딩 (Set ID 열 제외)\n",
    "test_data = test_data.drop(columns=['Set ID'])\n",
    "test_data = encoder.transform(test_data)\n",
    "\n",
    "# Set ID 열을 맨 앞에 추가\n",
    "test_data.insert(0, 'Set ID', set_id)\n",
    "\n",
    "# categorical_columns에 해당하는 열의 데이터 값만 확인\n",
    "print(train_data[categorical_columns].head(3))\n",
    "print(test_data[categorical_columns].head(3))\n",
    "\n",
    "# 역 매핑 딕셔너리 생성\n",
    "reverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "# 타겟 값을 원래대로 변환\n",
    "train_data[target] = train_data[target].map(reverse_target_mapping)\n",
    "test_data[target] = test_data[target].map(reverse_target_mapping)\n",
    "\n",
    "print(\"--- train_data ---\")\n",
    "\n",
    "# 변환된 타겟 값 확인\n",
    "print(train_data[[target]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a108490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(48), int64(14), object(1)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276e6df",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee950d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(\"target\", axis=1),\n",
    "    train_data[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de8996fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "def print_stats(df: pd.DataFrame):\n",
    "    num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "    num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "    print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  \\tAbnormal\\tNormal\")\n",
    "print_stats(df_train)\n",
    "print_stats(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1771a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 63 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED SPEED OF RESIN Collect Result_Dam           40506 non-null  int64  \n",
      " 3   DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam    40506 non-null  float64\n",
      " 4   DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam    40506 non-null  float64\n",
      " 5   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 6   Dispense Volume(Stage1) Collect Result_Dam             40506 non-null  float64\n",
      " 7   Dispense Volume(Stage2) Collect Result_Dam             40506 non-null  float64\n",
      " 8   Dispense Volume(Stage3) Collect Result_Dam             40506 non-null  float64\n",
      " 9   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 10  Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 11  Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 12  Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 13  WorkMode Collect Result                                40506 non-null  float64\n",
      " 14  1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 15  2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 16  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 17  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 18  DISCHARGED SPEED OF RESIN Collect Result_Fill1         40506 non-null  float64\n",
      " 19  DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1  40506 non-null  float64\n",
      " 20  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1  40506 non-null  float64\n",
      " 21  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 22  Dispense Volume(Stage1) Collect Result_Fill1           40506 non-null  float64\n",
      " 23  Dispense Volume(Stage2) Collect Result_Fill1           40506 non-null  float64\n",
      " 24  Dispense Volume(Stage3) Collect Result_Fill1           40506 non-null  float64\n",
      " 25  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 26  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 27  target                                                 40506 non-null  object \n",
      " 28  Dispenser_1                                            40506 non-null  int64  \n",
      " 29  Dispenser_2                                            40506 non-null  int64  \n",
      " 30  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 31  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 32  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 33  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 34  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 35  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 36  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 37  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 38  HEAD NORMAL DISTANCE_TRIANGLE_area_Dam                 40506 non-null  float64\n",
      " 39  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 40  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 41  HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1               40506 non-null  float64\n",
      " 42  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 43  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 44  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 45  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 46  Stage1_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 47  Stage2_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 48  Stage3_Distance_Speed_avg_Dam                          40506 non-null  float64\n",
      " 49  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 50  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 51  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 52  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 53  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 54  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 55  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 56  Workorder_0.9                                          40506 non-null  int64  \n",
      " 57  Workorder_0.7                                          40506 non-null  int64  \n",
      " 58  Workorder_0.5                                          40506 non-null  int64  \n",
      " 59  time_ratio_Dam                                         40506 non-null  float64\n",
      " 60  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 61  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 62  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(48), int64(14), object(1)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519265e7",
   "metadata": {},
   "source": [
    "공통 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "67dbaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_variables = [\n",
    "    'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[com_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf966448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Variable 1               Variable 2  Correlation\n",
      "0              Dispenser_2  PalletID_Collect_Result     0.860274\n",
      "1  PalletID_Collect_Result              Dispenser_2     0.860274\n",
      "2            Workorder_0.9            Workorder_0.7     0.747407\n",
      "3            Workorder_0.7            Workorder_0.9     0.747407\n",
      "4            Workorder_0.7            Workorder_0.5     0.816325\n",
      "5            Workorder_0.5            Workorder_0.7     0.816325\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.7) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "105fe344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 삭제\n",
    "train_data.drop(['Workorder_0.7', 'PalletID_Collect_Result'], axis=1, inplace=True)\n",
    "test_data.drop(['Workorder_0.7', 'PalletID_Collect_Result'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "807ffaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통 변수 리스트\n",
    "com_variables_train = [\n",
    "    'target'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    # , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]\n",
    "\n",
    "com_variables_test = [\n",
    "    'target'\n",
    "    , 'Set ID'\n",
    "    , 'Model.Suffix'\n",
    "    , 'Workorder'\n",
    "    , 'WorkMode Collect Result'\n",
    "    , 'Dispenser_1'\n",
    "    , 'Dispenser_2'\n",
    "    , 'Receip_No_Collect_Result'\n",
    "    # , 'PalletID_Collect_Result'\n",
    "    , 'Production_Qty_Collect_Result'\n",
    "    , 'Judge_Value_OK'\n",
    "    , 'Workorder_0.9'\n",
    "    # , 'Workorder_0.7'\n",
    "    , 'Workorder_0.5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b5911a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dam 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "Head Clean Position Z Collect Result_Dam\n",
      "Head Purge Position Z Collect Result_Dam\n",
      "Head Zero Position Y Collect Result_Dam\n",
      "Head Zero Position Z Collect Result_Dam\n",
      "CURE_Time_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "Stage1_Distance_Speed_avg_Dam\n",
      "Stage2_Distance_Speed_avg_Dam\n",
      "Stage3_Distance_Speed_avg_Dam\n",
      "Total_THICKNESS_Collect_Result_Dam\n",
      "time_ratio_Dam\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Dam 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d01ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\",\n",
    "    # \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\",\n",
    "    # \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Dam\",\n",
    "    # \"Dispense Volume(Stage3) Collect Result_Dam\",\n",
    "    \"Head Clean Position Z Collect Result_Dam\",\n",
    "    \"Head Purge Position Z Collect Result_Dam\",\n",
    "    \"Head Zero Position Y Collect Result_Dam\",\n",
    "    # \"Head Zero Position Z Collect Result_Dam\",\n",
    "    \"CURE_Time_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\",\n",
    "    # \"HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\",\n",
    "    \"Stage1_Distance_Speed_avg_Dam\",\n",
    "    \"Stage2_Distance_Speed_avg_Dam\",\n",
    "    # \"Stage3_Distance_Speed_avg_Dam\",\n",
    "    \"Total_THICKNESS_Collect_Result_Dam\",\n",
    "    \"time_ratio_Dam\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "749bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Dam\",\n",
    "    \"Head Zero Position Z Collect Result_Dam\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_area_Dam\",\n",
    "    \"Stage3_Distance_Speed_avg_Dam\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c4d0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f80651a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n",
      "time_ratio_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "566073bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"1st Pressure Collect Result_AutoClave\",\n",
    "    \"2nd Pressure Collect Result_AutoClave\",\n",
    "    \"3rd Pressure Collect Result_AutoClave\",\n",
    "    \"Chamber Temp. Collect Result_AutoClave\",\n",
    "    \"Chamber_Temp_OKNG_AutoClave\",\n",
    "    \"1st_Pressure_x_AutoClave\",\n",
    "    # \"2nd_Pressure_x_AutoClave\",\n",
    "    \"3rd_Pressure_x_AutoClave\",\n",
    "    \"All_Pressure_avg_AutoClave\",\n",
    "    \"Chamber_Temp_x_AutoClave\",\n",
    "    \"All_Pressure_frac_Chamber_Temp_AutoClave\",\n",
    "    \"time_ratio_AutoClave\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fff17e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"2nd_Pressure_x_AutoClave\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebdcf265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a03bc6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n",
      "Head Purge Position Z Collect Result_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "time_ratio_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill1').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fa145f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"DISCHARGED SPEED OF RESIN Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\",\n",
    "    \"DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\",\n",
    "    # \"Dispense Volume(Stage1) Collect Result_Fill1\",\n",
    "    # \"Dispense Volume(Stage2) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage3) Collect Result_Fill1\",\n",
    "    \"Head Purge Position Z Collect Result_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\",\n",
    "    # \"HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\",\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\",\n",
    "    \"time_ratio_Fill1\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5e63aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1\",\n",
    "    \"Dispense Volume(Stage1) Collect Result_Fill1\",\n",
    "    \"Dispense Volume(Stage2) Collect Result_Fill1\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b8ac77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04ce5f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Fill1 공정 관련 변수>\n",
      "Head Purge Position Z Collect Result_Fill2\n",
      "CURE_Time_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n",
      "time_ratio_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_Fill2').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<Fill1 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfb13c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 변수 목록\n",
    "variables = [\n",
    "    \"Head Purge Position Z Collect Result_Fill2\",\n",
    "    \"CURE_Time_Fill2\",\n",
    "    # \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\",\n",
    "    # \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\",\n",
    "    \"time_ratio_Fill2\"\n",
    "]\n",
    "\n",
    "# 변수들로만 이루어진 DataFrame 생성\n",
    "filtered_data = train_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7c533e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    \"HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\",\n",
    "    \"HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\"\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31aa87df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Variable 1, Variable 2, Correlation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 상관계수 행렬 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= 0.8) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "strong_correlations_pairs = strong_correlations_pairs[strong_correlations_pairs['Correlation'] >= 0.7]\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84f9c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dam 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Dam').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "20e341d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill1 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Fill1').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7d32ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill2 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_Fill2').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fed0e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "### autoclave 데이터셋\n",
    "# 열 이름 필터링 후 공통 변수와 결합\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# train\n",
    "final_columns_train = list(Process_Desc_col) + com_variables_train\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = list(Process_Desc_col) + com_variables_test\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb9e8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred_proba, threshold=0.5):\n",
    "    # 확률을 기준으로 예측 레이블 생성\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)  # 0.5 이상의 확률을 양성으로 간주\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f28f07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e56224",
   "metadata": {},
   "source": [
    "optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ec04f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "# train_data['target'] = train_data['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 300, 5000),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 300, 4000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "#         'boosting': 'dart',  # dart 사용\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         'verbose': -1\n",
    "#     }\n",
    "       \n",
    "#     model = LGBMClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),\n",
    "#     train_data[\"target\"],\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=3000)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0d6d6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 정의\n",
    "# class_weights = {1: 1, 0: 5}  # 클래스의 비율에 따라 가중치 설정\n",
    "\n",
    "model_Dam = LGBMClassifier(\n",
    "    n_estimators=1019\n",
    "    , num_leaves=1513\n",
    "    , max_depth=115\n",
    "    , learning_rate=0.010329666890588058\n",
    "    , min_child_samples=7\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_AutoClave = LGBMClassifier(\n",
    "    n_estimators=1019\n",
    "    , num_leaves=1513\n",
    "    , max_depth=115\n",
    "    , learning_rate=0.010329666890588058\n",
    "    , min_child_samples=7\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_Fill1 = LGBMClassifier(\n",
    "    n_estimators=1019\n",
    "    , num_leaves=1513\n",
    "    , max_depth=115\n",
    "    , learning_rate=0.010329666890588058\n",
    "    , min_child_samples=7\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")\n",
    "model_Fill2 = LGBMClassifier(\n",
    "    n_estimators=1019\n",
    "    , num_leaves=1513\n",
    "    , max_depth=115\n",
    "    , learning_rate=0.010329666890588058\n",
    "    , min_child_samples=7\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    # , class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1072be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dam, df_val_dam = train_test_split(\n",
    "    train_data_dam,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_fill1, df_val_fill1 = train_test_split(\n",
    "    train_data_fill1,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_fill2, df_val_fill2 = train_test_split(\n",
    "    train_data_fill2,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "df_train_autoclave, df_val_autoclave = train_test_split(\n",
    "    train_data_autoclave,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "637330c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "[I 2024-08-15 05:27:31,915] A new study created in memory with name: no-name-7036eb80-48f2-41fb-9a94-f36cb14d04c1\n",
      "[I 2024-08-15 05:27:59,417] Trial 0 finished with value: 0.18497109826589594 and parameters: {'n_estimators': 613, 'num_leaves': 2078, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 69}. Best is trial 0 with value: 0.18497109826589594.\n",
      "[I 2024-08-15 05:37:45,510] Trial 1 finished with value: 0.22481751824817517 and parameters: {'n_estimators': 2143, 'num_leaves': 2879, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 11}. Best is trial 1 with value: 0.22481751824817517.\n",
      "[I 2024-08-15 05:40:34,708] Trial 2 finished with value: 0.13721413721413722 and parameters: {'n_estimators': 1346, 'num_leaves': 1084, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 43}. Best is trial 1 with value: 0.22481751824817517.\n",
      "[I 2024-08-15 05:42:56,654] Trial 3 finished with value: 0.17928286852589642 and parameters: {'n_estimators': 1630, 'num_leaves': 357, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 42}. Best is trial 1 with value: 0.22481751824817517.\n",
      "[I 2024-08-15 05:46:06,352] Trial 4 finished with value: 0.23338735818476503 and parameters: {'n_estimators': 1148, 'num_leaves': 2381, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 35}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 05:46:44,426] Trial 5 finished with value: 0.18786692759295495 and parameters: {'n_estimators': 367, 'num_leaves': 541, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 27}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 05:56:03,332] Trial 6 finished with value: 0.22320117474302495 and parameters: {'n_estimators': 2356, 'num_leaves': 1759, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 19}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:00:23,145] Trial 7 finished with value: 0.22408026755852845 and parameters: {'n_estimators': 2215, 'num_leaves': 408, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 27}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:05:48,325] Trial 8 finished with value: 0.22255192878338279 and parameters: {'n_estimators': 1377, 'num_leaves': 2228, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 24}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:06:07,145] Trial 9 finished with value: 0.16935483870967744 and parameters: {'n_estimators': 335, 'num_leaves': 2354, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 96}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:07:42,795] Trial 10 finished with value: 0.18181818181818182 and parameters: {'n_estimators': 994, 'num_leaves': 2985, 'max_depth': 283, 'learning_rate': 0.030359066403491803, 'min_child_samples': 65}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:18:26,651] Trial 11 finished with value: 0.22421524663677128 and parameters: {'n_estimators': 1927, 'num_leaves': 2984, 'max_depth': 197, 'learning_rate': 0.04199422245226993, 'min_child_samples': 5}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:32:25,000] Trial 12 finished with value: 0.21659634317862164 and parameters: {'n_estimators': 2842, 'num_leaves': 2566, 'max_depth': 217, 'learning_rate': 0.04043181336317924, 'min_child_samples': 3}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:41:15,805] Trial 13 finished with value: 0.218077474892396 and parameters: {'n_estimators': 2916, 'num_leaves': 2652, 'max_depth': 130, 'learning_rate': 0.06431897150813264, 'min_child_samples': 52}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:45:11,909] Trial 14 finished with value: 0.2108731466227348 and parameters: {'n_estimators': 947, 'num_leaves': 1708, 'max_depth': 158, 'learning_rate': 0.023590161939075347, 'min_child_samples': 14}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:53:27,119] Trial 15 finished with value: 0.22123893805309736 and parameters: {'n_estimators': 2444, 'num_leaves': 2627, 'max_depth': 88, 'learning_rate': 0.05310480864591416, 'min_child_samples': 37}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 06:58:42,159] Trial 16 finished with value: 0.22058823529411764 and parameters: {'n_estimators': 1822, 'num_leaves': 1295, 'max_depth': 224, 'learning_rate': 0.07945268788695498, 'min_child_samples': 64}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:00:42,727] Trial 17 finished with value: 0.20599250936329588 and parameters: {'n_estimators': 1095, 'num_leaves': 1923, 'max_depth': 12, 'learning_rate': 0.0353590206065692, 'min_child_samples': 12}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:04:58,962] Trial 18 finished with value: 0.2141732283464567 and parameters: {'n_estimators': 2057, 'num_leaves': 1310, 'max_depth': 300, 'learning_rate': 0.05214743826306029, 'min_child_samples': 82}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:09:41,899] Trial 19 finished with value: 0.2027027027027027 and parameters: {'n_estimators': 1676, 'num_leaves': 2424, 'max_depth': 203, 'learning_rate': 0.019539999107710395, 'min_child_samples': 34}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:16:56,230] Trial 20 finished with value: 0.21468926553672318 and parameters: {'n_estimators': 2648, 'num_leaves': 2823, 'max_depth': 149, 'learning_rate': 0.09913196298727578, 'min_child_samples': 49}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:30:59,151] Trial 21 finished with value: 0.22446043165467627 and parameters: {'n_estimators': 1980, 'num_leaves': 2952, 'max_depth': 192, 'learning_rate': 0.04272871983021703, 'min_child_samples': 3}. Best is trial 4 with value: 0.23338735818476503.\n",
      "[I 2024-08-15 07:40:18,635] Trial 22 finished with value: 0.23423423423423426 and parameters: {'n_estimators': 1438, 'num_leaves': 2718, 'max_depth': 246, 'learning_rate': 0.04576380877610901, 'min_child_samples': 11}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 07:47:06,884] Trial 23 finished with value: 0.22056631892697467 and parameters: {'n_estimators': 1378, 'num_leaves': 2734, 'max_depth': 259, 'learning_rate': 0.059059352058282985, 'min_child_samples': 15}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 07:52:02,643] Trial 24 finished with value: 0.22023809523809523 and parameters: {'n_estimators': 1560, 'num_leaves': 2165, 'max_depth': 238, 'learning_rate': 0.07327305347099342, 'min_child_samples': 30}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 07:54:15,929] Trial 25 finished with value: 0.20962199312714777 and parameters: {'n_estimators': 806, 'num_leaves': 2491, 'max_depth': 265, 'learning_rate': 0.03130636805815055, 'min_child_samples': 21}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:01:30,955] Trial 26 finished with value: 0.2239031770045386 and parameters: {'n_estimators': 1199, 'num_leaves': 2356, 'max_depth': 168, 'learning_rate': 0.045100422485745716, 'min_child_samples': 10}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:02:50,838] Trial 27 finished with value: 0.20819112627986347 and parameters: {'n_estimators': 761, 'num_leaves': 1969, 'max_depth': 220, 'learning_rate': 0.07072685675528564, 'min_child_samples': 54}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:10:56,995] Trial 28 finished with value: 0.22652757078986588 and parameters: {'n_estimators': 1765, 'num_leaves': 2786, 'max_depth': 242, 'learning_rate': 0.053774525954247185, 'min_child_samples': 19}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:16:03,569] Trial 29 finished with value: 0.2261904761904762 and parameters: {'n_estimators': 1810, 'num_leaves': 2101, 'max_depth': 279, 'learning_rate': 0.05780684171846131, 'min_child_samples': 37}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:22:28,704] Trial 30 finished with value: 0.22290076335877865 and parameters: {'n_estimators': 1506, 'num_leaves': 2753, 'max_depth': 241, 'learning_rate': 0.035382626302368554, 'min_child_samples': 20}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:28:23,313] Trial 31 finished with value: 0.2261904761904762 and parameters: {'n_estimators': 1833, 'num_leaves': 2030, 'max_depth': 281, 'learning_rate': 0.05874546615400874, 'min_child_samples': 33}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:31:09,237] Trial 32 finished with value: 0.21571648690292755 and parameters: {'n_estimators': 1214, 'num_leaves': 2242, 'max_depth': 298, 'learning_rate': 0.056877541812529575, 'min_child_samples': 40}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:34:45,852] Trial 33 finished with value: 0.22796352583586624 and parameters: {'n_estimators': 1761, 'num_leaves': 2504, 'max_depth': 264, 'learning_rate': 0.04715106136148795, 'min_child_samples': 47}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:38:28,086] Trial 34 finished with value: 0.2121212121212121 and parameters: {'n_estimators': 1690, 'num_leaves': 2512, 'max_depth': 253, 'learning_rate': 0.04810440223490567, 'min_child_samples': 47}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:41:12,399] Trial 35 finished with value: 0.20884955752212392 and parameters: {'n_estimators': 1271, 'num_leaves': 2789, 'max_depth': 210, 'learning_rate': 0.038065490048820046, 'min_child_samples': 57}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:44:53,972] Trial 36 finished with value: 0.2141623488773748 and parameters: {'n_estimators': 1445, 'num_leaves': 1471, 'max_depth': 230, 'learning_rate': 0.02870916472424109, 'min_child_samples': 44}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:47:20,348] Trial 37 finished with value: 0.17303822937625757 and parameters: {'n_estimators': 1582, 'num_leaves': 665, 'max_depth': 176, 'learning_rate': 0.01427760097670723, 'min_child_samples': 74}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:54:29,711] Trial 38 finished with value: 0.22385861561119294 and parameters: {'n_estimators': 2193, 'num_leaves': 889, 'max_depth': 269, 'learning_rate': 0.04973365985953514, 'min_child_samples': 26}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 08:56:40,914] Trial 39 finished with value: 0.22395023328149302 and parameters: {'n_estimators': 621, 'num_leaves': 2646, 'max_depth': 245, 'learning_rate': 0.06727674893833673, 'min_child_samples': 18}. Best is trial 22 with value: 0.23423423423423426.\n",
      "[I 2024-08-15 09:03:01,630] Trial 40 finished with value: 0.2349397590361446 and parameters: {'n_estimators': 1087, 'num_leaves': 2329, 'max_depth': 142, 'learning_rate': 0.04621450707732194, 'min_child_samples': 8}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:09:39,436] Trial 41 finished with value: 0.22492401215805474 and parameters: {'n_estimators': 1077, 'num_leaves': 2349, 'max_depth': 130, 'learning_rate': 0.04539546085489986, 'min_child_samples': 8}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:12:36,722] Trial 42 finished with value: 0.23211446740858507 and parameters: {'n_estimators': 816, 'num_leaves': 1875, 'max_depth': 96, 'learning_rate': 0.05355685044908767, 'min_child_samples': 23}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:15:15,360] Trial 43 finished with value: 0.21926910299003322 and parameters: {'n_estimators': 862, 'num_leaves': 1810, 'max_depth': 93, 'learning_rate': 0.04607126359591341, 'min_child_samples': 26}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:16:20,151] Trial 44 finished with value: 0.1969111969111969 and parameters: {'n_estimators': 518, 'num_leaves': 2247, 'max_depth': 110, 'learning_rate': 0.03634531282232307, 'min_child_samples': 31}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:19:48,868] Trial 45 finished with value: 0.22009569377990432 and parameters: {'n_estimators': 694, 'num_leaves': 1613, 'max_depth': 51, 'learning_rate': 0.026009066350220714, 'min_child_samples': 8}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:24:13,508] Trial 46 finished with value: 0.22595419847328246 and parameters: {'n_estimators': 917, 'num_leaves': 1879, 'max_depth': 81, 'learning_rate': 0.06233619458755419, 'min_child_samples': 15}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:27:43,967] Trial 47 finished with value: 0.2272 and parameters: {'n_estimators': 1064, 'num_leaves': 2455, 'max_depth': 144, 'learning_rate': 0.04074014430550599, 'min_child_samples': 23}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:28:21,045] Trial 48 finished with value: 0.17892644135188868 and parameters: {'n_estimators': 451, 'num_leaves': 2135, 'max_depth': 101, 'learning_rate': 0.055035163077163614, 'min_child_samples': 58}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:30:46,456] Trial 49 finished with value: 0.14049586776859502 and parameters: {'n_estimators': 1304, 'num_leaves': 2295, 'max_depth': 65, 'learning_rate': 0.003151353363870839, 'min_child_samples': 41}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:38:03,058] Trial 50 finished with value: 0.22492401215805474 and parameters: {'n_estimators': 1191, 'num_leaves': 2545, 'max_depth': 137, 'learning_rate': 0.031751557573389204, 'min_child_samples': 8}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:41:54,778] Trial 51 finished with value: 0.21939586645469 and parameters: {'n_estimators': 1098, 'num_leaves': 2429, 'max_depth': 148, 'learning_rate': 0.040761721686113056, 'min_child_samples': 23}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:44:38,615] Trial 52 finished with value: 0.22756410256410253 and parameters: {'n_estimators': 1019, 'num_leaves': 2651, 'max_depth': 166, 'learning_rate': 0.050556320291118235, 'min_child_samples': 30}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:50:46,697] Trial 53 finished with value: 0.22356495468277948 and parameters: {'n_estimators': 1417, 'num_leaves': 2632, 'max_depth': 164, 'learning_rate': 0.050503028290021276, 'min_child_samples': 16}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:54:05,275] Trial 54 finished with value: 0.2144 and parameters: {'n_estimators': 1008, 'num_leaves': 2901, 'max_depth': 184, 'learning_rate': 0.047707777632370024, 'min_child_samples': 29}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 09:56:40,344] Trial 55 finished with value: 0.21788617886178863 and parameters: {'n_estimators': 903, 'num_leaves': 2689, 'max_depth': 122, 'learning_rate': 0.051723830835075243, 'min_child_samples': 35}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 10:01:18,810] Trial 56 finished with value: 0.22291993720565148 and parameters: {'n_estimators': 674, 'num_leaves': 2863, 'max_depth': 179, 'learning_rate': 0.04378106637664378, 'min_child_samples': 11}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 10:05:00,318] Trial 57 finished with value: 0.22496147919876733 and parameters: {'n_estimators': 1334, 'num_leaves': 1592, 'max_depth': 207, 'learning_rate': 0.0611297041247519, 'min_child_samples': 44}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 10:07:20,683] Trial 58 finished with value: 0.22294022617124393 and parameters: {'n_estimators': 802, 'num_leaves': 2553, 'max_depth': 111, 'learning_rate': 0.06742226161973658, 'min_child_samples': 38}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 10:16:01,320] Trial 59 finished with value: 0.21726190476190477 and parameters: {'n_estimators': 1156, 'num_leaves': 2344, 'max_depth': 161, 'learning_rate': 0.03805481004683027, 'min_child_samples': 5}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[I 2024-08-15 10:21:03,096] Trial 60 finished with value: 0.21900161030595816 and parameters: {'n_estimators': 2306, 'num_leaves': 2067, 'max_depth': 24, 'learning_rate': 0.03366707615539333, 'min_child_samples': 28}. Best is trial 40 with value: 0.2349397590361446.\n",
      "[W 2024-08-15 10:22:28,910] Trial 61 failed with parameters: {'n_estimators': 982, 'num_leaves': 2455, 'max_depth': 146, 'learning_rate': 0.04086801548776608, 'min_child_samples': 23} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_19000\\1204700732.py\", line 40, in <lambda>\n",
      "    study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=1000)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_19000\\1204700732.py\", line 23, in objectiveLGBM_dart\n",
      "    model.fit(x_tr, y_tr)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1298, in fit\n",
      "    init_model=init_model,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 963, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\", line 4138, in update\n",
      "    ctypes.byref(is_finished),\n",
      "KeyboardInterrupt\n",
      "[W 2024-08-15 10:22:28,910] Trial 61 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19000\\1204700732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19000\\1204700732.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19000\\1204700732.py\u001b[0m in \u001b[0;36mobjectiveLGBM_dart\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4136\u001b[0m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m                 )\n\u001b[0;32m   4140\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_fill1['target'] = train_data_fill1['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 300, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 300, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 100),\n",
    "        \n",
    "        'boosting': 'dart',  # dart 사용\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred = model.predict(x_val)\n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill1.drop(\"target\", axis=1),\n",
    "    train_data_fill1[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=1000)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561132c",
   "metadata": {},
   "source": [
    "Trial 40 finished with value: 0.2349397590361446 and parameters: {'n_estimators': 1087, 'num_leaves': 2329, 'max_depth': 142, 'learning_rate': 0.04621450707732194, 'min_child_samples': 8}. Best is trial 40 with value: 0.2349397590361446."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7576d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
