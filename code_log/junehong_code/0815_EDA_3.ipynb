{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3456,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3457,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a6bbc",
   "metadata": {},
   "source": [
    "기본 전처리 할것들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3458,
   "id": "e1367da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Workorder_AutoClave' 열에서 '-' 다음 숫자 값 추출 및 '000' 제거\n",
    "train_data['Workorder'] = train_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)\n",
    "test_data['Workorder'] = test_data['Workorder'].str.replace(r'-(\\d+)', lambda x: '-' + x.group(1).lstrip('0'), regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3459,
   "id": "735040a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispenser_num 값에 따라 새로운 변수 생성\n",
    "train_data['Dispenser_1'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "train_data['Dispenser_2'] = train_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "test_data['Dispenser_1'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#1' else 0)\n",
    "test_data['Dispenser_2'] = test_data['Dispenser_num'].apply(lambda x: 1 if x == '#2' else 0)\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['Dispenser_num'], axis=1, inplace=True)\n",
    "test_data.drop(['Dispenser_num'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3460,
   "id": "262866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result_Dam의 이름을 WorkMode Collect Result로 변경\n",
    "train_data = train_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "test_data = test_data.rename(columns={'WorkMode Collect Result_Dam': 'WorkMode Collect Result'})\n",
    "\n",
    "# WorkMode Collect Result_Fill1, WorkMode Collect Result_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])\n",
    "test_data = test_data.drop(columns=['WorkMode Collect Result_Fill1', 'WorkMode Collect Result_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3461,
   "id": "6e2e5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkMode Collect Result 열의 값이 7인 행을 1로 변경\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].replace(7, 1)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].replace(7, 1)\n",
    "\n",
    "# WorkMode Collect Result 열의 결측값을 0으로 채움\n",
    "train_data['WorkMode Collect Result'] = train_data['WorkMode Collect Result'].fillna(0)\n",
    "test_data['WorkMode Collect Result'] = test_data['WorkMode Collect Result'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3462,
   "id": "38ab6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_receip_no_collect_result(df):\n",
    "    df['Receip_No_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Receip No Collect Result_Dam'] \n",
    "                    if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_receip_no_collect_result(train_data)\n",
    "create_receip_no_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3463,
   "id": "d60cd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Receip No Collect Result_Dam',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3464,
   "id": "66f9a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['PalletID_Collect_Result'] = df.apply(\n",
    "        lambda row: row['PalletID Collect Result_Dam'] \n",
    "                    if (row['PalletID Collect Result_Dam'] == row['PalletID Collect Result_Fill1'] == row['PalletID Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3465,
   "id": "f4f7c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3466,
   "id": "e14c7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 변수의 값이 동일하면 해당 값을 가져가고, 하나라도 일치하지 않으면 0의 값을 가지는 파생 변수 생성 함수\n",
    "def create_palletid_collect_result(df):\n",
    "    df['Production_Qty_Collect_Result'] = df.apply(\n",
    "        lambda row: row['Production Qty Collect Result_Dam'] \n",
    "                    if (row['Production Qty Collect Result_Dam'] == row['Production Qty Collect Result_Fill1'] == row['Production Qty Collect Result_Fill2']) \n",
    "                    else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_palletid_collect_result(train_data)\n",
    "create_palletid_collect_result(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3467,
   "id": "b8fdec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3468,
   "id": "a22797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Chamber Temp. Judge Value_AutoClave\" 변수의 값을 기준으로 파생 변수 생성 함수\n",
    "def create_judge_value_binary(df):\n",
    "    df['Chamber_Temp_OKNG_AutoClave'] = df['Chamber Temp. Judge Value_AutoClave'].apply(\n",
    "        lambda x: 1 if x == 'OK' else 0\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_binary(train_data)\n",
    "create_judge_value_binary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3469,
   "id": "dd9ccf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Judge Value 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam\n",
      "Chamber Temp. Judge Value_AutoClave\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'Judge Value'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Judge Value').columns\n",
    "\n",
    "print(\"\\n Judge Value 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3470,
   "id": "efa52eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 변수 목록\n",
    "judge_value_columns = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_judge_value_feature(df):\n",
    "    df['Judge_Value_OK'] = df[judge_value_columns].apply(\n",
    "        lambda row: 1 if any(row == 'OK') else 0, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 함수 적용\n",
    "create_judge_value_feature(train_data)\n",
    "create_judge_value_feature(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3471,
   "id": "ebe087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'Chamber Temp. Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2'\n",
    "    , 'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3472,
   "id": "4fb1e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수명 변경\n",
    "train_data = train_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})\n",
    "test_data = test_data.rename(columns={'1st Pressure 1st Pressure Unit Time_AutoClave': '1st Pressure Unit Time_AutoClave'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3473,
   "id": "6cdd01e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Columns: 108 entries, Model.Suffix to Judge_Value_OK\n",
      "dtypes: float64(56), int64(49), object(3)\n",
      "memory usage: 33.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3474,
   "id": "5c4b1899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Columns: 109 entries, Set ID to Judge_Value_OK\n",
      "dtypes: float64(86), int64(20), object(3)\n",
      "memory usage: 14.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d3595",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54df9c3",
   "metadata": {},
   "source": [
    "반복적으로 쓰는 툴 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3475,
   "id": "09d2efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(df, col_name):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임과 열 이름에 대해 박스 플롯을 그리는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): 데이터프레임\n",
    "    column_name (str): 열 이름\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.boxplot(df[col_name], vert=False)\n",
    "    plt.xlabel(col_name)\n",
    "    plt.title(f'Box Plot of {col_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3476,
   "id": "7515da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_ratio(df, col_name, target_name='target'):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임의 특정 열에 대해 각 값마다 타겟 변수의 비율과 갯수, 총 갯수를 출력하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): 데이터프레임\n",
    "    col_name (str): 열 이름\n",
    "    target_name (str): 타겟 변수 이름\n",
    "    \"\"\"\n",
    "    # 각 값마다 타겟 변수의 비율 계산\n",
    "    value_counts = df.groupby(col_name)[target_name].value_counts(normalize=True).unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 타겟 변수의 갯수 계산\n",
    "    counts = df.groupby(col_name)[target_name].value_counts().unstack().fillna(0)\n",
    "    \n",
    "    # 각 값마다 총 갯수 계산\n",
    "    total_counts = df[col_name].value_counts().rename('Total_Count')\n",
    "    \n",
    "    # 비율과 갯수를 합침\n",
    "    result = value_counts.join(counts, lsuffix='_ratio', rsuffix='_count')\n",
    "    \n",
    "    # 총 갯수를 합침\n",
    "    result = result.join(total_counts, on=col_name)\n",
    "    \n",
    "    # 출력 형식 조정\n",
    "    result.index.name = 'variable'\n",
    "    print(f\"\\n{col_name}별 {target_name} 비율 및 갯수\\n\")\n",
    "    print(result.rename(columns=lambda x: x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3477,
   "id": "9eed238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_group(df, group_by_columns):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_columns)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AdNormal' 비율과 갯수 계산\n",
    "        adnormal_count = group['target'].value_counts().get('AbNormal', 0)\n",
    "        adnormal_ratio = adnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, adnormal_count, adnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', \"'AdNormal' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그룹화된 변수들의 이름을 제목행으로 출력\n",
    "    print(f\"Grouped by: {', '.join(group_by_columns)}\")\n",
    "    print()\n",
    "    # 데이터프레임 출력\n",
    "    print(results_df)\n",
    "\n",
    "# 예시코드\n",
    "# summarize_grouped_data(train_data, ['1st Pressure Collect Result_AutoClave', '1st Pressure Unit Time_AutoClave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3478,
   "id": "f4bfbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ratio(df, group_by_column, target_column='target', abnormal_value='AbNormal'):\n",
    "    # 데이터프레임을 그룹화\n",
    "    grouped_df = df.groupby(group_by_column)\n",
    "    \n",
    "    # 결과를 저장할 리스트 초기화\n",
    "    results = []\n",
    "    \n",
    "    # 그룹화된 데이터프레임의 내용을 확인하는 코드\n",
    "    for name, group in grouped_df:\n",
    "        # 그룹의 갯수 계산\n",
    "        group_count = group.shape[0]\n",
    "        \n",
    "        # 'target' 변수의 'AbNormal' 비율과 갯수 계산\n",
    "        abnormal_count = group[target_column].value_counts().get(abnormal_value, 0)\n",
    "        abnormal_ratio = abnormal_count / group_count\n",
    "        \n",
    "        # 결과 리스트에 추가\n",
    "        results.append([name, abnormal_count, abnormal_ratio, group_count])\n",
    "    \n",
    "    # 결과 리스트를 데이터프레임으로 변환\n",
    "    results_df = pd.DataFrame(results, columns=['group', f\"'{abnormal_value}' count\", 'ratio', 'Total'])\n",
    "    \n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # 막대 그래프 생성\n",
    "    ax = results_df.plot(kind='bar', x='group', y='ratio', legend=False)\n",
    "    \n",
    "    # 각 막대 위에 AbNormal 갯수와 총 갯수 표시\n",
    "    for i, (abnormal_count, total) in enumerate(zip(results_df[f\"'{abnormal_value}' count\"], results_df['Total'])):\n",
    "        ax.text(i, results_df['ratio'][i], f'{abnormal_count} ({total})', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "     # 그래프 제목 및 축 레이블 설정\n",
    "    ax.set_title(f'{abnormal_value} Ratio by {group_by_column}')\n",
    "    ax.set_xlabel(group_by_column)\n",
    "    ax.set_ylabel(f'{abnormal_value} Ratio')\n",
    "   \n",
    "    # 그래프 출력\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3479,
   "id": "aad45361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_ratio_boxplot(data, time_ratio_column, target_column='target'):\n",
    "    # 그래프 스타일 설정\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # 그래프 그리기\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=time_ratio_column, y=target_column, data=data)\n",
    "\n",
    "    # 그래프 제목 및 레이블 설정\n",
    "    plt.title(f'{time_ratio_column} vs {target_column}')\n",
    "    plt.xlabel(time_ratio_column)\n",
    "    plt.ylabel(target_column)\n",
    "\n",
    "    # 그래프 출력\n",
    "    plt.show()\n",
    "\n",
    "# 함수 호출 예제\n",
    "#plot_time_ratio_vs_target(train_data, 'time_ratio_Dam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8a90c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3480,
   "id": "0e84bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model.Suffix',\n",
       " 'Workorder',\n",
       " 'CURE END POSITION X Collect Result_Dam',\n",
       " 'CURE END POSITION Z Collect Result_Dam',\n",
       " 'CURE END POSITION Θ Collect Result_Dam',\n",
       " 'CURE SPEED Collect Result_Dam',\n",
       " 'CURE START POSITION X Collect Result_Dam',\n",
       " 'CURE START POSITION Θ Collect Result_Dam',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage1) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage2) Collect Result_Dam',\n",
       " 'Dispense Volume(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
       " 'Head Clean Position Z Collect Result_Dam',\n",
       " 'Head Purge Position Z Collect Result_Dam',\n",
       " 'Head Zero Position Y Collect Result_Dam',\n",
       " 'Head Zero Position Z Collect Result_Dam',\n",
       " 'Machine Tact time Collect Result_Dam',\n",
       " 'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
       " 'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
       " 'THICKNESS 1 Collect Result_Dam',\n",
       " 'THICKNESS 2 Collect Result_Dam',\n",
       " 'THICKNESS 3 Collect Result_Dam',\n",
       " 'WorkMode Collect Result',\n",
       " '1st Pressure Collect Result_AutoClave',\n",
       " '1st Pressure Unit Time_AutoClave',\n",
       " '2nd Pressure Collect Result_AutoClave',\n",
       " '2nd Pressure Unit Time_AutoClave',\n",
       " '3rd Pressure Collect Result_AutoClave',\n",
       " '3rd Pressure Unit Time_AutoClave',\n",
       " 'Chamber Temp. Collect Result_AutoClave',\n",
       " 'Chamber Temp. Unit Time_AutoClave',\n",
       " 'DISCHARGED SPEED OF RESIN Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
       " 'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage1) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage2) Collect Result_Fill1',\n",
       " 'Dispense Volume(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
       " 'Head Purge Position Z Collect Result_Fill1',\n",
       " 'Machine Tact time Collect Result_Fill1',\n",
       " 'CURE END POSITION X Collect Result_Fill2',\n",
       " 'CURE END POSITION Z Collect Result_Fill2',\n",
       " 'CURE SPEED Collect Result_Fill2',\n",
       " 'CURE STANDBY POSITION Z Collect Result_Fill2',\n",
       " 'CURE START POSITION X Collect Result_Fill2',\n",
       " 'CURE START POSITION Z Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
       " 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2',\n",
       " 'Head Purge Position Z Collect Result_Fill2',\n",
       " 'Machine Tact time Collect Result_Fill2',\n",
       " 'target',\n",
       " 'Dispenser_1',\n",
       " 'Dispenser_2',\n",
       " 'Receip_No_Collect_Result',\n",
       " 'PalletID_Collect_Result',\n",
       " 'Production_Qty_Collect_Result',\n",
       " 'Chamber_Temp_OKNG_AutoClave',\n",
       " 'Judge_Value_OK']"
      ]
     },
     "execution_count": 3480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a9465e",
   "metadata": {},
   "source": [
    "### 1. CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3481,
   "id": "45bdcc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE END POSITION Θ Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE START POSITION Θ Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'와 '_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3482,
   "id": "33dc2f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION Θ Collect Result_Dam, CURE START POSITION Θ Collect Result_Dam\n",
      "\n",
      "              group  'AdNormal' count     ratio  Total\n",
      "0  (0, 0, -90, -90)                19  1.000000     19\n",
      "1    (0, 0, 90, 90)                15  1.000000     15\n",
      "2    (0, 1, 90, 90)               850  0.054977  15461\n",
      "3  (1, 0, -90, -90)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE START POSITION X Collect Result_Dam'\n",
    ", 'CURE START POSITION Θ Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aff796",
   "metadata": {},
   "source": [
    "dispenser 종류에 따라 POSITION Θ 값이 따라감  \n",
    "-> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3483,
   "id": "a2bcdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION Θ Collect Result_Dam'\n",
    "    , 'CURE START POSITION Θ Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3484,
   "id": "1b7aff20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE END POSITION X Collect Result_Dam\n",
      "CURE END POSITION Z Collect Result_Dam\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE START POSITION X Collect Result_Dam\n",
      "CURE END POSITION X Collect Result_Fill2\n",
      "CURE END POSITION Z Collect Result_Fill2\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE START POSITION X Collect Result_Fill2\n",
      "CURE START POSITION Z Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3485,
   "id": "61cf9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE END POSITION X Collect Result_Dam, CURE END POSITION Z Collect Result_Dam, CURE START POSITION X Collect Result_Dam\n",
      "\n",
      "                     group  'AdNormal' count     ratio  Total\n",
      "0   (0, 0, 240, 2.5, 1030)                19  1.000000     19\n",
      "1  (0, 0, 1000, 12.5, 280)                15  1.000000     15\n",
      "2  (0, 1, 1000, 12.5, 280)               850  0.054977  15461\n",
      "3   (1, 0, 240, 2.5, 1030)              1466  0.058614  25011\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    ", 'CURE END POSITION X Collect Result_Dam'\n",
    ", 'CURE END POSITION Z Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    ", 'CURE START POSITION X Collect Result_Dam'\n",
    "# , 'CURE END POSITION X Collect Result_Fill2'\n",
    "# , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    "# , 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE START POSITION X Collect Result_Fill2'\n",
    "# , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d641dc",
   "metadata": {},
   "source": [
    "좌표값을 통해 좌표간의 거리를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3486,
   "id": "96d3ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Dam'\n",
    "start_z_col = 33.5\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Dam'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Dam'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - start_z_col) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3487,
   "id": "a5fa846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 위치와 끝 위치 열 이름\n",
    "start_x_col = 'CURE START POSITION X Collect Result_Fill2'\n",
    "start_z_col = 'CURE START POSITION Z Collect Result_Fill2'\n",
    "end_x_col = 'CURE END POSITION X Collect Result_Fill2'\n",
    "end_z_col = 'CURE END POSITION Z Collect Result_Fill2'\n",
    "\n",
    "# 시작 위치와 끝 위치 사이의 거리 계산\n",
    "train_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")\n",
    "\n",
    "test_data['CURE_DISTANCE_Fill2'] = np.sqrt(\n",
    "    (train_data[end_x_col] - train_data[start_x_col]) ** 2 +\n",
    "    (train_data[end_z_col] - train_data[start_z_col]) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3488,
   "id": "fbe2fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE START POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION X Collect Result_Dam'\n",
    "    , 'CURE END POSITION Z Collect Result_Dam'\n",
    "\n",
    "    , 'CURE START POSITION X Collect Result_Fill2'\n",
    "    , 'CURE START POSITION Z Collect Result_Fill2'\n",
    "    , 'CURE END POSITION X Collect Result_Fill2'\n",
    "    , 'CURE END POSITION Z Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3489,
   "id": "2b9efd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3490,
   "id": "46e713c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: CURE STANDBY POSITION Z Collect Result_Fill2\n",
      "\n",
      "   group  'AdNormal' count     ratio  Total\n",
      "0     22                34  0.072495    469\n",
      "1     23                22  0.107843    204\n",
      "2     32               421  0.085866   4903\n",
      "3     33              1873  0.053622  34930\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "# 'Dispenser_1'\n",
    "# , 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    " 'CURE STANDBY POSITION Z Collect Result_Fill2'\n",
    "# , 'CURE_DISTANCE_Dam'\n",
    "# , 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b3d80",
   "metadata": {},
   "source": [
    "'CURE STANDBY POSITION Z Collect Result_Fill2' 변수의 유의미함을 찾을수 x  \n",
    "다른 변수와 연결된만한것도 찾지 못함 -> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3491,
   "id": "dc313406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = ['CURE STANDBY POSITION Z Collect Result_Fill2']\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3492,
   "id": "50fe7e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3493,
   "id": "18af7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Dispenser_1, Dispenser_2, CURE_DISTANCE_Dam, CURE_DISTANCE_Fill2\n",
      "\n",
      "                                          group  'AdNormal' count     ratio  \\\n",
      "0              (0, 0, 720.3061848963953, 780.0)                15  1.000000   \n",
      "1               (0, 0, 790.607993888248, 780.0)                19  1.000000   \n",
      "2              (0, 1, 720.3061848963953, 780.0)               827  0.054645   \n",
      "3  (0, 1, 720.3061848963953, 780.0006410253776)                23  0.070552   \n",
      "4  (0, 1, 720.3061848963953, 780.0775602464155)                 0  0.000000   \n",
      "5               (1, 0, 790.607993888248, 780.0)              1129  0.054418   \n",
      "6   (1, 0, 790.607993888248, 780.0006410253776)               286  0.077591   \n",
      "7   (1, 0, 790.607993888248, 780.0640999302557)                51  0.088235   \n",
      "\n",
      "   Total  \n",
      "0     15  \n",
      "1     19  \n",
      "2  15134  \n",
      "3    326  \n",
      "4      1  \n",
      "5  20747  \n",
      "6   3686  \n",
      "7    578  \n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Dispenser_1'\n",
    ", 'Dispenser_2'\n",
    "# , 'CURE SPEED Collect Result_Dam'\n",
    "# , 'CURE SPEED Collect Result_Fill2'\n",
    ", 'CURE_DISTANCE_Dam'\n",
    ", 'CURE_DISTANCE_Fill2'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340dbf40",
   "metadata": {},
   "source": [
    "거리의 차이에 따라 ratio 값 변화 크지 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3494,
   "id": "c26ff29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 / 속도 -> 시간 파생 변수 생성\n",
    "train_data['CURE_Time_Dam']  = train_data['CURE_DISTANCE_Dam'] / train_data['CURE SPEED Collect Result_Dam']\n",
    "test_data['CURE_Time_Dam']  = test_data['CURE_DISTANCE_Dam'] / test_data['CURE SPEED Collect Result_Dam']\n",
    "\n",
    "train_data['CURE_Time_Fill2']  = train_data['CURE_DISTANCE_Fill2'] / train_data['CURE SPEED Collect Result_Fill2']\n",
    "test_data['CURE_Time_Fill2']  = test_data['CURE_DISTANCE_Fill2'] / test_data['CURE SPEED Collect Result_Fill2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3495,
   "id": "48b4c8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE SPEED Collect Result_Dam\n",
      "CURE SPEED Collect Result_Fill2\n",
      "CURE_DISTANCE_Dam\n",
      "CURE_DISTANCE_Fill2\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3496,
   "id": "4195b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'CURE_DISTANCE_Dam'\n",
    "    , 'CURE SPEED Collect Result_Dam'\n",
    "    , 'CURE_DISTANCE_Fill2'\n",
    "    , 'CURE SPEED Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3497,
   "id": "2d0840f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CURE 포함 변수>\n",
      "CURE_Time_Dam\n",
      "CURE_Time_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'CURE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='CURE').columns\n",
    "\n",
    "print(\"\\n CURE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caac149",
   "metadata": {},
   "source": [
    "### 2. HEAD NORMAL COORDINATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3498,
   "id": "39a38fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL COORDINATE 포함 변수>\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL COORDINATE'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL COORDINATE').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL COORDINATE 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3499,
   "id": "acc3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3500,
   "id": "287f0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    # data['HEAD NORMAL DISTANCE_TRIANGLE_area_Dam'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Dam'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3501,
   "id": "efb87f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3502,
   "id": "dd662cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3503,
   "id": "f9fb0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 열 이름\n",
    "stage1_stage2_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "stage2_stage3_col = 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "stage1_stage3_col = 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "# 삼각형의 넓이와 높이를 계산하는 함수\n",
    "def calculate_triangle_features(data):\n",
    "    a = data[stage1_stage2_col]\n",
    "    b = data[stage2_stage3_col]\n",
    "    c = data[stage1_stage3_col]\n",
    "\n",
    "    # 헤론의 공식에 따른 삼각형의 넓이 계산\n",
    "    s = (a + b + c) / 2\n",
    "    area = np.sqrt(s * (s - a) * (s - b) * (s - c))\n",
    "\n",
    "    # 높이 계산 (밑변을 c로 가정)\n",
    "    height = (2 * area) / c\n",
    "\n",
    "    # 결과를 새로운 열에 저장\n",
    "    # data['HEAD NORMAL DISTANCE_TRIANGLE_area_Fill1'] = area\n",
    "    data['HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1'] = height\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_triangle_features(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_triangle_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3504,
   "id": "0df37c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3505,
   "id": "ac6abb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 각 스테이지의 좌표 열 정의\n",
    "stage1_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2']\n",
    "\n",
    "stage2_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2']\n",
    "\n",
    "stage3_cols = ['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "               'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2']\n",
    "\n",
    "# 거리 계산 함수\n",
    "def calculate_distances(data):\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'] = np.sqrt(\n",
    "        (data[stage2_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage2_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage2_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage2_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage2_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage2_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    data['HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'] = np.sqrt(\n",
    "        (data[stage3_cols[0]] - data[stage1_cols[0]]) ** 2 +\n",
    "        (data[stage3_cols[1]] - data[stage1_cols[1]]) ** 2 +\n",
    "        (data[stage3_cols[2]] - data[stage1_cols[2]]) ** 2\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "# train_data에 적용\n",
    "train_data = calculate_distances(train_data)\n",
    "\n",
    "# test_data에 적용\n",
    "test_data = calculate_distances(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3506,
   "id": "4c4cf668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2'\n",
    "\n",
    "    , 'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2'\n",
    "    , 'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3507,
   "id": "9688a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3508,
   "id": "47c86049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Dam'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Dam'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam'\n",
    "\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill1'\n",
    "    , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill1'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1'\n",
    "\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'\n",
    "    # , 'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3509,
   "id": "0fa789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " HEAD NORMAL 포함 변수>\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Dam\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1\n",
      "HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2\n",
      "HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2\n"
     ]
    }
   ],
   "source": [
    "# 'HEAD NORMAL'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='HEAD NORMAL').columns\n",
    "\n",
    "print(\"\\n HEAD NORMAL 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333a2e0",
   "metadata": {},
   "source": [
    "### 3. RESIN(처리x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3510,
   "id": "91c64cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'RESIN' 또는 'Dispense Volume' 포함 변수>\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "Dispense Volume(Stage1) Collect Result_Dam\n",
      "Dispense Volume(Stage2) Collect Result_Dam\n",
      "Dispense Volume(Stage3) Collect Result_Dam\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "Dispense Volume(Stage1) Collect Result_Fill1\n",
      "Dispense Volume(Stage2) Collect Result_Fill1\n",
      "Dispense Volume(Stage3) Collect Result_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3511,
   "id": "92e34edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dam\n",
    "train_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Dam'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "test_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Dam'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "\n",
    "train_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Dam'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "test_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Dam'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "\n",
    "train_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Dam'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "test_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Dam'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage1_Dam'] = train_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Dam'] * train_data['Dispense Volume(Stage1) Collect Result_Dam']\n",
    "test_data['RESIN_Volume_Ratio_Stage1_Dam'] = test_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Dam'] * test_data['Dispense Volume(Stage1) Collect Result_Dam']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage2_Dam'] = train_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Dam'] * train_data['Dispense Volume(Stage2) Collect Result_Dam']\n",
    "test_data['RESIN_Volume_Ratio_Stage2_Dam'] = test_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Dam'] * test_data['Dispense Volume(Stage2) Collect Result_Dam']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage3_Dam'] = train_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Dam'] * train_data['Dispense Volume(Stage3) Collect Result_Dam']\n",
    "test_data['RESIN_Volume_Ratio_Stage3_Dam'] = test_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Dam'] * test_data['Dispense Volume(Stage3) Collect Result_Dam']\n",
    "\n",
    "\n",
    "# Fill1\n",
    "train_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Fill1'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "test_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Fill1'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "\n",
    "train_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Fill1'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "test_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Fill1'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "\n",
    "train_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Fill1'] = train_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "test_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Fill1'] = test_data['DISCHARGED SPEED OF RESIN Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage1_Fill1'] = train_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Fill1'] * train_data['Dispense Volume(Stage1) Collect Result_Fill1']\n",
    "test_data['RESIN_Volume_Ratio_Stage1_Fill1'] = test_data['RESIN DISCHARGED_stage1_SPEED_x_TIME_Fill1'] * test_data['Dispense Volume(Stage1) Collect Result_Fill1']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage2_Fill1'] = train_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Fill1'] * train_data['Dispense Volume(Stage2) Collect Result_Fill1']\n",
    "test_data['RESIN_Volume_Ratio_Stage2_Fill1'] = test_data['RESIN DISCHARGED_stage2_SPEED_x_TIME_Fill1'] * test_data['Dispense Volume(Stage2) Collect Result_Fill1']\n",
    "\n",
    "train_data['RESIN_Volume_Ratio_Stage3_Fill1'] = train_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Fill1'] * train_data['Dispense Volume(Stage3) Collect Result_Fill1']\n",
    "test_data['RESIN_Volume_Ratio_Stage3_Fill1'] = test_data['RESIN DISCHARGED_stage3_SPEED_x_TIME_Fill1'] * test_data['Dispense Volume(Stage3) Collect Result_Fill1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3512,
   "id": "d1f97eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'DISCHARGED SPEED OF RESIN Collect Result_Dam'\n",
    "    , 'Dispense Volume(Stage1) Collect Result_Dam'\n",
    "    , 'Dispense Volume(Stage2) Collect Result_Dam'\n",
    "    , 'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "    , 'RESIN DISCHARGED_stage1_SPEED_x_TIME_Dam'\n",
    "    , 'RESIN DISCHARGED_stage2_SPEED_x_TIME_Dam'\n",
    "    , 'RESIN DISCHARGED_stage3_SPEED_x_TIME_Dam'\n",
    "\n",
    "    , 'DISCHARGED SPEED OF RESIN Collect Result_Fill1'\n",
    "    , 'Dispense Volume(Stage1) Collect Result_Fill1'\n",
    "    , 'Dispense Volume(Stage2) Collect Result_Fill1'\n",
    "    , 'Dispense Volume(Stage3) Collect Result_Fill1'\n",
    "    , 'RESIN DISCHARGED_stage1_SPEED_x_TIME_Fill1'\n",
    "    , 'RESIN DISCHARGED_stage2_SPEED_x_TIME_Fill1'\n",
    "    , 'RESIN DISCHARGED_stage3_SPEED_x_TIME_Fill1'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3513,
   "id": "0fb8d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "상관계수가 0.80 이상인 변수 쌍>\n",
      "                                              Variable 1  \\\n",
      "0    DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam   \n",
      "1    DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam   \n",
      "2    DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam   \n",
      "3  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1   \n",
      "4                          RESIN_Volume_Ratio_Stage1_Dam   \n",
      "5                          RESIN_Volume_Ratio_Stage2_Dam   \n",
      "6                          RESIN_Volume_Ratio_Stage3_Dam   \n",
      "7                        RESIN_Volume_Ratio_Stage2_Fill1   \n",
      "\n",
      "                                              Variable 2  Correlation  \n",
      "0    DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam     0.999476  \n",
      "1                          RESIN_Volume_Ratio_Stage2_Dam     0.830620  \n",
      "2    DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam     0.999476  \n",
      "3                        RESIN_Volume_Ratio_Stage2_Fill1     0.933748  \n",
      "4                          RESIN_Volume_Ratio_Stage3_Dam     0.928627  \n",
      "5    DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam     0.830620  \n",
      "6                          RESIN_Volume_Ratio_Stage1_Dam     0.928627  \n",
      "7  DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1     0.933748  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "# 해당 변수들만 추출하여 새로운 데이터프레임 생성\n",
    "filtered_data = train_data[Process_Desc_col]\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기 자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "threshold = 0.8\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= threshold) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n상관계수가 {:.2f} 이상인 변수 쌍>\".format(threshold))\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3514,
   "id": "ae8b07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 이름 정의\n",
    "columns_to_drop = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam'\n",
    "    , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam'\n",
    "    , 'RESIN_Volume_Ratio_Stage3_Dam'\n",
    "    \n",
    "    , 'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1'\n",
    "    , 'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1'\n",
    "    , 'RESIN_Volume_Ratio_Stage3_Fill1'\n",
    "]\n",
    "\n",
    "# train_data에서 열 삭제\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# test_data에서 열 삭제\n",
    "test_data = test_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3515,
   "id": "ffd70bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'RESIN' 또는 'Dispense Volume' 포함 변수>\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1\n",
      "RESIN_Volume_Ratio_Stage1_Dam\n",
      "RESIN_Volume_Ratio_Stage2_Dam\n",
      "RESIN_Volume_Ratio_Stage1_Fill1\n",
      "RESIN_Volume_Ratio_Stage2_Fill1\n"
     ]
    }
   ],
   "source": [
    "# 'RESIN' 또는 'Dispense Volume'을 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(regex='RESIN|Dispense Volume').columns\n",
    "\n",
    "print(\"\\n'RESIN' 또는 'Dispense Volume' 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac6aad",
   "metadata": {},
   "source": [
    "### 4. Distance Speed Collect Result_Dam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f6a2ba",
   "metadata": {},
   "source": [
    "Dam 공정의 Circle, Line 길이 변수들 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3516,
   "id": "8f1ca6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Distance Speed Collect Result_Dam 포함 변수>\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance Speed Collect Result_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance Speed Collect Result_Dam').columns\n",
    "\n",
    "print(\"\\n Distance Speed Collect Result_Dam 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3517,
   "id": "d4f83f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "새로 생성된 파생변수 (train_data)>\n",
      "Circle1_Sum_Dam\n",
      "Circle2_Sum_Dam\n",
      "Circle3_Sum_Dam\n",
      "Circle4_Sum_Dam\n",
      "Line1_Sum_Dam\n",
      "Line2_Sum_Dam\n",
      "Line3_Sum_Dam\n",
      "Line4_Sum_Dam\n",
      "\n",
      "새로 생성된 파생변수 (test_data)>\n",
      "Circle1_Sum_Dam\n",
      "Circle2_Sum_Dam\n",
      "Circle3_Sum_Dam\n",
      "Circle4_Sum_Dam\n",
      "Line1_Sum_Dam\n",
      "Line2_Sum_Dam\n",
      "Line3_Sum_Dam\n",
      "Line4_Sum_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Distance Speed Collect Result_Dam'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='Distance Speed Collect Result_Dam').columns\n",
    "\n",
    "# Circle 시리즈와 Line 시리즈를 합산한 파생변수 생성 함수\n",
    "def create_sum_dam_columns(data, process_desc_col):\n",
    "    for series in ['Circle1', 'Circle2', 'Circle3', 'Circle4', 'Line1', 'Line2', 'Line3', 'Line4']:\n",
    "        series_cols = [col for col in process_desc_col if series in col]\n",
    "        new_col_name = f'{series}_Sum_Dam'\n",
    "        data[new_col_name] = data[series_cols].sum(axis=1)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 적용\n",
    "train_data = create_sum_dam_columns(train_data, Process_Desc_col)\n",
    "test_data = create_sum_dam_columns(test_data, Process_Desc_col)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n새로 생성된 파생변수 (train_data)>\")\n",
    "for col in train_data.columns:\n",
    "    if 'Sum_Dam' in col:\n",
    "        print(col)\n",
    "\n",
    "print(\"\\n새로 생성된 파생변수 (test_data)>\")\n",
    "for col in test_data.columns:\n",
    "    if 'Sum_Dam' in col:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3518,
   "id": "5f4ef779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Circle1_Sum_Dam, Circle2_Sum_Dam, Circle3_Sum_Dam, Circle4_Sum_Dam, Line1_Sum_Dam, Line2_Sum_Dam, Line3_Sum_Dam, Line4_Sum_Dam\n",
      "\n",
      "                                                       group  \\\n",
      "0   (12000, 12000, 12000, 12000, 12000, 12000, 12000, 12000)   \n",
      "1   (13000, 13000, 13000, 13000, 13000, 13000, 13000, 13000)   \n",
      "2   (16000, 16000, 16000, 16000, 16000, 16000, 16000, 16000)   \n",
      "3   (16900, 16900, 16900, 16900, 16900, 16900, 16700, 16900)   \n",
      "4   (16900, 16900, 16900, 16900, 16900, 16900, 16900, 16900)   \n",
      "5   (17000, 17000, 17000, 17000, 17000, 17000, 17000, 17000)   \n",
      "6   (17500, 17500, 17500, 17500, 17500, 17500, 17500, 17500)   \n",
      "7   (17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900)   \n",
      "8   (18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000)   \n",
      "9   (18500, 18500, 18500, 18500, 17500, 18500, 18500, 18500)   \n",
      "10  (18500, 18500, 18500, 18500, 18500, 18500, 17500, 18500)   \n",
      "11  (18500, 18500, 18500, 18500, 18500, 18500, 18500, 18500)   \n",
      "12  (18500, 18500, 18500, 18500, 18500, 18800, 18500, 18800)   \n",
      "13  (19000, 19000, 19000, 19000, 18500, 19000, 18000, 19000)   \n",
      "14  (19000, 19000, 19000, 19000, 19000, 19000, 19000, 19000)   \n",
      "15  (19500, 19500, 19500, 19500, 18000, 19500, 18000, 19500)   \n",
      "16  (19500, 19500, 19500, 19500, 18500, 19500, 18500, 19500)   \n",
      "17  (19500, 19500, 19500, 19500, 19500, 19500, 19000, 19500)   \n",
      "18  (19500, 19500, 19500, 19500, 19500, 19500, 19500, 19500)   \n",
      "19  (19500, 19500, 19500, 19500, 26000, 19500, 19500, 19500)   \n",
      "20  (25000, 25000, 25000, 25000, 25000, 25000, 25000, 25000)   \n",
      "21  (27000, 27000, 27000, 27000, 27000, 27000, 27000, 27000)   \n",
      "22  (30000, 30000, 30000, 30000, 26000, 30000, 26000, 30000)   \n",
      "23  (30000, 30000, 30000, 30000, 30000, 30000, 30000, 30000)   \n",
      "\n",
      "    'AdNormal' count     ratio  Total  \n",
      "0                164  0.040918   4008  \n",
      "1                 57  0.042191   1351  \n",
      "2                 28  0.063636    440  \n",
      "3                227  0.056764   3999  \n",
      "4                 42  0.032407   1296  \n",
      "5                  7  0.020649    339  \n",
      "6                 65  0.048435   1342  \n",
      "7                 15  0.052817    284  \n",
      "8                  5  0.061728     81  \n",
      "9                  5  0.024752    202  \n",
      "10                 4  0.013605    294  \n",
      "11               132  0.034546   3821  \n",
      "12                 8  0.296296     27  \n",
      "13                 3  0.083333     36  \n",
      "14               305  0.062232   4901  \n",
      "15                 3  0.055556     54  \n",
      "16               122  0.048937   2493  \n",
      "17                 3  0.027523    109  \n",
      "18               305  0.056786   5371  \n",
      "19                 2  0.333333      6  \n",
      "20                 3  0.066667     45  \n",
      "21               548  0.083245   6583  \n",
      "22                12  0.113208    106  \n",
      "23               285  0.085895   3318  \n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Circle1_Sum_Dam'\n",
    ", 'Circle2_Sum_Dam'\n",
    ", 'Circle3_Sum_Dam'\n",
    ", 'Circle4_Sum_Dam'\n",
    ", 'Line1_Sum_Dam'\n",
    ", 'Line2_Sum_Dam'\n",
    ", 'Line3_Sum_Dam'\n",
    ", 'Line4_Sum_Dam'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3519,
   "id": "69e803f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "새로 생성된 파생변수 (train_data)>\n",
      "Circle1_Line1_Equal_Dam\n",
      "Circle2_Line2_Equal_Dam\n",
      "Circle3_Line3_Equal_Dam\n",
      "Circle4_Line4_Equal_Dam\n",
      "\n",
      "새로 생성된 파생변수 (test_data)>\n",
      "Circle1_Line1_Equal_Dam\n",
      "Circle2_Line2_Equal_Dam\n",
      "Circle3_Line3_Equal_Dam\n",
      "Circle4_Line4_Equal_Dam\n"
     ]
    }
   ],
   "source": [
    "# Circle과 Line 시리즈의 값을 비교하여 같으면 1, 다르면 0을 부여하는 파생변수 생성 함수\n",
    "def create_equal_dam_columns(data):\n",
    "    for i in range(1, 5):\n",
    "        circle_col = f'Circle{i}_Sum_Dam'\n",
    "        line_col = f'Line{i}_Sum_Dam'\n",
    "        new_col_name = f'Circle{i}_Line{i}_Equal_Dam'\n",
    "        data[new_col_name] = (data[circle_col] == data[line_col]).astype(int)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 적용\n",
    "train_data = create_equal_dam_columns(train_data)\n",
    "test_data = create_equal_dam_columns(test_data)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n새로 생성된 파생변수 (train_data)>\")\n",
    "for col in train_data.columns:\n",
    "    if 'Equal' in col:\n",
    "        print(col)\n",
    "\n",
    "print(\"\\n새로 생성된 파생변수 (test_data)>\")\n",
    "for col in test_data.columns:\n",
    "    if 'Equal' in col:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3520,
   "id": "ca58d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouped by: Circle1_Line1_Equal_Dam, Circle2_Line2_Equal_Dam, Circle3_Line3_Equal_Dam, Circle4_Line4_Equal_Dam\n",
      "\n",
      "          group  'AdNormal' count     ratio  Total\n",
      "0  (0, 1, 0, 1)               140  0.052064   2689\n",
      "1  (0, 1, 1, 1)                 7  0.033654    208\n",
      "2  (1, 0, 1, 0)                 8  0.296296     27\n",
      "3  (1, 1, 0, 1)               234  0.053158   4402\n",
      "4  (1, 1, 1, 1)              1961  0.059102  33180\n"
     ]
    }
   ],
   "source": [
    "summarize_group(train_data, [\n",
    "'Circle1_Line1_Equal_Dam'\n",
    ", 'Circle2_Line2_Equal_Dam'\n",
    ", 'Circle3_Line3_Equal_Dam'\n",
    ", 'Circle4_Line4_Equal_Dam'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3521,
   "id": "3645c46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Circle' 또는 'Line'이 포함된 변수>\n",
      "Stage1 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage1 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage1 Line1 Distance Speed Collect Result_Dam\n",
      "Stage1 Line2 Distance Speed Collect Result_Dam\n",
      "Stage1 Line3 Distance Speed Collect Result_Dam\n",
      "Stage1 Line4 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage2 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage2 Line1 Distance Speed Collect Result_Dam\n",
      "Stage2 Line2 Distance Speed Collect Result_Dam\n",
      "Stage2 Line3 Distance Speed Collect Result_Dam\n",
      "Stage2 Line4 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle1 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle2 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle3 Distance Speed Collect Result_Dam\n",
      "Stage3 Circle4 Distance Speed Collect Result_Dam\n",
      "Stage3 Line1 Distance Speed Collect Result_Dam\n",
      "Stage3 Line2 Distance Speed Collect Result_Dam\n",
      "Stage3 Line3 Distance Speed Collect Result_Dam\n",
      "Stage3 Line4 Distance Speed Collect Result_Dam\n",
      "Circle1_Sum_Dam\n",
      "Circle2_Sum_Dam\n",
      "Circle3_Sum_Dam\n",
      "Circle4_Sum_Dam\n",
      "Line1_Sum_Dam\n",
      "Line2_Sum_Dam\n",
      "Line3_Sum_Dam\n",
      "Line4_Sum_Dam\n",
      "Circle1_Line1_Equal_Dam\n",
      "Circle2_Line2_Equal_Dam\n",
      "Circle3_Line3_Equal_Dam\n",
      "Circle4_Line4_Equal_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Circle' 또는 'Line'이 포함된 열만 필터링\n",
    "filtered_cols = [col for col in train_data.columns if 'Circle' in col or 'Line' in col]\n",
    "\n",
    "print(\"\\n'Circle' 또는 'Line'이 포함된 변수>\")\n",
    "for col in filtered_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3522,
   "id": "0a453df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Stage1 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage1 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage2 Line4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Circle4 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line1 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line2 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line3 Distance Speed Collect Result_Dam'\n",
    ", 'Stage3 Line4 Distance Speed Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3523,
   "id": "2d2c9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Circle' 또는 'Line'이 포함된 변수>\n",
      "Circle1_Sum_Dam\n",
      "Circle2_Sum_Dam\n",
      "Circle3_Sum_Dam\n",
      "Circle4_Sum_Dam\n",
      "Line1_Sum_Dam\n",
      "Line2_Sum_Dam\n",
      "Line3_Sum_Dam\n",
      "Line4_Sum_Dam\n",
      "Circle1_Line1_Equal_Dam\n",
      "Circle2_Line2_Equal_Dam\n",
      "Circle3_Line3_Equal_Dam\n",
      "Circle4_Line4_Equal_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Circle' 또는 'Line'이 포함된 열만 필터링\n",
    "filtered_cols = [col for col in train_data.columns if 'Circle' in col or 'Line' in col]\n",
    "\n",
    "print(\"\\n'Circle' 또는 'Line'이 포함된 변수>\")\n",
    "for col in filtered_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3524,
   "id": "e45d23a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "상관계수가 0.80 이상인 변수 쌍>\n",
      "         Variable 1       Variable 2  Correlation\n",
      "0   Circle1_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "1   Circle1_Sum_Dam    Line2_Sum_Dam     0.999999\n",
      "2   Circle1_Sum_Dam    Line3_Sum_Dam     0.997965\n",
      "3   Circle1_Sum_Dam    Line4_Sum_Dam     0.999999\n",
      "4   Circle2_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "5   Circle2_Sum_Dam    Line2_Sum_Dam     0.999999\n",
      "6   Circle2_Sum_Dam    Line3_Sum_Dam     0.997965\n",
      "7   Circle2_Sum_Dam    Line4_Sum_Dam     0.999999\n",
      "8   Circle3_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "9   Circle3_Sum_Dam    Line2_Sum_Dam     0.999999\n",
      "10  Circle3_Sum_Dam    Line3_Sum_Dam     0.997965\n",
      "11  Circle3_Sum_Dam    Line4_Sum_Dam     0.999999\n",
      "12  Circle4_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "13  Circle4_Sum_Dam    Line2_Sum_Dam     0.999999\n",
      "14  Circle4_Sum_Dam    Line3_Sum_Dam     0.997965\n",
      "15  Circle4_Sum_Dam    Line4_Sum_Dam     0.999999\n",
      "16    Line1_Sum_Dam  Circle1_Sum_Dam     0.997897\n",
      "17    Line1_Sum_Dam  Circle2_Sum_Dam     0.997897\n",
      "18    Line1_Sum_Dam  Circle3_Sum_Dam     0.997897\n",
      "19    Line1_Sum_Dam  Circle4_Sum_Dam     0.997897\n",
      "20    Line1_Sum_Dam    Line2_Sum_Dam     0.997897\n",
      "21    Line1_Sum_Dam    Line3_Sum_Dam     0.999576\n",
      "22    Line1_Sum_Dam    Line4_Sum_Dam     0.997897\n",
      "23    Line2_Sum_Dam  Circle1_Sum_Dam     0.999999\n",
      "24    Line2_Sum_Dam  Circle2_Sum_Dam     0.999999\n",
      "25    Line2_Sum_Dam  Circle3_Sum_Dam     0.999999\n",
      "26    Line2_Sum_Dam  Circle4_Sum_Dam     0.999999\n",
      "27    Line2_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "28    Line2_Sum_Dam    Line3_Sum_Dam     0.997964\n",
      "29    Line3_Sum_Dam  Circle1_Sum_Dam     0.997965\n",
      "30    Line3_Sum_Dam  Circle2_Sum_Dam     0.997965\n",
      "31    Line3_Sum_Dam  Circle3_Sum_Dam     0.997965\n",
      "32    Line3_Sum_Dam  Circle4_Sum_Dam     0.997965\n",
      "33    Line3_Sum_Dam    Line1_Sum_Dam     0.999576\n",
      "34    Line3_Sum_Dam    Line2_Sum_Dam     0.997964\n",
      "35    Line3_Sum_Dam    Line4_Sum_Dam     0.997964\n",
      "36    Line4_Sum_Dam  Circle1_Sum_Dam     0.999999\n",
      "37    Line4_Sum_Dam  Circle2_Sum_Dam     0.999999\n",
      "38    Line4_Sum_Dam  Circle3_Sum_Dam     0.999999\n",
      "39    Line4_Sum_Dam  Circle4_Sum_Dam     0.999999\n",
      "40    Line4_Sum_Dam    Line1_Sum_Dam     0.997897\n",
      "41    Line4_Sum_Dam    Line3_Sum_Dam     0.997964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'Circle' 또는 'Line'이 포함된 열만 필터링\n",
    "filtered_cols = [col for col in train_data.columns if 'Circle' in col or 'Line' in col]\n",
    "\n",
    "# 해당 변수들만 추출하여 새로운 데이터프레임 생성\n",
    "filtered_data = train_data[filtered_cols]\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기 자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "threshold = 0.8\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= threshold) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n상관계수가 {:.2f} 이상인 변수 쌍>\".format(threshold))\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3525,
   "id": "74c5964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Circle1_Sum_Dam'\n",
    ", 'Circle2_Sum_Dam'\n",
    ", 'Circle3_Sum_Dam'\n",
    ", 'Circle4_Sum_Dam'\n",
    ", 'Line1_Sum_Dam'\n",
    ", 'Line2_Sum_Dam'\n",
    ", 'Line3_Sum_Dam'\n",
    ", 'Line4_Sum_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3526,
   "id": "d1c35686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Circle' 또는 'Line'이 포함된 변수>\n",
      "Circle1_Line1_Equal_Dam\n",
      "Circle2_Line2_Equal_Dam\n",
      "Circle3_Line3_Equal_Dam\n",
      "Circle4_Line4_Equal_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'Circle' 또는 'Line'이 포함된 열만 필터링\n",
    "filtered_cols = [col for col in train_data.columns if 'Circle' in col or 'Line' in col]\n",
    "\n",
    "print(\"\\n'Circle' 또는 'Line'이 포함된 변수>\")\n",
    "for col in filtered_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a4274",
   "metadata": {},
   "source": [
    "### 5. THICKNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3527,
   "id": "d1907522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "THICKNESS 1 Collect Result_Dam\n",
      "THICKNESS 2 Collect Result_Dam\n",
      "THICKNESS 3 Collect Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3528,
   "id": "c3ae04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 파생변수 생성 함수\n",
    "def create_total_thickness_dam(data):\n",
    "    data['Total_THICKNESS_Collect_Result_Dam'] = (\n",
    "        data['THICKNESS 1 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 2 Collect Result_Dam']**2 \n",
    "        + data['THICKNESS 3 Collect Result_Dam']**2\n",
    "    )\n",
    "    # 기존 변수 삭제\n",
    "    data.drop(columns=[\n",
    "        'THICKNESS 1 Collect Result_Dam',\n",
    "        'THICKNESS 2 Collect Result_Dam',\n",
    "        'THICKNESS 3 Collect Result_Dam'\n",
    "    ], inplace=True)\n",
    "    return data\n",
    "\n",
    "train_data = create_total_thickness_dam(train_data)\n",
    "test_data = create_total_thickness_dam(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3529,
   "id": "af96f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THICKNESS 포함 변수>\n",
      "Total_THICKNESS_Collect_Result_Dam\n"
     ]
    }
   ],
   "source": [
    "# 'THICKNESS'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='THICKNESS').columns\n",
    "\n",
    "print(\"\\n THICKNESS 포함 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4349a",
   "metadata": {},
   "source": [
    "### 6. AutoClave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3530,
   "id": "27ac3556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3531,
   "id": "b3c024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성\n",
    "train_data['1st_Pressure_x_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure Unit Time_AutoClave'] \n",
    "test_data['1st_Pressure_x_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['2nd_Pressure_x_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave'] \n",
    "test_data['2nd_Pressure_x_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['3rd_Pressure_x_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave'] \n",
    "test_data['3rd_Pressure_x_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave'] \n",
    "\n",
    "train_data['All_Pressure_x_AutoClave'] = train_data['1st_Pressure_x_AutoClave'] + train_data['2nd_Pressure_x_AutoClave'] + train_data['3rd_Pressure_x_AutoClave']\n",
    "test_data['All_Pressure_x_AutoClave'] = test_data['1st_Pressure_x_AutoClave'] + test_data['2nd_Pressure_x_AutoClave'] + test_data['3rd_Pressure_x_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_avg_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['All_Pressure_avg_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['Chamber_Temp_x_AutoClave'] = train_data['Chamber Temp. Collect Result_AutoClave'] * train_data['Chamber Temp. Unit Time_AutoClave']\n",
    "test_data['Chamber_Temp_x_AutoClave'] = test_data['Chamber Temp. Collect Result_AutoClave'] * test_data['Chamber Temp. Unit Time_AutoClave']\n",
    "\n",
    "train_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = train_data['All_Pressure_x_AutoClave'] / train_data['Chamber_Temp_x_AutoClave']\n",
    "test_data['All_Pressure_frac_Chamber_Temp_AutoClave'] = test_data['All_Pressure_x_AutoClave'] / test_data['Chamber_Temp_x_AutoClave']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3532,
   "id": "a69ad859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3533,
   "id": "adc71635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "1st Pressure Unit Time_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "2nd Pressure Unit Time_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Unit Time_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n",
      "\n",
      "상관계수가 0.90 이상인 변수 쌍>\n",
      "                           Variable 1                         Variable 2  \\\n",
      "0    1st Pressure Unit Time_AutoClave           1st_Pressure_x_AutoClave   \n",
      "1    2nd Pressure Unit Time_AutoClave  Chamber Temp. Unit Time_AutoClave   \n",
      "2    2nd Pressure Unit Time_AutoClave           2nd_Pressure_x_AutoClave   \n",
      "3   Chamber Temp. Unit Time_AutoClave   2nd Pressure Unit Time_AutoClave   \n",
      "4   Chamber Temp. Unit Time_AutoClave           All_Pressure_x_AutoClave   \n",
      "5   Chamber Temp. Unit Time_AutoClave           Chamber_Temp_x_AutoClave   \n",
      "6            1st_Pressure_x_AutoClave   1st Pressure Unit Time_AutoClave   \n",
      "7            2nd_Pressure_x_AutoClave   2nd Pressure Unit Time_AutoClave   \n",
      "8            2nd_Pressure_x_AutoClave           All_Pressure_x_AutoClave   \n",
      "9            All_Pressure_x_AutoClave  Chamber Temp. Unit Time_AutoClave   \n",
      "10           All_Pressure_x_AutoClave           2nd_Pressure_x_AutoClave   \n",
      "11           Chamber_Temp_x_AutoClave  Chamber Temp. Unit Time_AutoClave   \n",
      "\n",
      "    Correlation  \n",
      "0      0.980915  \n",
      "1      0.916025  \n",
      "2      0.956947  \n",
      "3      0.916025  \n",
      "4      0.942628  \n",
      "5      0.935742  \n",
      "6      0.980915  \n",
      "7      0.956947  \n",
      "8      0.907845  \n",
      "9      0.942628  \n",
      "10     0.907845  \n",
      "11     0.935742  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)\n",
    "\n",
    "# 해당 변수들만 추출하여 새로운 데이터프레임 생성\n",
    "filtered_data = train_data[Process_Desc_col]\n",
    "\n",
    "# 상관관계 계산\n",
    "correlation_matrix = filtered_data.corr()\n",
    "\n",
    "# 자기 자신을 제외하고 특정 값 이상인 조합 찾기\n",
    "threshold = 0.9\n",
    "strong_correlations = correlation_matrix[(correlation_matrix >= threshold) & (correlation_matrix != 1)]\n",
    "\n",
    "# 리스트로 변환\n",
    "strong_correlations_pairs = strong_correlations.stack().reset_index()\n",
    "strong_correlations_pairs.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n상관계수가 {:.2f} 이상인 변수 쌍>\".format(threshold))\n",
    "print(strong_correlations_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3534,
   "id": "3e714beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "# '1st Pressure Collect Result_AutoClave'\n",
    "'1st Pressure Unit Time_AutoClave'\n",
    "# , '2nd Pressure Collect Result_AutoClave'\n",
    ", '2nd Pressure Unit Time_AutoClave'\n",
    "# , '3rd Pressure Collect Result_AutoClave'\n",
    ", '3rd Pressure Unit Time_AutoClave'\n",
    "# , 'Chamber Temp. Collect Result_AutoClave'\n",
    "# , 'Chamber Temp. Unit Time_AutoClave'\n",
    "\n",
    "# , '1st_Pressure_x_AutoClave'\n",
    "# , '2nd_Pressure_x_AutoClave'\n",
    "# , '3rd_Pressure_x_AutoClave'\n",
    ", 'All_Pressure_x_AutoClave'\n",
    "# , 'All_Pressure_avg_AutoClave'\n",
    "# , 'Chamber_Temp_x_AutoClave'\n",
    "# , 'All_Pressure_frac_Chamber_Temp_AutoClave'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3535,
   "id": "20ce50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AutoClave 공정 관련 변수>\n",
      "1st Pressure Collect Result_AutoClave\n",
      "2nd Pressure Collect Result_AutoClave\n",
      "3rd Pressure Collect Result_AutoClave\n",
      "Chamber Temp. Collect Result_AutoClave\n",
      "Chamber Temp. Unit Time_AutoClave\n",
      "Chamber_Temp_OKNG_AutoClave\n",
      "1st_Pressure_x_AutoClave\n",
      "2nd_Pressure_x_AutoClave\n",
      "3rd_Pressure_x_AutoClave\n",
      "All_Pressure_avg_AutoClave\n",
      "Chamber_Temp_x_AutoClave\n",
      "All_Pressure_frac_Chamber_Temp_AutoClave\n"
     ]
    }
   ],
   "source": [
    "# '_AutoClave'를 포함하는 열 이름 필터링\n",
    "Process_Desc_col = train_data.filter(like='_AutoClave').columns\n",
    "\n",
    "# 필터링된 열 이름 출력\n",
    "print(\"<AutoClave 공정 관련 변수>\")\n",
    "for col in Process_Desc_col:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a69dcf",
   "metadata": {},
   "source": [
    "### 7. ETC.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b05ca",
   "metadata": {},
   "source": [
    "7-1. workorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3536,
   "id": "e2e4240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟 변수를 0과 1로 변환\n",
    "train_data['target_binary'] = train_data['target'].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# Workorder 변수의 값에 대한 타겟 변수 비율 계산\n",
    "workorder_target_ratio = train_data.groupby('Workorder')['target_binary'].mean()\n",
    "\n",
    "# 파생 변수 생성 함수\n",
    "def create_derived_variable(row, ratio_dict, threshold):\n",
    "    return 1 if ratio_dict.get(row['Workorder'], 0) >= threshold else 0\n",
    "\n",
    "# 파생 변수 생성\n",
    "train_data['Workorder_0.9'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "train_data['Workorder_0.7'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "train_data['Workorder_0.5'] = train_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "test_data['Workorder_0.9'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.9)\n",
    "test_data['Workorder_0.7'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.7)\n",
    "test_data['Workorder_0.5'] = test_data.apply(create_derived_variable, axis=1, ratio_dict=workorder_target_ratio, threshold=0.5)\n",
    "\n",
    "\n",
    "# 불필요한 변수 제거\n",
    "train_data.drop(['target_binary'], axis=1, inplace=True)\n",
    "\n",
    "# train_data.drop(['Workorder', 'target_binary'], axis=1, inplace=True)\n",
    "# test_data.drop(['Workorder'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48c3f8",
   "metadata": {},
   "source": [
    "7-2. Machine Tact time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3537,
   "id": "4d866fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 총시간 대비 비율 변수\n",
    "def calculate_total_time_and_ratios(data):\n",
    "    data['total_time'] = (\n",
    "        data['Machine Tact time Collect Result_Dam'] +\n",
    "        data['Machine Tact time Collect Result_Fill1'] +\n",
    "        data['Machine Tact time Collect Result_Fill2'] +\n",
    "        data['Chamber Temp. Unit Time_AutoClave']\n",
    "    )\n",
    "    data['time_ratio_Dam'] = (data['Machine Tact time Collect Result_Dam'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill1'] = (data['Machine Tact time Collect Result_Fill1'] / data['total_time']).round(3)\n",
    "    data['time_ratio_Fill2'] = (data['Machine Tact time Collect Result_Fill2'] / data['total_time']).round(3)\n",
    "    data['time_ratio_AutoClave'] = (data['Chamber Temp. Unit Time_AutoClave'] / data['total_time']).round(3)\n",
    "    return data\n",
    "\n",
    "# train_data와 test_data에 함수 적용\n",
    "train_data = calculate_total_time_and_ratios(train_data)\n",
    "test_data = calculate_total_time_and_ratios(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3538,
   "id": "dec2a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 제거\n",
    "train_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)\n",
    "\n",
    "test_data.drop(columns=[\n",
    "    'total_time'\n",
    "    , 'Machine Tact time Collect Result_Dam'\n",
    "    , 'Machine Tact time Collect Result_Fill1'\n",
    "    , 'Machine Tact time Collect Result_Fill2'\n",
    "    , 'Chamber Temp. Unit Time_AutoClave'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3539,
   "id": "49a7d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  object \n",
      " 1   Workorder                                              40506 non-null  object \n",
      " 2   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 3   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 4   Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 5   Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 6   Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 7   WorkMode Collect Result                                40506 non-null  float64\n",
      " 8   1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 9   2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 10  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 11  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 12  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 13  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 14  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 15  target                                                 40506 non-null  object \n",
      " 16  Dispenser_1                                            40506 non-null  int64  \n",
      " 17  Dispenser_2                                            40506 non-null  int64  \n",
      " 18  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 19  PalletID_Collect_Result                                40506 non-null  int64  \n",
      " 20  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 21  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 22  Judge_Value_OK                                         40506 non-null  int64  \n",
      " 23  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 24  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 25  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 26  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 27  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 28  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 29  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2               40506 non-null  float64\n",
      " 30  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2               40506 non-null  float64\n",
      " 31  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2               40506 non-null  float64\n",
      " 32  RESIN_Volume_Ratio_Stage1_Dam                          40506 non-null  float64\n",
      " 33  RESIN_Volume_Ratio_Stage2_Dam                          40506 non-null  float64\n",
      " 34  RESIN_Volume_Ratio_Stage1_Fill1                        40506 non-null  float64\n",
      " 35  RESIN_Volume_Ratio_Stage2_Fill1                        40506 non-null  float64\n",
      " 36  Circle1_Line1_Equal_Dam                                40506 non-null  int32  \n",
      " 37  Circle2_Line2_Equal_Dam                                40506 non-null  int32  \n",
      " 38  Circle3_Line3_Equal_Dam                                40506 non-null  int32  \n",
      " 39  Circle4_Line4_Equal_Dam                                40506 non-null  int32  \n",
      " 40  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 41  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 42  2nd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 43  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 44  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 45  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 46  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 47  Workorder_0.9                                          40506 non-null  int64  \n",
      " 48  Workorder_0.7                                          40506 non-null  int64  \n",
      " 49  Workorder_0.5                                          40506 non-null  int64  \n",
      " 50  time_ratio_Dam                                         40506 non-null  float64\n",
      " 51  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 52  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 53  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(34), int32(4), int64(13), object(3)\n",
      "memory usage: 16.1+ MB\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "print('---')\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3540,
   "id": "769e6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 각 변수별로 결측값이 존재하는지 확인하는 코드\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 변수와 그 개수 출력\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(missing_values)\n",
    "\n",
    "# 결측값이 존재하는 변수명을 리스트에 담기\n",
    "missing_columns = missing_values.index.tolist()\n",
    "# print(\"결측값이 존재하는 변수명:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b20a3",
   "metadata": {},
   "source": [
    "## 타겟 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3541,
   "id": "fb37ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Model.Suffix', 'Workorder', 'target'], dtype='object')  train_object_columns 갯수 : 3\n",
      "Index(['Set ID', 'Model.Suffix', 'Workorder', 'target'], dtype='object')  test_object_columns 갯수 : 4\n",
      "\n",
      "Train Data:\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 663\n",
      "target unique 값 갯수: 2\n",
      "\n",
      "Test Data:\n",
      "Set ID unique 값 갯수: 17361\n",
      "Model.Suffix unique 값 갯수: 7\n",
      "Workorder unique 값 갯수: 662\n",
      "target unique 값 갯수: 0\n"
     ]
    }
   ],
   "source": [
    "# 'target' 열의 변수 타입을 object로 변경\n",
    "# -> test 데이터는 float64 타입으로 되어있음 \n",
    "test_data['target'] = test_data['target'].astype('object')\n",
    "\n",
    "# object 타입의 변수 출력\n",
    "train_object_columns = train_data.select_dtypes(include=['object']).columns\n",
    "test_object_columns = test_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(train_object_columns, f\" train_object_columns 갯수 : {len(train_object_columns)}\")\n",
    "print(test_object_columns, f\" test_object_columns 갯수 : {len(test_object_columns)}\")\n",
    "\n",
    "# 각 object 변수의 고유 값 개수 출력\n",
    "print(\"\\nTrain Data:\")\n",
    "for col in train_object_columns:\n",
    "    unique_count = train_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "for col in test_object_columns:\n",
    "    unique_count = test_data[col].nunique()\n",
    "    print(f\"{col} unique 값 갯수: {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3542,
   "id": "156c68be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model.Suffix  Workorder\n",
      "0      0.049336   0.158385\n",
      "1      0.049336   0.015314\n",
      "2      0.056712   0.009534\n",
      "   Model.Suffix  Workorder\n",
      "0      0.056712   0.091912\n",
      "1      0.056712   0.024247\n",
      "2      0.056712   0.091463\n",
      "--- train_data ---\n",
      "target  \n",
      "Normal      38156\n",
      "AbNormal     2350\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# 타겟 변수와 범주형 변수 지정\n",
    "## Target Encoding의 smoothing 파라미터는 default로 auto로 설정되어 있음\n",
    "target = 'target'  # 타겟 변수 이름으로 변경\n",
    "categorical_columns = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "]  # 범주형 변수 이름으로 변경\n",
    "\n",
    "# 타겟 값을 숫자로 변환\n",
    "target_mapping = {'Normal': 0, 'AbNormal': 1}\n",
    "train_data[target] = train_data[target].map(target_mapping)\n",
    "test_data[target] = test_data[target].map(target_mapping)\n",
    "\n",
    "# 열이 존재하는지 확인\n",
    "missing_columns = [col for col in categorical_columns if col not in train_data.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"train_data에 다음 열이 존재하지 않습니다: {missing_columns}\")\n",
    "\n",
    "# 타겟 인코더 생성 및 학습\n",
    "encoder = ce.TargetEncoder(cols=categorical_columns)\n",
    "train_data = encoder.fit_transform(train_data, train_data[target])\n",
    "\n",
    "# Set ID 열을 별도로 저장\n",
    "set_id = test_data['Set ID']\n",
    "\n",
    "# 테스트 데이터 인코딩 (Set ID 열 제외)\n",
    "test_data = test_data.drop(columns=['Set ID'])\n",
    "test_data = encoder.transform(test_data)\n",
    "\n",
    "# Set ID 열을 맨 앞에 추가\n",
    "test_data.insert(0, 'Set ID', set_id)\n",
    "\n",
    "# categorical_columns에 해당하는 열의 데이터 값만 확인\n",
    "print(train_data[categorical_columns].head(3))\n",
    "print(test_data[categorical_columns].head(3))\n",
    "\n",
    "# 역 매핑 딕셔너리 생성\n",
    "reverse_target_mapping = {v: k for k, v in target_mapping.items()}\n",
    "\n",
    "# 타겟 값을 원래대로 변환\n",
    "train_data[target] = train_data[target].map(reverse_target_mapping)\n",
    "test_data[target] = test_data[target].map(reverse_target_mapping)\n",
    "\n",
    "print(\"--- train_data ---\")\n",
    "\n",
    "# 변환된 타겟 값 확인\n",
    "print(train_data[[target]].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f925483",
   "metadata": {},
   "source": [
    "상관계수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3543,
   "id": "e8e65198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Variable1  \\\n",
      "823                                Dispenser_1   \n",
      "824                                Dispenser_1   \n",
      "825                                Dispenser_1   \n",
      "1513  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2   \n",
      "1514  HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2   \n",
      "1567  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2   \n",
      "1946                   Circle2_Line2_Equal_Dam   \n",
      "\n",
      "                                     Variable2  Correlation  \n",
      "823   HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2     0.999216  \n",
      "824   HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2     0.999211  \n",
      "825   HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2     0.999216  \n",
      "1513  HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2     0.999993  \n",
      "1514  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2     0.999999  \n",
      "1567  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2     0.999997  \n",
      "1946                   Circle4_Line4_Equal_Dam     1.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# 상관계수가 0.9 이상인 조합 찾기\n",
    "high_corr_pairs = correlation_matrix.unstack().reset_index()\n",
    "high_corr_pairs.columns = ['Variable1', 'Variable2', 'Correlation']\n",
    "high_corr_pairs = high_corr_pairs[(high_corr_pairs['Correlation'] >= 0.9) & (high_corr_pairs['Variable1'] != high_corr_pairs['Variable2'])]\n",
    "\n",
    "# 중복 제거 (Variable1-Variable2와 Variable2-Variable1은 동일한 조합이므로)\n",
    "high_corr_pairs = high_corr_pairs.drop_duplicates(subset=['Correlation'])\n",
    "\n",
    "# 상관계수가 0.9 이상인 조합 출력\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3544,
   "id": "c98848d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill2'\n",
    ", 'HEAD NORMAL DISTANCE_STAGE2_STAGE3_Fill2'\n",
    ", 'HEAD NORMAL DISTANCE_STAGE1_STAGE2_Fill2'\n",
    ", 'Circle4_Line4_Equal_Dam'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3545,
   "id": "6559dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Variable1                 Variable2  \\\n",
      "315   Head Zero Position Z Collect Result_Dam            Judge_Value_OK   \n",
      "802                               Dispenser_2   PalletID_Collect_Result   \n",
      "1853                 2nd_Pressure_x_AutoClave  Chamber_Temp_x_AutoClave   \n",
      "2151                            Workorder_0.7             Workorder_0.5   \n",
      "\n",
      "      Correlation  \n",
      "315      0.800262  \n",
      "802      0.860274  \n",
      "1853     0.804096  \n",
      "2151     0.816325  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 상관계수 계산\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# 상관계수가 0.9 이상인 조합 찾기\n",
    "high_corr_pairs = correlation_matrix.unstack().reset_index()\n",
    "high_corr_pairs.columns = ['Variable1', 'Variable2', 'Correlation']\n",
    "high_corr_pairs = high_corr_pairs[(high_corr_pairs['Correlation'] >= 0.8) & (high_corr_pairs['Variable1'] != high_corr_pairs['Variable2'])]\n",
    "\n",
    "# 중복 제거 (Variable1-Variable2와 Variable2-Variable1은 동일한 조합이므로)\n",
    "high_corr_pairs = high_corr_pairs.drop_duplicates(subset=['Correlation'])\n",
    "\n",
    "# 상관계수가 0.9 이상인 조합 출력\n",
    "print(high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3546,
   "id": "6a831b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제거할 변수 목록\n",
    "columns_to_drop = [\n",
    "'Judge_Value_OK'\n",
    ", 'PalletID_Collect_Result'\n",
    ", '2nd_Pressure_x_AutoClave'\n",
    ", 'Workorder_0.7'\n",
    "]\n",
    "\n",
    "# 변수 제거\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3547,
   "id": "6a108490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 46 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Model.Suffix                                           40506 non-null  float64\n",
      " 1   Workorder                                              40506 non-null  float64\n",
      " 2   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    40506 non-null  float64\n",
      " 3   Head Clean Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 4   Head Purge Position Z Collect Result_Dam               40506 non-null  float64\n",
      " 5   Head Zero Position Y Collect Result_Dam                40506 non-null  float64\n",
      " 6   Head Zero Position Z Collect Result_Dam                40506 non-null  float64\n",
      " 7   WorkMode Collect Result                                40506 non-null  float64\n",
      " 8   1st Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 9   2nd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 10  3rd Pressure Collect Result_AutoClave                  40506 non-null  float64\n",
      " 11  Chamber Temp. Collect Result_AutoClave                 40506 non-null  int64  \n",
      " 12  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  40506 non-null  float64\n",
      " 13  Head Purge Position Z Collect Result_Fill1             40506 non-null  int64  \n",
      " 14  Head Purge Position Z Collect Result_Fill2             40506 non-null  float64\n",
      " 15  target                                                 40506 non-null  object \n",
      " 16  Dispenser_1                                            40506 non-null  int64  \n",
      " 17  Dispenser_2                                            40506 non-null  int64  \n",
      " 18  Receip_No_Collect_Result                               40506 non-null  int64  \n",
      " 19  Production_Qty_Collect_Result                          40506 non-null  int64  \n",
      " 20  Chamber_Temp_OKNG_AutoClave                            40506 non-null  int64  \n",
      " 21  CURE_Time_Dam                                          40506 non-null  float64\n",
      " 22  CURE_Time_Fill2                                        40506 non-null  float64\n",
      " 23  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 40506 non-null  float64\n",
      " 24  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               40506 non-null  float64\n",
      " 25  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               40506 non-null  float64\n",
      " 26  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             40506 non-null  float64\n",
      " 27  RESIN_Volume_Ratio_Stage1_Dam                          40506 non-null  float64\n",
      " 28  RESIN_Volume_Ratio_Stage2_Dam                          40506 non-null  float64\n",
      " 29  RESIN_Volume_Ratio_Stage1_Fill1                        40506 non-null  float64\n",
      " 30  RESIN_Volume_Ratio_Stage2_Fill1                        40506 non-null  float64\n",
      " 31  Circle1_Line1_Equal_Dam                                40506 non-null  int32  \n",
      " 32  Circle2_Line2_Equal_Dam                                40506 non-null  int32  \n",
      " 33  Circle3_Line3_Equal_Dam                                40506 non-null  int32  \n",
      " 34  Total_THICKNESS_Collect_Result_Dam                     40506 non-null  float64\n",
      " 35  1st_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 36  3rd_Pressure_x_AutoClave                               40506 non-null  float64\n",
      " 37  All_Pressure_avg_AutoClave                             40506 non-null  float64\n",
      " 38  Chamber_Temp_x_AutoClave                               40506 non-null  int64  \n",
      " 39  All_Pressure_frac_Chamber_Temp_AutoClave               40506 non-null  float64\n",
      " 40  Workorder_0.9                                          40506 non-null  int64  \n",
      " 41  Workorder_0.5                                          40506 non-null  int64  \n",
      " 42  time_ratio_Dam                                         40506 non-null  float64\n",
      " 43  time_ratio_Fill1                                       40506 non-null  float64\n",
      " 44  time_ratio_Fill2                                       40506 non-null  float64\n",
      " 45  time_ratio_AutoClave                                   40506 non-null  float64\n",
      "dtypes: float64(32), int32(3), int64(10), object(1)\n",
      "memory usage: 13.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3548,
   "id": "2a5581c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17361 entries, 0 to 17360\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype  \n",
      "---  ------                                                 --------------  -----  \n",
      " 0   Set ID                                                 17361 non-null  object \n",
      " 1   Model.Suffix                                           17361 non-null  float64\n",
      " 2   Workorder                                              17361 non-null  float64\n",
      " 3   DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam    17361 non-null  float64\n",
      " 4   Head Clean Position Z Collect Result_Dam               17361 non-null  float64\n",
      " 5   Head Purge Position Z Collect Result_Dam               17361 non-null  float64\n",
      " 6   Head Zero Position Y Collect Result_Dam                17361 non-null  float64\n",
      " 7   Head Zero Position Z Collect Result_Dam                17361 non-null  float64\n",
      " 8   WorkMode Collect Result                                17361 non-null  float64\n",
      " 9   1st Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 10  2nd Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 11  3rd Pressure Collect Result_AutoClave                  17361 non-null  float64\n",
      " 12  Chamber Temp. Collect Result_AutoClave                 17361 non-null  int64  \n",
      " 13  DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1  17361 non-null  float64\n",
      " 14  Head Purge Position Z Collect Result_Fill1             17361 non-null  float64\n",
      " 15  Head Purge Position Z Collect Result_Fill2             17361 non-null  float64\n",
      " 16  target                                                 0 non-null      object \n",
      " 17  Dispenser_1                                            17361 non-null  int64  \n",
      " 18  Dispenser_2                                            17361 non-null  int64  \n",
      " 19  Receip_No_Collect_Result                               17361 non-null  float64\n",
      " 20  Production_Qty_Collect_Result                          17361 non-null  float64\n",
      " 21  Chamber_Temp_OKNG_AutoClave                            17361 non-null  int64  \n",
      " 22  CURE_Time_Dam                                          17361 non-null  float64\n",
      " 23  CURE_Time_Fill2                                        17361 non-null  float64\n",
      " 24  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Dam                 17361 non-null  float64\n",
      " 25  HEAD NORMAL DISTANCE_TRIANGLE_height_Dam               17361 non-null  float64\n",
      " 26  HEAD NORMAL DISTANCE_STAGE1_STAGE3_Fill1               17361 non-null  float64\n",
      " 27  HEAD NORMAL DISTANCE_TRIANGLE_height_Fill1             17361 non-null  float64\n",
      " 28  RESIN_Volume_Ratio_Stage1_Dam                          17361 non-null  float64\n",
      " 29  RESIN_Volume_Ratio_Stage2_Dam                          17361 non-null  float64\n",
      " 30  RESIN_Volume_Ratio_Stage1_Fill1                        17361 non-null  float64\n",
      " 31  RESIN_Volume_Ratio_Stage2_Fill1                        17361 non-null  float64\n",
      " 32  Circle1_Line1_Equal_Dam                                17361 non-null  int32  \n",
      " 33  Circle2_Line2_Equal_Dam                                17361 non-null  int32  \n",
      " 34  Circle3_Line3_Equal_Dam                                17361 non-null  int32  \n",
      " 35  Total_THICKNESS_Collect_Result_Dam                     17361 non-null  float64\n",
      " 36  1st_Pressure_x_AutoClave                               17361 non-null  float64\n",
      " 37  3rd_Pressure_x_AutoClave                               17361 non-null  float64\n",
      " 38  All_Pressure_avg_AutoClave                             17361 non-null  float64\n",
      " 39  Chamber_Temp_x_AutoClave                               17361 non-null  int64  \n",
      " 40  All_Pressure_frac_Chamber_Temp_AutoClave               17361 non-null  float64\n",
      " 41  Workorder_0.9                                          17361 non-null  int64  \n",
      " 42  Workorder_0.5                                          17361 non-null  int64  \n",
      " 43  time_ratio_Dam                                         17361 non-null  float64\n",
      " 44  time_ratio_Fill1                                       17361 non-null  float64\n",
      " 45  time_ratio_Fill2                                       17361 non-null  float64\n",
      " 46  time_ratio_AutoClave                                   17361 non-null  float64\n",
      "dtypes: float64(35), int32(3), int64(7), object(2)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276e6df",
   "metadata": {},
   "source": [
    "## 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3549,
   "id": "de8996fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \tAbnormal\tNormal\n",
      "  Total: Normal: 30524, AbNormal: 1880 ratio: 0.06159087930808544\n",
      "  Total: Normal: 7632, AbNormal: 470 ratio: 0.061582809224318656\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.2,\n",
    "    stratify=train_data[\"target\"],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "def print_stats(df: pd.DataFrame):\n",
    "    num_normal = len(df[df[\"target\"] == \"Normal\"])\n",
    "    num_abnormal = len(df[df[\"target\"] == \"AbNormal\"])\n",
    "\n",
    "    print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\" + f\" ratio: {num_abnormal/num_normal}\")\n",
    "\n",
    "\n",
    "# Print statistics\n",
    "print(f\"  \\tAbnormal\\tNormal\")\n",
    "print_stats(df_train)\n",
    "print_stats(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3550,
   "id": "fb9e8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred_proba, threshold=0.5):\n",
    "    # 확률을 기준으로 예측 레이블 생성\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)  # 0.5 이상의 확률을 양성으로 간주\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e56224",
   "metadata": {},
   "source": [
    "optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec04f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "# train_data['target'] = train_data['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1000, 3000),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 300, 3000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 3, 100),\n",
    "        \n",
    "#         'boosting': 'dart',  # dart 사용\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         'verbose': -1\n",
    "#     }\n",
    "       \n",
    "#     model = LGBMClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),\n",
    "#     train_data[\"target\"],\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=500)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb958f",
   "metadata": {},
   "source": [
    "Trial 20 finished with value: 0.22156573116691286 and parameters: {'n_estimators': 2663, 'num_leaves': 2606, 'max_depth': 252,  \n",
    "'learning_rate': 0.0735993514037681, 'min_child_samples': 79}. Best is trial 20 with value: 0.22156573116691286."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3552,
   "id": "0d6d6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=2663\n",
    "    , num_leaves=2606\n",
    "    , max_depth=252\n",
    "    , learning_rate=0.0735993514037681\n",
    "    , min_child_samples=79\n",
    "    , verbose = -1\n",
    "    , boosting= 'dart'\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3553,
   "id": "1072be63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting='dart', learning_rate=0.0735993514037681, max_depth=252,\n",
       "               min_child_samples=79, n_estimators=2663, num_leaves=2606,\n",
       "               random_state=110, verbose=-1)"
      ]
     },
     "execution_count": 3553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "df_train[\"target\"] = df_train[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "# features = df_train.columns.tolist()\n",
    "\n",
    "train_x = df_train.drop(columns=[\"target\"])\n",
    "train_y = df_train[\"target\"]\n",
    "\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "id": "43b3c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 준비\n",
    "df_val[\"target\"] = df_val[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "val_x = df_val.drop(columns=[\"target\"])\n",
    "val_y = df_val[\"target\"]\n",
    "\n",
    "# 확률 예측\n",
    "y_pred_proba = model.predict_proba(val_x)[:, 1]  # 양성 클래스에 대한 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3555,
   "id": "79263b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7515  117]\n",
      " [ 407   63]]\n",
      "Accuracy: 0.9353\n",
      "Precision: 0.3500\n",
      "Recall: 0.1340\n",
      "F1 Score: 0.1938\n"
     ]
    }
   ],
   "source": [
    "## 스레스홀드 적용\n",
    "threshold = 0.3\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3554,
   "id": "924bb7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[7410  222]\n",
      " [ 392   78]]\n",
      "Accuracy: 0.9242\n",
      "Precision: 0.2600\n",
      "Recall: 0.1660\n",
      "F1 Score: 0.2026\n"
     ]
    }
   ],
   "source": [
    "## 스레스홀드 적용\n",
    "threshold = 0.2\n",
    "y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# 모델 성능 평가\n",
    "get_clf_eval(val_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990d2c7",
   "metadata": {},
   "source": [
    "분할한 데이터 -> 원래의 데이터(train data)로 학습한 새 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "id": "fedb270f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15dc97b9388>"
      ]
     },
     "execution_count": 1495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train 데이터로 학습\n",
    "train_data[\"target\"] = train_data[\"target\"].apply(lambda x: 1 if x == 'AbNormal' else 0)\n",
    "\n",
    "train_x_all = train_data.drop(columns=[\"target\"])\n",
    "train_y_all = train_data[\"target\"]\n",
    "\n",
    "model.fit(train_x_all, train_y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "48bdb493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 확률\n",
    "probs = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# 스레숄드 조절\n",
    "threshold = 0.2\n",
    "preds = [1 if prob >= threshold else 0 for prob in probs]\n",
    "\n",
    "# 테스트 데이터에서 AbNormal로 예측된 개수 출력\n",
    "print(sum(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = preds\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      16727\n",
       "AbNormal      634\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "9efee1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID  target\n",
       "0  0001be084fbc4aaa9d921f39e595961b  Normal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80  Normal\n",
       "2  000948934c4140d883d670adcb609584  Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7  Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95  Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2  Normal\n",
       "6  0020734a7b29472298358ad58645a0c9  Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135  Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  Normal\n",
       "9  002d904240d84b188d410d16383a9c3a  Normal"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
