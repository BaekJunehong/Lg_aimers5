{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce97401-9de4-483b-a353-6587b77590ba",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da636f9-5109-44d2-82aa-81ea60741631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541415b4-bc7d-4a89-87c0-05fa9d5d4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 불러오기\n",
    "train_data = pd.read_csv('trim_train_data.csv')\n",
    "test_data = pd.read_csv('trim_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe51167-d3dd-449f-9a7b-fec4bc3bb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 열을 임시로 분리\n",
    "target_train = train_data['target']\n",
    "target_test = test_data['target']\n",
    "\n",
    "# 모든 값이 NaN인 열 제거\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "\n",
    "# target 열을 다시 결합\n",
    "train_data['target'] = target_train\n",
    "test_data['target'] = target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046450a1-0f40-4842-9465-ff3127838dc3",
   "metadata": {},
   "source": [
    "### 좌표 관련 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb02bf9-36fb-4985-a97a-13086c83645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레진 도포 좌표 - 새로운 좌표에 대한 거리와 방향 계산하는 함수\n",
    "def calculate_vector(row, stage, process):\n",
    "    x = row[f'HEAD NORMAL COORDINATE X AXIS(Stage{stage}) Collect Result_{process}']\n",
    "    y = row[f'HEAD NORMAL COORDINATE Y AXIS(Stage{stage}) Collect Result_{process}']\n",
    "    z = row[f'HEAD NORMAL COORDINATE Z AXIS(Stage{stage}) Collect Result_{process}']\n",
    "    \n",
    "    a = row[f'HEAD Standby Position X Collect Result_{process}']\n",
    "    b = row[f'HEAD Standby Position Y Collect Result_{process}']\n",
    "    c = row[f'HEAD Standby Position Z Collect Result_{process}']\n",
    "    \n",
    "    # 두 좌표 간의 거리 계산\n",
    "    dx = x - a\n",
    "    dy = y - b\n",
    "    dz = z - c\n",
    "    distance = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "    \n",
    "    # 단위 벡터 계산\n",
    "    if distance != 0:  # 0으로 나누는 것을 방지\n",
    "        unit_vector = (dx / distance, dy / distance, dz / distance)\n",
    "    else:\n",
    "        unit_vector = (0, 0, 0)  # 거리 0일 때 단위 벡터는 정의되지 않음\n",
    "\n",
    "    combined_value = distance * (unit_vector[0] + unit_vector[1] + unit_vector[2])\n",
    "    \n",
    "    return combined_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5693f19-a8c1-430c-b306-15135985e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_store_vectors(data, process):\n",
    "    for stage in range(1, 4):\n",
    "        data[f'head_normal_vector_stage{stage}_{process}'] = data.apply(calculate_vector, axis=1, stage=stage, process=process)\n",
    "\n",
    "# train\n",
    "calculate_and_store_vectors(train_data, 'Dam')\n",
    "calculate_and_store_vectors(train_data, 'Fill1')\n",
    "calculate_and_store_vectors(train_data, 'Fill2')\n",
    "\n",
    "# test\n",
    "calculate_and_store_vectors(test_data, 'Dam')\n",
    "calculate_and_store_vectors(test_data, 'Fill1')\n",
    "calculate_and_store_vectors(test_data, 'Fill2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc59a87-e73b-4b4a-9423-1a4a1d01acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레진 도포 좌표 X, Y, Z 컬럼 드롭\n",
    "columns_to_drop = [\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Dam',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam',\n",
    "\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill1',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill1',\n",
    "    \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Judge Value_Fill2',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Fill2',\n",
    "    'HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 컬럼 드롭\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15da86f5-2b41-41b6-8910-a2290d423788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \bUV 경화 좌표 합치기\n",
    "def create_coordinate_columns(data):\n",
    "    # Dam\n",
    "    # cure end\n",
    "    data['cure_end_position_XZΘ_Dam'] = (\n",
    "        data['CURE END POSITION X Collect Result_Dam'].astype(str) + ',' +\n",
    "        data['CURE END POSITION Z Collect Result_Dam'].astype(str) + ',' +\n",
    "        data['CURE END POSITION Θ Collect Result_Dam'].astype(str)\n",
    "    )\n",
    "\n",
    "    # cure start\n",
    "    data['cure_start_position_XΘ_Dam'] = (\n",
    "        data['CURE START POSITION X Collect Result_Dam'].astype(str) + ',' +\n",
    "        data['CURE START POSITION Θ Collect Result_Dam'].astype(str)\n",
    "    )\n",
    "\n",
    "    # Fill2\n",
    "    # cure end\n",
    "    data['cure_end_position_XZ_Fill2'] = (\n",
    "        data['CURE END POSITION X Collect Result_Fill2'].astype(str) + ',' +\n",
    "        data['CURE END POSITION Z Collect Result_Fill2'].astype(str) \n",
    "    )\n",
    "\n",
    "    # cure start\n",
    "    data['cure_start_position_XZ_Fill2'] = (\n",
    "        data['CURE START POSITION X Collect Result_Fill2'].astype(str) + ',' +\n",
    "        data['CURE START POSITION Z Collect Result_Fill2'].astype(str) \n",
    "    )\n",
    "\n",
    "# train_data와 test_data에 대해 함수 호출\n",
    "create_coordinate_columns(train_data)\n",
    "create_coordinate_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6b8844-ee3c-4199-a709-5e1884a95b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UV 경화 좌표 X, Y, Z 컬럼 드롭\n",
    "columns_to_drop = [\n",
    "    'CURE END POSITION X Collect Result_Dam',\n",
    "    'CURE END POSITION Z Collect Result_Dam',\n",
    "    'CURE END POSITION Θ Collect Result_Dam',\n",
    "    'CURE START POSITION X Collect Result_Dam',\n",
    "    'CURE START POSITION Θ Collect Result_Dam',\n",
    "\n",
    "    'CURE END POSITION X Collect Result_Fill2',\n",
    "    'CURE END POSITION Z Collect Result_Fill2',\n",
    "    'CURE START POSITION X Collect Result_Fill2',\n",
    "    'CURE START POSITION Z Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 컬럼 드롭\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17ce817-1b58-47b6-ab70-367fc53ef080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dam 노즐 zero 위치 Z좌표 드롭\n",
    "train_data.drop(columns='Head Zero Position Z Collect Result_Dam', inplace=True)\n",
    "test_data.drop(columns='Head Zero Position Z Collect Result_Dam', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b7bbb-374e-4144-9bf4-7fa65832810d",
   "metadata": {},
   "source": [
    "### 기본 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035d7f97-18f4-4388-809a-b77dc853e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wip Line 열 제거\n",
    "wip_line_columns = train_data.filter(like='Wip Line').columns\n",
    "\n",
    "train_data.drop(columns=wip_line_columns, inplace=True)\n",
    "test_data.drop(columns=wip_line_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54078a22-a1ea-4e9a-b772-c3d92feecd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Desc 열 제거\n",
    "Process_Desc_col = train_data.filter(like='Process Desc').columns\n",
    "\n",
    "train_data.drop(columns=Process_Desc_col, inplace=True)\n",
    "test_data.drop(columns=Process_Desc_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea254e4-5361-4b5a-9842-7bffd40b0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equipment로 시작하는 열 필터링\n",
    "Equipment_col = train_data.filter(like='Equipment').columns\n",
    "Equipment_col2 = test_data.filter(like='Equipment').columns\n",
    "\n",
    "new_train = train_data.filter(items=Equipment_col)\n",
    "new_test = test_data.filter(items=Equipment_col2)\n",
    "\n",
    "# Equipment_same_num 파생변수 생성\n",
    "def determine_equipment_same_num(row):\n",
    "    if (row['Equipment_Dam'] == 'Dam dispenser #1' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #1' and row['Equipment_Fill2'] == 'Fill2 dispenser #1') or \\\n",
    "       (row['Equipment_Dam'] == 'Dam dispenser #2' and row['Equipment_AutoClave'] == 'Auto Clave Out' and \n",
    "        row['Equipment_Fill1'] == 'Fill1 dispenser #2' and row['Equipment_Fill2'] == 'Fill2 dispenser #2'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data['Equipment_same_num'] = new_train.apply(determine_equipment_same_num, axis=1)\n",
    "test_data['Equipment_same_num'] = new_test.apply(determine_equipment_same_num, axis=1)\n",
    "\n",
    "train_data = train_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])\n",
    "test_data = test_data.drop(columns=['Equipment_Dam', 'Equipment_AutoClave', 'Equipment_Fill1', 'Equipment_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df25bda-b738-4a06-a443-94060702b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.Suffix_Dam의 이름을 Model.Suffix로 변경\n",
    "train_data = train_data.rename(columns={'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "test_data = test_data.rename(columns={'Model.Suffix_Dam': 'Model.Suffix'})\n",
    "\n",
    "# Model.Suffix_AutoClave, Model.Suffix_Fill1, Model.Suffix_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])\n",
    "test_data = test_data.drop(columns=['Model.Suffix_AutoClave', 'Model.Suffix_Fill1', 'Model.Suffix_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38bbc4e0-01ce-474c-8a60-e7f1ce2f9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workorder_Dam의 이름을 Workorder로 변경\n",
    "train_data = train_data.rename(columns={'Workorder_Dam': 'Workorder'})\n",
    "test_data = test_data.rename(columns={'Workorder_Dam': 'Workorder'})\n",
    "\n",
    "# Workorder_AutoClave, Workorder_Fill1, Workorder_Fill2 열 드롭\n",
    "train_data = train_data.drop(columns=['Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])\n",
    "test_data = test_data.drop(columns=['Workorder_AutoClave', 'Workorder_Fill1', 'Workorder_Fill2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a06479d-6380-4498-ad75-26ad16673fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insp. Seq No 열 제거\n",
    "Insp_Seq_No_col = train_data.filter(like='Insp. Seq No').columns\n",
    "\n",
    "train_data.drop(columns=Insp_Seq_No_col, inplace=True)\n",
    "test_data.drop(columns=Insp_Seq_No_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c56c92-bf89-452b-b8c3-01e7ee19b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insp Judge Code 열 제거\n",
    "Insp_Judge_Code_col = train_data.filter(like='Insp Judge Code').columns\n",
    "\n",
    "train_data.drop(columns=Insp_Judge_Code_col, inplace=True)\n",
    "test_data.drop(columns=Insp_Judge_Code_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434b1df0-e37c-4a66-a367-d6228b941d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 train_data 열 개수: 42\n",
      "삭제된 test_data 열 개수: 42\n"
     ]
    }
   ],
   "source": [
    "# 값의 종류가 1개이고 결측값이 없는 열을 제거하는 함수\n",
    "def drop_single_value_columns(df):\n",
    "    cols_to_drop = [col for col in df.columns if col != 'target' and df[col].nunique() == 1 and df[col].isnull().sum() == 0]\n",
    "    df_dropped = df.drop(columns=cols_to_drop)\n",
    "    return df_dropped, cols_to_drop\n",
    "\n",
    "# train_data와 test_data에서 해당 열 제거 및 삭제된 열 이름과 개수 출력\n",
    "train_data, train_cols_dropped = drop_single_value_columns(train_data)\n",
    "test_data, test_cols_dropped = drop_single_value_columns(test_data)\n",
    "\n",
    "# print(\"삭제된 train_data 열 이름:\", train_cols_dropped)\n",
    "print(\"삭제된 train_data 열 개수:\", len(train_cols_dropped))\n",
    "\n",
    "# print(\"삭제된 test_data 열 이름:\", test_cols_dropped)\n",
    "print(\"삭제된 test_data 열 개수:\", len(test_cols_dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f36fc-0f1e-41dd-8908-6d6ceb84abc5",
   "metadata": {},
   "source": [
    "### 제품 관련 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9950e772-b860-410f-b011-9a414ccca06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성: 3개의 컬럼 값이 모두 동일하면 해당 값을 저장, 아니면 diff\n",
    "train_data['Receip_No'] = train_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "test_data['Receip_No'] = test_data.apply(\n",
    "    lambda row: row['Receip No Collect Result_Dam'] if (row['Receip No Collect Result_Dam'] == row['Receip No Collect Result_Fill1'] == row['Receip No Collect Result_Fill2']) else 'diff',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2c8b86-5dbc-47ba-8240-40fc71002189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생변수 생성: Receip No와 Model.Suffix의 조합\n",
    "train_data['model_receip'] = train_data['Model.Suffix'] + '_' + train_data['Receip_No'].astype(str)\n",
    "test_data['model_receip'] = test_data['Model.Suffix'] + '_' + test_data['Receip_No'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8591e8-8b9c-4635-ab55-c6abbb8025e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \b파생변수 생성: workorder 앞 4자리 -> workorder_prefix\n",
    "train_data['workorder_prefix'] = train_data['Workorder'].str[:4]\n",
    "test_data['workorder_prefix'] = test_data['Workorder'].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b51e608b-aa87-4eb6-b527-0bdf5f062bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \b파생변수 생성: Receip No와 workorder_prefix의 조합 -> diff, 3.0, 9.0의 경우에만\n",
    "train_data['workorder_receip'] = train_data.apply(\n",
    "    lambda row: f\"{row['workorder_prefix']}_{row['Receip_No']}\" \n",
    "    if row['Receip_No'] in ['diff', 3.0, 9.0] else row['workorder_prefix'],\n",
    "    axis=1\n",
    ")\n",
    "test_data['workorder_receip'] = test_data.apply(\n",
    "    lambda row: f\"{row['workorder_prefix']}_{row['Receip_No']}\" \n",
    "    if row['Receip_No'] in ['diff', 3.0, 9.0] else row['workorder_prefix'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d315800b-c8da-41b1-a4d2-178180380c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Model.Suffix',\n",
    "    'Workorder',\n",
    "    'workorder_prefix',\n",
    "    'Receip_No',\n",
    "    'Receip No Collect Result_Dam',\n",
    "    'Receip No Collect Result_Fill1',\n",
    "    'Receip No Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 컬럼 드롭\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcc89b-0ce3-4bd9-9df1-8a4c127c0aa0",
   "metadata": {},
   "source": [
    "### dam circle & line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c205c242-5bc6-4077-84e4-27bcbbb4bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## circle train\n",
    "# Stage1과 Stage2의 차이 절댓값 계산\n",
    "train_data['Stage1_Stage2_Absolute_Difference'] = abs(train_data['Stage2 Circle1 Distance Speed Collect Result_Dam'] - train_data['Stage1 Circle1 Distance Speed Collect Result_Dam'])\n",
    "\n",
    "# Stage2와 Stage3의 차이 절댓값 계산\n",
    "train_data['Stage2_Stage3_Absolute_Difference'] = abs(train_data['Stage3 Circle1 Distance Speed Collect Result_Dam'] - train_data['Stage2 Circle1 Distance Speed Collect Result_Dam'])\n",
    "\n",
    "# 두 개의 절댓값 차이를 더한 값 계산\n",
    "train_data['total_circle_distance_speed_Dam'] = (\n",
    "    train_data['Stage1_Stage2_Absolute_Difference'] + \n",
    "    train_data['Stage2_Stage3_Absolute_Difference']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f041d807-69c5-4f99-bf1d-c35d6ffdfd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## circle test\n",
    "# Stage1과 Stage2의 차이 절댓값 계산\n",
    "test_data['Stage1_Stage2_Absolute_Difference'] = abs(test_data['Stage2 Circle1 Distance Speed Collect Result_Dam'] - test_data['Stage1 Circle1 Distance Speed Collect Result_Dam'])\n",
    "\n",
    "# Stage2와 Stage3의 차이 절댓값 계산\n",
    "test_data['Stage2_Stage3_Absolute_Difference'] = abs(test_data['Stage3 Circle1 Distance Speed Collect Result_Dam'] - test_data['Stage2 Circle1 Distance Speed Collect Result_Dam'])\n",
    "\n",
    "# 두 개의 절댓값 차이를 더한 값 계산\n",
    "test_data['total_circle_distance_speed_Dam'] = (\n",
    "    test_data['Stage1_Stage2_Absolute_Difference'] + \n",
    "    test_data['Stage2_Stage3_Absolute_Difference']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8610db7c-a3d2-4c47-a723-138d83d24c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## line train\n",
    "# stage1 (같으면 그 값, 다르면 diff)\n",
    "train_data['stage1_line_distance_speed_Dam'] = train_data.apply(\n",
    "    lambda row: row['Stage1 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage1 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# stage2 (같으면 그 값, 다르면 diff)\n",
    "train_data['stage2_line_distance_speed_Dam'] = train_data.apply(\n",
    "    lambda row: row['Stage2 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage2 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# stage3 (같으면 그 값, 다르면 diff)\n",
    "train_data['stage3_line_distance_speed_Dam'] = train_data.apply(\n",
    "    lambda row: row['Stage3 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage3 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# total stage (같으면 그 값, 다르면 diff)\n",
    "train_data['total_line_distance_speed_Dam'] = train_data.apply(\n",
    "    lambda row: row['stage1_line_distance_speed_Dam'] \n",
    "    if (row['stage1_line_distance_speed_Dam'] == \n",
    "        row['stage2_line_distance_speed_Dam'] == \n",
    "        row['stage3_line_distance_speed_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05363714-343b-4893-bee0-57f5863e37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## line test\n",
    "# stage1 (같으면 그 값, 다르면 diff)\n",
    "test_data['stage1_line_distance_speed_Dam'] = test_data.apply(\n",
    "    lambda row: row['Stage1 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage1 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage1 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# stage2 (같으면 그 값, 다르면 diff)\n",
    "test_data['stage2_line_distance_speed_Dam'] = test_data.apply(\n",
    "    lambda row: row['Stage2 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage2 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage2 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# stage3 (같으면 그 값, 다르면 diff)\n",
    "test_data['stage3_line_distance_speed_Dam'] = test_data.apply(\n",
    "    lambda row: row['Stage3 Line1 Distance Speed Collect Result_Dam'] \n",
    "    if (row['Stage3 Line1 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line2 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line3 Distance Speed Collect Result_Dam'] == \n",
    "        row['Stage3 Line4 Distance Speed Collect Result_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# total stage (같으면 그 값, 다르면 diff)\n",
    "test_data['total_line_distance_speed_Dam'] = test_data.apply(\n",
    "    lambda row: row['stage1_line_distance_speed_Dam'] \n",
    "    if (row['stage1_line_distance_speed_Dam'] == \n",
    "        row['stage2_line_distance_speed_Dam'] == \n",
    "        row['stage3_line_distance_speed_Dam']) else 'diff',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a39f89bb-6017-484c-83f4-700f22755b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드랍할 열 목록\n",
    "columns_to_drop = [\n",
    "    'Stage1 Circle1 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage1 Line4 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle1 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage2 Line4 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle1 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Circle4 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line1 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line2 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line3 Distance Speed Collect Result_Dam',\n",
    "    'Stage3 Line4 Distance Speed Collect Result_Dam',\n",
    "    'Stage1_Stage2_Absolute_Difference',\n",
    "    'Stage2_Stage3_Absolute_Difference',\n",
    "    'stage1_line_distance_speed_Dam',\n",
    "    'stage2_line_distance_speed_Dam',\n",
    "    'stage3_line_distance_speed_Dam'\n",
    "]\n",
    "\n",
    "# 열 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30d3a1-d003-42b7-8e35-0807f9fdbdba",
   "metadata": {},
   "source": [
    "### dam dispense volume & time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11325e8d-e7d9-4d98-9d48-75bbbdb09c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train\n",
    "# volume*time 파생변수 - Dam\n",
    "train_data['volume_time_multip_stage1_Dam'] = train_data['Dispense Volume(Stage1) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "train_data['volume_time_multip_stage2_Dam'] = train_data['Dispense Volume(Stage2) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "train_data['volume_time_multip_stage3_Dam'] = train_data['Dispense Volume(Stage3) Collect Result_Dam'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "\n",
    "train_data['volume_time_multip_avg_Dam'] = (train_data['volume_time_multip_stage1_Dam'] + \n",
    "                                            train_data['volume_time_multip_stage2_Dam'] + \n",
    "                                            train_data['volume_time_multip_stage3_Dam']) / 3\n",
    "\n",
    "# volume*time 파생변수 - Fill1\n",
    "train_data['volume_time_multip_stage1_Fill1'] = train_data['Dispense Volume(Stage1) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "train_data['volume_time_multip_stage2_Fill1'] = train_data['Dispense Volume(Stage2) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "train_data['volume_time_multip_stage3_Fill1'] = train_data['Dispense Volume(Stage3) Collect Result_Fill1'] * train_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "\n",
    "train_data['volume_time_multip_avg_Fill1'] = (train_data['volume_time_multip_stage1_Fill1'] + \n",
    "                                            train_data['volume_time_multip_stage2_Fill1'] + \n",
    "                                            train_data['volume_time_multip_stage3_Fill1']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b14c1fdb-b2f1-4cde-9c52-8ef268018ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "# volume*time 파생변수 - Dam\n",
    "test_data['volume_time_multip_stage1_Dam'] = test_data['Dispense Volume(Stage1) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam']\n",
    "test_data['volume_time_multip_stage2_Dam'] = test_data['Dispense Volume(Stage2) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam']\n",
    "test_data['volume_time_multip_stage3_Dam'] = test_data['Dispense Volume(Stage3) Collect Result_Dam'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam']\n",
    "\n",
    "test_data['volume_time_multip_avg_Dam'] = (test_data['volume_time_multip_stage1_Dam'] + \n",
    "                                            test_data['volume_time_multip_stage2_Dam'] + \n",
    "                                            test_data['volume_time_multip_stage3_Dam']) / 3\n",
    "\n",
    "# volume*time 파생변수 - Fill1\n",
    "test_data['volume_time_multip_stage1_Fill1'] = test_data['Dispense Volume(Stage1) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1']\n",
    "test_data['volume_time_multip_stage2_Fill1'] = test_data['Dispense Volume(Stage2) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1']\n",
    "test_data['volume_time_multip_stage3_Fill1'] = test_data['Dispense Volume(Stage3) Collect Result_Fill1'] * test_data['DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1']\n",
    "\n",
    "test_data['volume_time_multip_avg_Fill1'] = (test_data['volume_time_multip_stage1_Fill1'] + \n",
    "                                            test_data['volume_time_multip_stage2_Fill1'] + \n",
    "                                            test_data['volume_time_multip_stage3_Fill1']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9edcc103-3d81-4419-9aad-73708d893b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 열 목록 추가\n",
    "columns_to_drop = [\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam',\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam',\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage1) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage2) Collect Result_Dam',\n",
    "    'Dispense Volume(Stage3) Collect Result_Dam',\n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1',\n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1',\n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1',\n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1',\n",
    "    'volume_time_multip_stage1_Dam',\n",
    "    'volume_time_multip_stage2_Dam',\n",
    "    'volume_time_multip_stage3_Dam',\n",
    "    'volume_time_multip_stage1_Fill1',\n",
    "    'volume_time_multip_stage2_Fill1',\n",
    "    'volume_time_multip_stage3_Fill1'\n",
    "]\n",
    "\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077d4148-6c51-4270-b80b-b3fa36c9a643",
   "metadata": {},
   "source": [
    "### dam thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06fdcb9f-cfa1-45c8-a67b-f5481a1a3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 개 컬럼의 평균을 계산하여 새로운 컬럼 생성\n",
    "train_data['average_thickness_Dam'] = train_data[['THICKNESS 1 Collect Result_Dam', \n",
    "                                                  'THICKNESS 2 Collect Result_Dam', \n",
    "                                                  'THICKNESS 3 Collect Result_Dam']].mean(axis=1)\n",
    "\n",
    "test_data['average_thickness_Dam'] = test_data[['THICKNESS 1 Collect Result_Dam', \n",
    "                                                'THICKNESS 2 Collect Result_Dam', \n",
    "                                                'THICKNESS 3 Collect Result_Dam']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4299cc2-8038-4966-9e84-0d6019ce28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    'THICKNESS 1 Collect Result_Dam',\n",
    "    'THICKNESS 2 Collect Result_Dam',\n",
    "    'THICKNESS 3 Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea041a-ae68-4d6b-b483-59fff95e17f0",
   "metadata": {},
   "source": [
    "### autoclave pressure & unit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "624c6588-3952-4f8d-bb79-f55668dca505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 압력과 시간의 곱을 담은 새로운 컬럼 생성\n",
    "train_data['1st_pressure_time_AutoClave'] = train_data['1st Pressure Collect Result_AutoClave'] * train_data['1st Pressure 1st Pressure Unit Time_AutoClave']\n",
    "train_data['2nd_pressure_time_AutoClave'] = train_data['2nd Pressure Collect Result_AutoClave'] * train_data['2nd Pressure Unit Time_AutoClave']\n",
    "train_data['3rd_pressure_time_AutoClave'] = train_data['3rd Pressure Collect Result_AutoClave'] * train_data['3rd Pressure Unit Time_AutoClave']\n",
    "\n",
    "train_data['avg_pressure_time_AutoClave'] = (train_data['1st_pressure_time_AutoClave'] +\n",
    "                                             train_data['2nd_pressure_time_AutoClave'] +\n",
    "                                             train_data['3rd_pressure_time_AutoClave']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0596bc61-ddbd-4dfc-bc8e-1d4f44e654a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 압력과 시간의 곱을 담은 새로운 컬럼 생성\n",
    "test_data['1st_pressure_time_AutoClave'] = test_data['1st Pressure Collect Result_AutoClave'] * test_data['1st Pressure 1st Pressure Unit Time_AutoClave']\n",
    "test_data['2nd_pressure_time_AutoClave'] = test_data['2nd Pressure Collect Result_AutoClave'] * test_data['2nd Pressure Unit Time_AutoClave']\n",
    "test_data['3rd_pressure_time_AutoClave'] = test_data['3rd Pressure Collect Result_AutoClave'] * test_data['3rd Pressure Unit Time_AutoClave']\n",
    "\n",
    "test_data['avg_pressure_time_AutoClave'] = (test_data['1st_pressure_time_AutoClave'] +\n",
    "                                             test_data['2nd_pressure_time_AutoClave'] +\n",
    "                                             test_data['3rd_pressure_time_AutoClave']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc1d461b-0fee-4791-a52f-be21c5593626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    '1st Pressure Collect Result_AutoClave',\n",
    "    '1st Pressure 1st Pressure Unit Time_AutoClave',\n",
    "    '2nd Pressure Collect Result_AutoClave',\n",
    "    '2nd Pressure Unit Time_AutoClave',\n",
    "    '3rd Pressure Collect Result_AutoClave',\n",
    "    '3rd Pressure Unit Time_AutoClave',\n",
    "\n",
    "    '1st_pressure_time_AutoClave',\n",
    "    '2nd_pressure_time_AutoClave',\n",
    "    '3rd_pressure_time_AutoClave'\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9218268-af06-4611-9136-7d86db384933",
   "metadata": {},
   "source": [
    "### total tact time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bedf09e6-179c-40a2-89b4-d0a10410e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_tact_time\n",
    "train_data['total_tact_time'] = (train_data['Machine Tact time Collect Result_Dam'] + \n",
    "                                 train_data['Machine Tact time Collect Result_Fill1'] +\n",
    "                                 train_data['Machine Tact time Collect Result_Fill2'] +\n",
    "                                 train_data['Chamber Temp. Unit Time_AutoClave'])\n",
    "\n",
    "# total_tact_time\n",
    "test_data['total_tact_time'] = (test_data['Machine Tact time Collect Result_Dam'] + \n",
    "                                 test_data['Machine Tact time Collect Result_Fill1'] +\n",
    "                                 test_data['Machine Tact time Collect Result_Fill2'] +\n",
    "                                 test_data['Chamber Temp. Unit Time_AutoClave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e13e085d-fad6-4400-992e-396bb68c58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    'Machine Tact time Collect Result_Dam',\n",
    "    'Machine Tact time Collect Result_Fill1',\n",
    "    'Machine Tact time Collect Result_Fill2',\n",
    "    'Chamber Temp. Unit Time_AutoClave',\n",
    "    'Chamber Temp. Judge Value_AutoClave',\n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave',\n",
    "    'GMES_ORIGIN_INSP_JUDGE_CODE Judge Value_AutoClave'\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca67b6-e704-45cf-ad76-941f43ccbf7c",
   "metadata": {},
   "source": [
    "### 기타 변수 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "393304a1-ddd4-4165-bed6-ebae6c2f3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제할 컬럼 리스트\n",
    "columns_to_drop = [\n",
    "    'PalletID Collect Result_Dam',\n",
    "    'Production Qty Collect Result_Dam',\n",
    "    'WorkMode Collect Result_Dam',\n",
    "    'PalletID Collect Result_Fill1',\n",
    "    'Production Qty Collect Result_Fill1',\n",
    "    'WorkMode Collect Result_Fill1',\n",
    "    'PalletID Collect Result_Fill2',\n",
    "    'Production Qty Collect Result_Fill2',\n",
    "    'WorkMode Collect Result_Fill2'\n",
    "]\n",
    "\n",
    "# 지정한 컬럼 삭제\n",
    "train_data.drop(columns=columns_to_drop, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1eb68-8f26-432d-afa9-062f06eb8ddd",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ca35b6-7042-4f88-95e1-439ca53e0ac3",
   "metadata": {},
   "source": [
    "### workorder_receip & model_receip 가중치 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47d7415e-a282-4ac8-b2dc-0e719a5be6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 범주별 abnormal 비율 계산\n",
    "abnormal_counts = train_data[train_data['target'] == 'AbNormal'].groupby('workorder_receip').size()\n",
    "total_counts = train_data.groupby('workorder_receip').size()\n",
    "abnormal_ratio = abnormal_counts / total_counts\n",
    "\n",
    "# 가중치 적용하여 새로운 컬럼 생성\n",
    "train_data['workorder_receip_weighted'] = train_data['workorder_receip'].map(abnormal_ratio).fillna(0)\n",
    "test_data['workorder_receip_weighted'] = test_data['workorder_receip'].map(abnormal_ratio).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f7f5ba-e03d-4531-b763-69cce32f1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 범주별 abnormal 비율 계산\n",
    "abnormal_counts = train_data[train_data['target'] == 'AbNormal'].groupby('model_receip').size()\n",
    "total_counts = train_data.groupby('model_receip').size()\n",
    "abnormal_ratio = abnormal_counts / total_counts\n",
    "\n",
    "# 가중치 적용하여 새로운 컬럼 생성\n",
    "train_data['model_receip_weighted'] = train_data['model_receip'].map(abnormal_ratio).fillna(0)\n",
    "test_data['model_receip_weighted'] = test_data['model_receip'].map(abnormal_ratio).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f29d431-b6ea-4162-941f-a3e6a84f6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'workorder_receip'와 'model_receip' 열 삭제\n",
    "train_data = train_data.drop(columns=['workorder_receip', 'model_receip'])\n",
    "test_data = test_data.drop(columns=['workorder_receip', 'model_receip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025686d-d523-4fe3-bdc9-f8523e1c57d0",
   "metadata": {},
   "source": [
    "### 컬럼 확인 및 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc96eac2-c92a-4350-869e-f03b89c8dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 오류나서 직접 레이블 인코딩\n",
    "train_data['cure_end_position_XZΘ_Dam'] = train_data['cure_end_position_XZΘ_Dam'].replace({'240.0,2.5,-90': 0, '1000.0,12.5,90': 1})\n",
    "test_data['cure_end_position_XZΘ_Dam'] = test_data['cure_end_position_XZΘ_Dam'].replace({'240.0,2.5,-90': 0, '1000.0,12.5,90': 1})\n",
    "\n",
    "train_data['cure_start_position_XΘ_Dam'] = train_data['cure_start_position_XΘ_Dam'].replace({'1030,-90': 0, '280,90': 1})\n",
    "test_data['cure_start_position_XΘ_Dam'] = test_data['cure_start_position_XΘ_Dam'].replace({'1030,-90': 0, '280,90': 1})\n",
    "\n",
    "train_data['cure_end_position_XZ_Fill2'] = train_data['cure_end_position_XZ_Fill2'].replace({'240,33': 0, '240,32': 1, '1020,33': 2, '240,22': 3})\n",
    "test_data['cure_end_position_XZ_Fill2'] = test_data['cure_end_position_XZ_Fill2'].replace({'240,33': 0, '240,32': 1, '1020,33': 2, '240,22': 3})\n",
    "\n",
    "train_data['cure_start_position_XZ_Fill2'] = train_data['cure_start_position_XZ_Fill2'].replace({'1020,33': 0, '1020,32': 1, '1020,22': 2, '1020,23': 3, '240,33': 4})\n",
    "test_data['cure_start_position_XZ_Fill2'] = test_data['cure_start_position_XZ_Fill2'].replace({'1020,33': 0, '1020,32': 1, '1020,22': 2, '1020,23': 3, '240,33': 4})\n",
    "\n",
    "train_data['total_line_distance_speed_Dam'] = train_data['total_line_distance_speed_Dam'].replace({'diff': 0, 9000.0: 1, 6500.0: 2, 4000.0: 3})\n",
    "test_data['total_line_distance_speed_Dam'] = test_data['total_line_distance_speed_Dam'].replace({'diff': 0, 9000.0: 1, 6500.0: 2, 4000.0: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c895190-b235-47ba-ad92-cd061facf005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40506 entries, 0 to 40505\n",
      "Data columns (total 35 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   CURE SPEED Collect Result_Dam                   40506 non-null  int64  \n",
      " 1   DISCHARGED SPEED OF RESIN Collect Result_Dam    40506 non-null  int64  \n",
      " 2   Head Clean Position Z Collect Result_Dam        40506 non-null  float64\n",
      " 3   Head Purge Position Z Collect Result_Dam        40506 non-null  float64\n",
      " 4   Head Zero Position Y Collect Result_Dam         40506 non-null  float64\n",
      " 5   Chamber Temp. Collect Result_AutoClave          40506 non-null  int64  \n",
      " 6   DISCHARGED SPEED OF RESIN Collect Result_Fill1  40506 non-null  float64\n",
      " 7   Head Purge Position Z Collect Result_Fill1      40506 non-null  float64\n",
      " 8   CURE SPEED Collect Result_Fill2                 40506 non-null  int64  \n",
      " 9   CURE STANDBY POSITION Z Collect Result_Fill2    40506 non-null  int64  \n",
      " 10  Head Purge Position Z Collect Result_Fill2      40506 non-null  float64\n",
      " 11  target                                          40506 non-null  object \n",
      " 12  head_normal_vector_stage1_Dam                   40506 non-null  float64\n",
      " 13  head_normal_vector_stage2_Dam                   40506 non-null  float64\n",
      " 14  head_normal_vector_stage3_Dam                   40506 non-null  float64\n",
      " 15  head_normal_vector_stage1_Fill1                 40506 non-null  float64\n",
      " 16  head_normal_vector_stage2_Fill1                 40506 non-null  float64\n",
      " 17  head_normal_vector_stage3_Fill1                 40506 non-null  float64\n",
      " 18  head_normal_vector_stage1_Fill2                 40506 non-null  float64\n",
      " 19  head_normal_vector_stage2_Fill2                 40506 non-null  float64\n",
      " 20  head_normal_vector_stage3_Fill2                 40506 non-null  float64\n",
      " 21  cure_end_position_XZΘ_Dam                       40506 non-null  int64  \n",
      " 22  cure_start_position_XΘ_Dam                      40506 non-null  int64  \n",
      " 23  cure_end_position_XZ_Fill2                      40506 non-null  int64  \n",
      " 24  cure_start_position_XZ_Fill2                    40506 non-null  int64  \n",
      " 25  Equipment_same_num                              40506 non-null  int64  \n",
      " 26  total_circle_distance_speed_Dam                 40506 non-null  float64\n",
      " 27  total_line_distance_speed_Dam                   40506 non-null  float64\n",
      " 28  volume_time_multip_avg_Dam                      40506 non-null  float64\n",
      " 29  volume_time_multip_avg_Fill1                    40506 non-null  float64\n",
      " 30  average_thickness_Dam                           40506 non-null  float64\n",
      " 31  avg_pressure_time_AutoClave                     40506 non-null  float64\n",
      " 32  total_tact_time                                 40506 non-null  float64\n",
      " 33  workorder_receip_weighted                       40506 non-null  float64\n",
      " 34  model_receip_weighted                           40506 non-null  float64\n",
      "dtypes: float64(24), int64(10), object(1)\n",
      "memory usage: 10.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# info 잘리지 않게 출력\n",
    "train_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac43d9-0627-49d3-a444-44708baaa17b",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52d0ab56-1af4-4402-967b-ad11bb2531ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타깃값 분리\n",
    "y_train = train_data['target']\n",
    "x_train = train_data.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfa71b9b-a0d7-4239-8905-7a111752f4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={&#x27;AbNormal&#x27;: 5, &#x27;Normal&#x27;: 1},\n",
       "                       n_estimators=900, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={&#x27;AbNormal&#x27;: 5, &#x27;Normal&#x27;: 1},\n",
       "                       n_estimators=900, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={'AbNormal': 5, 'Normal': 1},\n",
       "                       n_estimators=900, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스의 비율에 따라 가중치 설정\n",
    "class_weights = {'Normal': 1, 'AbNormal': 5} \n",
    "\n",
    "# 랜덤 포레스트 모델 생성 및 학습\n",
    "rf = RandomForestClassifier(n_estimators=900, class_weight=class_weights, random_state=42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f0694b1-0a27-435c-9f2e-5edad56d2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Set ID'와 'target' 컬럼 분리\n",
    "set_id = test_data['Set ID']  \n",
    "target = test_data['target']   \n",
    "\n",
    "x_test = test_data.drop(columns=['Set ID', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae6c3105-8e41-49ca-890b-1e181a10917a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Normal', 'Normal', ..., 'Normal', 'Normal', 'Normal'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = rf.predict(x_test)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fec9b3a2-8347-427c-8110-ebfe10b577cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b9ef784-dbea-40bb-ba03-da4566ae07c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsend files ['code.ipynb', 'submission.csv'] for grade...\\ndone!\\n\\nScore: None\\nDuration: 1.538 seconds\\n=== Message ===\\n작성하신 답안 제출이 완료되었습니다.\\nPublic Score : 0.14593698175787728\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "send files ['code.ipynb', 'submission.csv'] for grade...\n",
    "done!\n",
    "\n",
    "Score: None\n",
    "Duration: 1.538 seconds\n",
    "=== Message ===\n",
    "작성하신 답안 제출이 완료되었습니다.\n",
    "Public Score : 0.14593698175787728\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48d1692c-4768-44d1-9b6d-80adc6f1f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"0813_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f31af1-d506-420e-b76b-396734465489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
