{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5468dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./final_data/final_train_data_ver2.csv\")\n",
    "test_data = pd.read_csv(\"./final_data/final_test_data_ver2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84efc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result_encoded',\n",
    "    'WorkMode Collect Result',\n",
    "    'Receip_n_suffix_3',\n",
    "    'time_gap_All'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be6bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab42a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e7e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e81578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2cfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ea40b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 44\n",
      "train_data_dam DataFrame의 칼럼 수: 25\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 16\n",
      "train_data_fill2 DataFrame의 칼럼 수: 16\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 45\n",
      "test_data_dam DataFrame의 칼럼 수: 26\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 17\n",
      "test_data_fill2 DataFrame의 칼럼 수: 17\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1f651b-d56f-4b1b-90cc-12270e83463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-28 15:18:45,300] A new study created in memory with name: no-name-9e030c3b-64b4-4ef8-99df-4ca3211583f1\n",
      "[I 2024-09-28 15:19:00,841] Trial 0 finished with value: 0.2218700475435816 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.2218700475435816.\n",
      "[I 2024-09-28 15:21:54,936] Trial 1 finished with value: 0.24781849912739967 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 1 with value: 0.24781849912739967.\n",
      "[I 2024-09-28 15:22:49,136] Trial 2 finished with value: 0.24716553287981863 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 1 with value: 0.24781849912739967.\n",
      "[I 2024-09-28 15:23:52,797] Trial 3 finished with value: 0.20735785953177258 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 1 with value: 0.24781849912739967.\n",
      "[I 2024-09-28 15:24:49,043] Trial 4 finished with value: 0.21395348837209305 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 1 with value: 0.24781849912739967.\n",
      "[I 2024-09-28 15:25:08,035] Trial 5 finished with value: 0.2464454976303318 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 1 with value: 0.24781849912739967.\n",
      "[I 2024-09-28 15:27:56,048] Trial 6 finished with value: 0.25215889464594127 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:29:46,084] Trial 7 finished with value: 0.2410015649452269 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:31:19,105] Trial 8 finished with value: 0.24625623960066556 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:31:31,071] Trial 9 finished with value: 0.22801302931596087 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:35:29,041] Trial 10 finished with value: 0.24620573355817876 and parameters: {'n_estimators': 2803, 'num_leaves': 1595, 'max_depth': 104, 'learning_rate': 0.06930702009789055, 'min_child_samples': 12}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:39:54,158] Trial 11 finished with value: 0.2437275985663082 and parameters: {'n_estimators': 2285, 'num_leaves': 2985, 'max_depth': 298, 'learning_rate': 0.03795714279469744, 'min_child_samples': 7}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:42:57,901] Trial 12 finished with value: 0.24784853700516352 and parameters: {'n_estimators': 2337, 'num_leaves': 2881, 'max_depth': 126, 'learning_rate': 0.0583582625613716, 'min_child_samples': 35}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:45:12,701] Trial 13 finished with value: 0.2116564417177914 and parameters: {'n_estimators': 2950, 'num_leaves': 1840, 'max_depth': 118, 'learning_rate': 0.0972683392531865, 'min_child_samples': 209}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:46:36,908] Trial 14 finished with value: 0.2306569343065693 and parameters: {'n_estimators': 2623, 'num_leaves': 1325, 'max_depth': 13, 'learning_rate': 0.06931753196580968, 'min_child_samples': 173}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:48:43,825] Trial 15 finished with value: 0.24469820554649263 and parameters: {'n_estimators': 2027, 'num_leaves': 2705, 'max_depth': 141, 'learning_rate': 0.025889035557271938, 'min_child_samples': 45}. Best is trial 6 with value: 0.25215889464594127.\n",
      "[I 2024-09-28 15:51:46,969] Trial 16 finished with value: 0.25728987993138935 and parameters: {'n_estimators': 2600, 'num_leaves': 1927, 'max_depth': 81, 'learning_rate': 0.061462700617761164, 'min_child_samples': 50}. Best is trial 16 with value: 0.25728987993138935.\n",
      "[I 2024-09-28 15:53:53,270] Trial 17 finished with value: 0.22222222222222218 and parameters: {'n_estimators': 2649, 'num_leaves': 1946, 'max_depth': 78, 'learning_rate': 0.0780425312640976, 'min_child_samples': 158}. Best is trial 16 with value: 0.25728987993138935.\n",
      "[I 2024-09-28 15:55:03,177] Trial 18 finished with value: 0.22385861561119294 and parameters: {'n_estimators': 1932, 'num_leaves': 1545, 'max_depth': 15, 'learning_rate': 0.08241913967243289, 'min_child_samples': 109}. Best is trial 16 with value: 0.25728987993138935.\n",
      "[I 2024-09-28 15:56:39,716] Trial 19 finished with value: 0.22822822822822825 and parameters: {'n_estimators': 3000, 'num_leaves': 1072, 'max_depth': 83, 'learning_rate': 0.03308984013324817, 'min_child_samples': 300}. Best is trial 16 with value: 0.25728987993138935.\n",
      "[I 2024-09-28 15:59:40,233] Trial 20 finished with value: 0.2538593481989708 and parameters: {'n_estimators': 2525, 'num_leaves': 2057, 'max_depth': 42, 'learning_rate': 0.06491287522574142, 'min_child_samples': 46}. Best is trial 16 with value: 0.25728987993138935.\n",
      "[I 2024-09-28 16:02:44,970] Trial 21 finished with value: 0.26279863481228666 and parameters: {'n_estimators': 2556, 'num_leaves': 1969, 'max_depth': 43, 'learning_rate': 0.06823441507850171, 'min_child_samples': 48}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:05:05,541] Trial 22 finished with value: 0.21359223300970873 and parameters: {'n_estimators': 2567, 'num_leaves': 2107, 'max_depth': 39, 'learning_rate': 0.04907466084347349, 'min_child_samples': 91}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:08:17,845] Trial 23 finished with value: 0.24707846410684473 and parameters: {'n_estimators': 2752, 'num_leaves': 1618, 'max_depth': 36, 'learning_rate': 0.07316924926291651, 'min_child_samples': 53}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:11:40,537] Trial 24 finished with value: 0.24913494809688577 and parameters: {'n_estimators': 2493, 'num_leaves': 2597, 'max_depth': 87, 'learning_rate': 0.057738471538435025, 'min_child_samples': 31}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:13:32,156] Trial 25 finished with value: 0.22257551669316375 and parameters: {'n_estimators': 2040, 'num_leaves': 2060, 'max_depth': 61, 'learning_rate': 0.09023825427930035, 'min_child_samples': 133}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:16:39,389] Trial 26 finished with value: 0.25666666666666665 and parameters: {'n_estimators': 2875, 'num_leaves': 1696, 'max_depth': 33, 'learning_rate': 0.05449609695775623, 'min_child_samples': 67}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:18:38,460] Trial 27 finished with value: 0.25000000000000006 and parameters: {'n_estimators': 2823, 'num_leaves': 1697, 'max_depth': 10, 'learning_rate': 0.04414319102031948, 'min_child_samples': 7}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:21:41,444] Trial 28 finished with value: 0.24703891708967854 and parameters: {'n_estimators': 2850, 'num_leaves': 1443, 'max_depth': 96, 'learning_rate': 0.05492264306237853, 'min_child_samples': 70}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:22:06,190] Trial 29 finished with value: 0.22327044025157233 and parameters: {'n_estimators': 835, 'num_leaves': 1099, 'max_depth': 59, 'learning_rate': 0.06344818487590766, 'min_child_samples': 211}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:23:52,759] Trial 30 finished with value: 0.213855421686747 and parameters: {'n_estimators': 2666, 'num_leaves': 2236, 'max_depth': 33, 'learning_rate': 0.07505858867841714, 'min_child_samples': 247}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:26:45,790] Trial 31 finished with value: 0.24827586206896554 and parameters: {'n_estimators': 2433, 'num_leaves': 1960, 'max_depth': 71, 'learning_rate': 0.06429700450307954, 'min_child_samples': 57}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:29:28,994] Trial 32 finished with value: 0.24168126094570927 and parameters: {'n_estimators': 2140, 'num_leaves': 1788, 'max_depth': 32, 'learning_rate': 0.05906738428531599, 'min_child_samples': 27}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:32:06,736] Trial 33 finished with value: 0.2207130730050934 and parameters: {'n_estimators': 2526, 'num_leaves': 2002, 'max_depth': 46, 'learning_rate': 0.08489499435730849, 'min_child_samples': 93}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:34:18,822] Trial 34 finished with value: 0.2452504317789292 and parameters: {'n_estimators': 1787, 'num_leaves': 2219, 'max_depth': 27, 'learning_rate': 0.06929668558697367, 'min_child_samples': 28}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:36:57,080] Trial 35 finished with value: 0.21603927986906707 and parameters: {'n_estimators': 2885, 'num_leaves': 1442, 'max_depth': 53, 'learning_rate': 0.05129662049235512, 'min_child_samples': 111}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:39:37,160] Trial 36 finished with value: 0.2108731466227348 and parameters: {'n_estimators': 2702, 'num_leaves': 2366, 'max_depth': 154, 'learning_rate': 0.047301376536503945, 'min_child_samples': 90}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:41:08,179] Trial 37 finished with value: 0.22458270106221545 and parameters: {'n_estimators': 2132, 'num_leaves': 1746, 'max_depth': 109, 'learning_rate': 0.03847388162779018, 'min_child_samples': 130}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:42:22,540] Trial 38 finished with value: 0.2441471571906355 and parameters: {'n_estimators': 1211, 'num_leaves': 2618, 'max_depth': 73, 'learning_rate': 0.054863646775776855, 'min_child_samples': 45}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:44:50,996] Trial 39 finished with value: 0.25 and parameters: {'n_estimators': 2371, 'num_leaves': 2112, 'max_depth': 51, 'learning_rate': 0.06664641957897673, 'min_child_samples': 70}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:47:07,672] Trial 40 finished with value: 0.2421052631578947 and parameters: {'n_estimators': 1801, 'num_leaves': 936, 'max_depth': 203, 'learning_rate': 0.06108540494239842, 'min_child_samples': 19}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:49:50,734] Trial 41 finished with value: 0.252991452991453 and parameters: {'n_estimators': 2439, 'num_leaves': 1871, 'max_depth': 132, 'learning_rate': 0.07304865776632502, 'min_child_samples': 60}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:52:41,896] Trial 42 finished with value: 0.24915824915824916 and parameters: {'n_estimators': 2477, 'num_leaves': 1903, 'max_depth': 134, 'learning_rate': 0.07616086894285844, 'min_child_samples': 61}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:55:02,786] Trial 43 finished with value: 0.24958402662229617 and parameters: {'n_estimators': 2264, 'num_leaves': 1783, 'max_depth': 92, 'learning_rate': 0.07155102645273992, 'min_child_samples': 86}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 16:57:55,245] Trial 44 finished with value: 0.24126984126984127 and parameters: {'n_estimators': 2749, 'num_leaves': 1646, 'max_depth': 22, 'learning_rate': 0.008911630474763607, 'min_child_samples': 43}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:00:46,784] Trial 45 finished with value: 0.24707846410684473 and parameters: {'n_estimators': 2575, 'num_leaves': 1476, 'max_depth': 157, 'learning_rate': 0.08392765888641174, 'min_child_samples': 81}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:04:19,512] Trial 46 finished with value: 0.24790619765494137 and parameters: {'n_estimators': 2921, 'num_leaves': 2320, 'max_depth': 112, 'learning_rate': 0.06373994822659287, 'min_child_samples': 60}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:06:28,149] Trial 47 finished with value: 0.21970920840064617 and parameters: {'n_estimators': 2408, 'num_leaves': 2197, 'max_depth': 220, 'learning_rate': 0.0530695695329482, 'min_child_samples': 103}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:08:52,158] Trial 48 finished with value: 0.24424778761061947 and parameters: {'n_estimators': 1471, 'num_leaves': 2478, 'max_depth': 45, 'learning_rate': 0.06789796811146913, 'min_child_samples': 18}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:11:48,825] Trial 49 finished with value: 0.24738675958188155 and parameters: {'n_estimators': 2184, 'num_leaves': 2028, 'max_depth': 67, 'learning_rate': 0.0597089587960056, 'min_child_samples': 41}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:14:55,115] Trial 50 finished with value: 0.21999999999999997 and parameters: {'n_estimators': 3000, 'num_leaves': 1867, 'max_depth': 101, 'learning_rate': 0.08829986678716122, 'min_child_samples': 116}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:17:42,378] Trial 51 finished with value: 0.25170068027210885 and parameters: {'n_estimators': 2298, 'num_leaves': 1868, 'max_depth': 153, 'learning_rate': 0.07879780361734676, 'min_child_samples': 54}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:20:43,643] Trial 52 finished with value: 0.25084745762711863 and parameters: {'n_estimators': 2628, 'num_leaves': 1701, 'max_depth': 127, 'learning_rate': 0.07246716714504992, 'min_child_samples': 70}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:24:40,955] Trial 53 finished with value: 0.24573378839590446 and parameters: {'n_estimators': 2759, 'num_leaves': 1304, 'max_depth': 168, 'learning_rate': 0.066180330633556, 'min_child_samples': 31}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:26:53,874] Trial 54 finished with value: 0.2208398133748056 and parameters: {'n_estimators': 2544, 'num_leaves': 2156, 'max_depth': 140, 'learning_rate': 0.05680489334732819, 'min_child_samples': 147}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:29:39,121] Trial 55 finished with value: 0.24573378839590446 and parameters: {'n_estimators': 2377, 'num_leaves': 1539, 'max_depth': 83, 'learning_rate': 0.042341603079204565, 'min_child_samples': 49}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:31:38,925] Trial 56 finished with value: 0.24625623960066556 and parameters: {'n_estimators': 2050, 'num_leaves': 1957, 'max_depth': 119, 'learning_rate': 0.06100651564673787, 'min_child_samples': 79}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:33:48,373] Trial 57 finished with value: 0.2225609756097561 and parameters: {'n_estimators': 2828, 'num_leaves': 2079, 'max_depth': 294, 'learning_rate': 0.04731264601877837, 'min_child_samples': 189}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:37:31,369] Trial 58 finished with value: 0.24999999999999997 and parameters: {'n_estimators': 2621, 'num_leaves': 1810, 'max_depth': 20, 'learning_rate': 0.07190880650042303, 'min_child_samples': 6}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:40:08,326] Trial 59 finished with value: 0.24699828473413382 and parameters: {'n_estimators': 2241, 'num_leaves': 1613, 'max_depth': 61, 'learning_rate': 0.06481384209914184, 'min_child_samples': 63}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:43:58,312] Trial 60 finished with value: 0.24503311258278146 and parameters: {'n_estimators': 2474, 'num_leaves': 2444, 'max_depth': 44, 'learning_rate': 0.09559406588161477, 'min_child_samples': 17}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:46:43,756] Trial 61 finished with value: 0.25 and parameters: {'n_estimators': 2293, 'num_leaves': 1946, 'max_depth': 153, 'learning_rate': 0.08009557461906297, 'min_child_samples': 52}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:49:32,455] Trial 62 finished with value: 0.24657534246575344 and parameters: {'n_estimators': 1939, 'num_leaves': 1848, 'max_depth': 183, 'learning_rate': 0.0783882157970135, 'min_child_samples': 37}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:52:27,132] Trial 63 finished with value: 0.2483221476510067 and parameters: {'n_estimators': 2696, 'num_leaves': 1893, 'max_depth': 126, 'learning_rate': 0.07509646639236296, 'min_child_samples': 74}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:54:37,562] Trial 64 finished with value: 0.2203947368421053 and parameters: {'n_estimators': 2351, 'num_leaves': 1686, 'max_depth': 167, 'learning_rate': 0.06895879446721188, 'min_child_samples': 99}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 17:57:33,527] Trial 65 finished with value: 0.25042881646655235 and parameters: {'n_estimators': 2555, 'num_leaves': 2059, 'max_depth': 146, 'learning_rate': 0.062327175589058155, 'min_child_samples': 54}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:00:58,336] Trial 66 finished with value: 0.2402707275803723 and parameters: {'n_estimators': 2428, 'num_leaves': 1751, 'max_depth': 77, 'learning_rate': 0.0802933234420192, 'min_child_samples': 26}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:04:16,278] Trial 67 finished with value: 0.25 and parameters: {'n_estimators': 2786, 'num_leaves': 1542, 'max_depth': 179, 'learning_rate': 0.05621121904242254, 'min_child_samples': 65}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:07:27,431] Trial 68 finished with value: 0.25817555938037867 and parameters: {'n_estimators': 2324, 'num_leaves': 2274, 'max_depth': 103, 'learning_rate': 0.07049065996594572, 'min_child_samples': 36}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:11:29,151] Trial 69 finished with value: 0.2538593481989708 and parameters: {'n_estimators': 2901, 'num_leaves': 2267, 'max_depth': 97, 'learning_rate': 0.05284973974949006, 'min_child_samples': 42}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:15:48,443] Trial 70 finished with value: 0.24870466321243523 and parameters: {'n_estimators': 2898, 'num_leaves': 2304, 'max_depth': 96, 'learning_rate': 0.05227548457337837, 'min_child_samples': 36}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:18:18,845] Trial 71 finished with value: 0.24424778761061947 and parameters: {'n_estimators': 1632, 'num_leaves': 2528, 'max_depth': 109, 'learning_rate': 0.058359045681403085, 'min_child_samples': 22}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:21:41,548] Trial 72 finished with value: 0.24356775300171532 and parameters: {'n_estimators': 2719, 'num_leaves': 2251, 'max_depth': 88, 'learning_rate': 0.04999946351126911, 'min_child_samples': 45}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:25:06,936] Trial 73 finished with value: 0.24787775891341257 and parameters: {'n_estimators': 2626, 'num_leaves': 2152, 'max_depth': 103, 'learning_rate': 0.07031792856722935, 'min_child_samples': 35}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:29:01,924] Trial 74 finished with value: 0.23367697594501716 and parameters: {'n_estimators': 2481, 'num_leaves': 1982, 'max_depth': 53, 'learning_rate': 0.06675041175167191, 'min_child_samples': 12}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:29:46,641] Trial 75 finished with value: 0.2293577981651376 and parameters: {'n_estimators': 1322, 'num_leaves': 2388, 'max_depth': 130, 'learning_rate': 0.07481872382643827, 'min_child_samples': 258}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:32:36,886] Trial 76 finished with value: 0.2512396694214876 and parameters: {'n_estimators': 2934, 'num_leaves': 2838, 'max_depth': 35, 'learning_rate': 0.06243121037069009, 'min_child_samples': 85}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:36:00,567] Trial 77 finished with value: 0.25042881646655235 and parameters: {'n_estimators': 2835, 'num_leaves': 2178, 'max_depth': 118, 'learning_rate': 0.05480968265452804, 'min_child_samples': 46}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:38:36,428] Trial 78 finished with value: 0.24915824915824916 and parameters: {'n_estimators': 2587, 'num_leaves': 2027, 'max_depth': 71, 'learning_rate': 0.0363142454494613, 'min_child_samples': 60}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:39:04,928] Trial 79 finished with value: 0.2375 and parameters: {'n_estimators': 748, 'num_leaves': 2297, 'max_depth': 57, 'learning_rate': 0.045349417671582834, 'min_child_samples': 79}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:41:31,476] Trial 80 finished with value: 0.24798711755233496 and parameters: {'n_estimators': 2688, 'num_leaves': 2120, 'max_depth': 27, 'learning_rate': 0.06024781884375358, 'min_child_samples': 69}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:44:16,062] Trial 81 finished with value: 0.24742268041237117 and parameters: {'n_estimators': 2314, 'num_leaves': 1887, 'max_depth': 141, 'learning_rate': 0.08192554616346504, 'min_child_samples': 50}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:47:01,838] Trial 82 finished with value: 0.24315068493150685 and parameters: {'n_estimators': 2432, 'num_leaves': 1746, 'max_depth': 115, 'learning_rate': 0.0735120410726279, 'min_child_samples': 56}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:49:50,671] Trial 83 finished with value: 0.24489795918367344 and parameters: {'n_estimators': 2195, 'num_leaves': 1828, 'max_depth': 134, 'learning_rate': 0.08754692413814974, 'min_child_samples': 37}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:52:41,932] Trial 84 finished with value: 0.24305555555555558 and parameters: {'n_estimators': 2091, 'num_leaves': 1927, 'max_depth': 97, 'learning_rate': 0.07760723344816985, 'min_child_samples': 27}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:55:06,099] Trial 85 finished with value: 0.24440619621342513 and parameters: {'n_estimators': 1950, 'num_leaves': 2022, 'max_depth': 82, 'learning_rate': 0.06756486075429774, 'min_child_samples': 40}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 18:57:27,248] Trial 86 finished with value: 0.22296173044925124 and parameters: {'n_estimators': 2492, 'num_leaves': 1673, 'max_depth': 159, 'learning_rate': 0.065025168427896, 'min_child_samples': 96}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 19:00:02,611] Trial 87 finished with value: 0.2383419689119171 and parameters: {'n_estimators': 2370, 'num_leaves': 2085, 'max_depth': 41, 'learning_rate': 0.07104487240801163, 'min_child_samples': 56}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 19:03:00,936] Trial 88 finished with value: 0.24567474048442908 and parameters: {'n_estimators': 2223, 'num_leaves': 2239, 'max_depth': 124, 'learning_rate': 0.07659107367524158, 'min_child_samples': 3}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 19:05:29,687] Trial 89 finished with value: 0.25249169435215946 and parameters: {'n_estimators': 2523, 'num_leaves': 2344, 'max_depth': 105, 'learning_rate': 0.05407504508610914, 'min_child_samples': 75}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 19:08:36,116] Trial 90 finished with value: 0.2550335570469799 and parameters: {'n_estimators': 2874, 'num_leaves': 2491, 'max_depth': 107, 'learning_rate': 0.05191188928945305, 'min_child_samples': 74}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[I 2024-09-28 19:11:39,926] Trial 91 finished with value: 0.24790619765494137 and parameters: {'n_estimators': 2858, 'num_leaves': 2579, 'max_depth': 109, 'learning_rate': 0.053696772220272, 'min_child_samples': 73}. Best is trial 21 with value: 0.26279863481228666.\n",
      "[W 2024-09-28 19:13:12,614] Trial 92 failed with parameters: {'n_estimators': 2947, 'num_leaves': 2706, 'max_depth': 103, 'learning_rate': 0.049111121447048434, 'min_child_samples': 88} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_4824\\4045525815.py\", line 45, in <lambda>\n",
      "    study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_4824\\4045525815.py\", line 26, in objectiveLGBM_dart\n",
      "    model.fit(x_tr, y_tr)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1298, in fit\n",
      "    init_model=init_model,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 963, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\", line 4138, in update\n",
      "    ctypes.byref(is_finished),\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-28 19:13:12,669] Trial 92 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4824\\4045525815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4824\\4045525815.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4824\\4045525815.py\u001b[0m in \u001b[0;36mobjectiveLGBM_dart\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 양성 클래스 확률\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_proba\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 스레드홀드에 따른 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4136\u001b[0m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m                 )\n\u001b[0;32m   4140\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data['target'] = train_data['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(\"target\", axis=1),\n",
    "    train_data[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e8e2d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
