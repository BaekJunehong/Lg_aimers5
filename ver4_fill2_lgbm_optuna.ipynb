{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570f8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./final_data/train_data_ver4.csv\")\n",
    "test_data = pd.read_csv(\"./final_data/test_data_ver4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fcef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'PalletID_Collect_Result',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'Receip_No_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70793df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3b81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb5b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af8da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82ed5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 39\n",
      "train_data_dam DataFrame의 칼럼 수: 20\n",
      "train_data_autoclave DataFrame의 칼럼 수: 9\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 40\n",
      "test_data_dam DataFrame의 칼럼 수: 21\n",
      "test_data_autoclave DataFrame의 칼럼 수: 10\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "[I 2024-09-29 08:14:24,299] A new study created in memory with name: no-name-5953a8fd-58fa-4e56-b8a4-7d17ba2602c8\n",
      "[I 2024-09-29 08:14:46,642] Trial 0 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:17:33,475] Trial 1 finished with value: 0.19911504424778761 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:18:23,111] Trial 2 finished with value: 0.21733505821474772 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:19:22,818] Trial 3 finished with value: 0.2365988909426987 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:20:20,312] Trial 4 finished with value: 0.2267080745341615 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:20:38,419] Trial 5 finished with value: 0.23776223776223776 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:23:17,224] Trial 6 finished with value: 0.19887005649717515 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:24:52,849] Trial 7 finished with value: 0.22446043165467627 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:26:12,668] Trial 8 finished with value: 0.21090047393364933 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:26:22,626] Trial 9 finished with value: 0.2140221402214022 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:26:53,810] Trial 10 finished with value: 0.23127035830618894 and parameters: {'n_estimators': 996, 'num_leaves': 1534, 'max_depth': 104, 'learning_rate': 0.09731505694411961, 'min_child_samples': 211}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:27:04,065] Trial 11 finished with value: 0.1973929236499069 and parameters: {'n_estimators': 519, 'num_leaves': 1002, 'max_depth': 300, 'learning_rate': 0.040338453467110603, 'min_child_samples': 191}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:27:31,371] Trial 12 finished with value: 0.23971377459749552 and parameters: {'n_estimators': 924, 'num_leaves': 1852, 'max_depth': 276, 'learning_rate': 0.059047712126274104, 'min_child_samples': 184}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:29:30,909] Trial 13 finished with value: 0.22395833333333337 and parameters: {'n_estimators': 2922, 'num_leaves': 1932, 'max_depth': 120, 'learning_rate': 0.07222876152309926, 'min_child_samples': 194}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:29:54,352] Trial 14 finished with value: 0.22222222222222218 and parameters: {'n_estimators': 963, 'num_leaves': 1484, 'max_depth': 13, 'learning_rate': 0.06468044460156709, 'min_child_samples': 246}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-29 08:30:22,372] Trial 15 finished with value: 0.24581005586592178 and parameters: {'n_estimators': 1034, 'num_leaves': 2141, 'max_depth': 231, 'learning_rate': 0.025889035557271938, 'min_child_samples': 175}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:30:52,918] Trial 16 finished with value: 0.21892393320964748 and parameters: {'n_estimators': 1202, 'num_leaves': 2845, 'max_depth': 220, 'learning_rate': 0.026744213003533534, 'min_child_samples': 245}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:31:13,723] Trial 17 finished with value: 0.24489795918367346 and parameters: {'n_estimators': 828, 'num_leaves': 2161, 'max_depth': 130, 'learning_rate': 0.025827793874381135, 'min_child_samples': 166}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:32:16,881] Trial 18 finished with value: 0.23801065719360567 and parameters: {'n_estimators': 1827, 'num_leaves': 2602, 'max_depth': 155, 'learning_rate': 0.02637305339069682, 'min_child_samples': 163}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:33:18,297] Trial 19 finished with value: 0.24175824175824173 and parameters: {'n_estimators': 1864, 'num_leaves': 2084, 'max_depth': 222, 'learning_rate': 0.015830807137607594, 'min_child_samples': 152}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:34:52,286] Trial 20 finished with value: 0.20044052863436124 and parameters: {'n_estimators': 1211, 'num_leaves': 1540, 'max_depth': 143, 'learning_rate': 0.034351616318255146, 'min_child_samples': 3}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:35:11,715] Trial 21 finished with value: 0.21033210332103325 and parameters: {'n_estimators': 807, 'num_leaves': 2164, 'max_depth': 103, 'learning_rate': 0.03252333238220215, 'min_child_samples': 230}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:35:27,610] Trial 22 finished with value: 0.21184919210053862 and parameters: {'n_estimators': 757, 'num_leaves': 2613, 'max_depth': 64, 'learning_rate': 0.013812979575405261, 'min_child_samples': 275}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:35:46,409] Trial 23 finished with value: 0.23853211009174316 and parameters: {'n_estimators': 708, 'num_leaves': 1990, 'max_depth': 88, 'learning_rate': 0.0486413707021383, 'min_child_samples': 168}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:36:24,408] Trial 24 finished with value: 0.23591549295774647 and parameters: {'n_estimators': 1078, 'num_leaves': 2275, 'max_depth': 135, 'learning_rate': 0.03862725649777802, 'min_child_samples': 126}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:37:20,181] Trial 25 finished with value: 0.23529411764705888 and parameters: {'n_estimators': 1497, 'num_leaves': 2527, 'max_depth': 168, 'learning_rate': 0.07857374173756171, 'min_child_samples': 209}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:37:41,499] Trial 26 finished with value: 0.241635687732342 and parameters: {'n_estimators': 764, 'num_leaves': 1737, 'max_depth': 204, 'learning_rate': 0.024295421753719834, 'min_child_samples': 138}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:38:22,321] Trial 27 finished with value: 0.24381625441696111 and parameters: {'n_estimators': 1272, 'num_leaves': 1696, 'max_depth': 79, 'learning_rate': 0.05553112542786454, 'min_child_samples': 225}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:38:52,496] Trial 28 finished with value: 0.22185970636215335 and parameters: {'n_estimators': 1069, 'num_leaves': 2136, 'max_depth': 22, 'learning_rate': 0.003952506194687459, 'min_child_samples': 173}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:40:26,092] Trial 29 finished with value: 0.21939586645469 and parameters: {'n_estimators': 2701, 'num_leaves': 2655, 'max_depth': 207, 'learning_rate': 0.04618696128522181, 'min_child_samples': 257}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:41:34,917] Trial 30 finished with value: 0.22222222222222224 and parameters: {'n_estimators': 1662, 'num_leaves': 2931, 'max_depth': 151, 'learning_rate': 0.03273690408542686, 'min_child_samples': 98}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:42:17,477] Trial 31 finished with value: 0.23752151462994836 and parameters: {'n_estimators': 1330, 'num_leaves': 1672, 'max_depth': 91, 'learning_rate': 0.05952411254006535, 'min_child_samples': 222}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:42:42,942] Trial 32 finished with value: 0.23247232472324722 and parameters: {'n_estimators': 895, 'num_leaves': 1282, 'max_depth': 75, 'learning_rate': 0.05522636235542981, 'min_child_samples': 203}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:43:20,519] Trial 33 finished with value: 0.24041811846689898 and parameters: {'n_estimators': 1152, 'num_leaves': 2034, 'max_depth': 48, 'learning_rate': 0.06613740921247979, 'min_child_samples': 228}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:44:12,012] Trial 34 finished with value: 0.22009569377990432 and parameters: {'n_estimators': 1355, 'num_leaves': 2262, 'max_depth': 131, 'learning_rate': 0.05398330054070771, 'min_child_samples': 147}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 08:44:31,409] Trial 35 finished with value: 0.24686940966010737 and parameters: {'n_estimators': 702, 'num_leaves': 1297, 'max_depth': 111, 'learning_rate': 0.07270644607562118, 'min_child_samples': 181}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:44:51,461] Trial 36 finished with value: 0.23338735818476503 and parameters: {'n_estimators': 644, 'num_leaves': 986, 'max_depth': 105, 'learning_rate': 0.07614998741232676, 'min_child_samples': 110}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:45:17,843] Trial 37 finished with value: 0.23232323232323232 and parameters: {'n_estimators': 852, 'num_leaves': 1258, 'max_depth': 169, 'learning_rate': 0.08613768246488512, 'min_child_samples': 185}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:45:32,589] Trial 38 finished with value: 0.21973929236499068 and parameters: {'n_estimators': 639, 'num_leaves': 1045, 'max_depth': 121, 'learning_rate': 0.017587788321335757, 'min_child_samples': 140}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:45:47,853] Trial 39 finished with value: 0.2226148409893993 and parameters: {'n_estimators': 653, 'num_leaves': 2423, 'max_depth': 192, 'learning_rate': 0.00950525717043408, 'min_child_samples': 163}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:46:50,929] Trial 40 finished with value: 0.2235294117647059 and parameters: {'n_estimators': 1623, 'num_leaves': 2777, 'max_depth': 250, 'learning_rate': 0.06762787133773411, 'min_child_samples': 174}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:47:23,508] Trial 41 finished with value: 0.23698384201077197 and parameters: {'n_estimators': 1044, 'num_leaves': 1383, 'max_depth': 39, 'learning_rate': 0.060090633768634834, 'min_child_samples': 214}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:48:37,481] Trial 42 finished with value: 0.22903225806451616 and parameters: {'n_estimators': 2098, 'num_leaves': 1856, 'max_depth': 92, 'learning_rate': 0.04353863749284016, 'min_child_samples': 201}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:49:02,176] Trial 43 finished with value: 0.24593128390596747 and parameters: {'n_estimators': 866, 'num_leaves': 1758, 'max_depth': 75, 'learning_rate': 0.07123459608247246, 'min_child_samples': 242}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:49:26,907] Trial 44 finished with value: 0.24187725631768953 and parameters: {'n_estimators': 881, 'num_leaves': 2195, 'max_depth': 113, 'learning_rate': 0.07406272907187847, 'min_child_samples': 245}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:49:37,474] Trial 45 finished with value: 0.21811460258780033 and parameters: {'n_estimators': 517, 'num_leaves': 849, 'max_depth': 133, 'learning_rate': 0.08115044325732322, 'min_child_samples': 263}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:50:11,371] Trial 46 finished with value: 0.228099173553719 and parameters: {'n_estimators': 978, 'num_leaves': 1916, 'max_depth': 157, 'learning_rate': 0.08516834341163138, 'min_child_samples': 180}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:50:27,019] Trial 47 finished with value: 0.23443223443223443 and parameters: {'n_estimators': 629, 'num_leaves': 1603, 'max_depth': 64, 'learning_rate': 0.07126677830968893, 'min_child_samples': 196}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:50:53,196] Trial 48 finished with value: 0.22940226171243944 and parameters: {'n_estimators': 789, 'num_leaves': 2331, 'max_depth': 180, 'learning_rate': 0.0946366153960127, 'min_child_samples': 153}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:51:27,439] Trial 49 finished with value: 0.21631205673758866 and parameters: {'n_estimators': 1129, 'num_leaves': 1786, 'max_depth': 110, 'learning_rate': 0.07135917768946134, 'min_child_samples': 282}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:52:22,852] Trial 50 finished with value: 0.2268041237113402 and parameters: {'n_estimators': 1390, 'num_leaves': 1987, 'max_depth': 76, 'learning_rate': 0.06107177304243887, 'min_child_samples': 131}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:52:58,218] Trial 51 finished with value: 0.21897810218978103 and parameters: {'n_estimators': 1258, 'num_leaves': 1701, 'max_depth': 77, 'learning_rate': 0.05291214441433933, 'min_child_samples': 300}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:53:23,882] Trial 52 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 923, 'num_leaves': 1445, 'max_depth': 283, 'learning_rate': 0.06278828947581483, 'min_child_samples': 238}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:53:49,757] Trial 53 finished with value: 0.24637681159420288 and parameters: {'n_estimators': 902, 'num_leaves': 1436, 'max_depth': 299, 'learning_rate': 0.06839736886576359, 'min_child_samples': 243}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:54:06,427] Trial 54 finished with value: 0.21611721611721615 and parameters: {'n_estimators': 715, 'num_leaves': 1155, 'max_depth': 273, 'learning_rate': 0.06821201023532428, 'min_child_samples': 259}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:54:31,502] Trial 55 finished with value: 0.21150278293135438 and parameters: {'n_estimators': 987, 'num_leaves': 1402, 'max_depth': 250, 'learning_rate': 0.020282429781682782, 'min_child_samples': 216}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:54:53,352] Trial 56 finished with value: 0.2429906542056075 and parameters: {'n_estimators': 838, 'num_leaves': 1537, 'max_depth': 286, 'learning_rate': 0.029268102351274843, 'min_child_samples': 191}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:55:06,235] Trial 57 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 571, 'num_leaves': 1171, 'max_depth': 227, 'learning_rate': 0.08268911225513191, 'min_child_samples': 235}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:55:28,649] Trial 58 finished with value: 0.23652173913043478 and parameters: {'n_estimators': 750, 'num_leaves': 2104, 'max_depth': 298, 'learning_rate': 0.07620880754088573, 'min_child_samples': 159}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:56:12,223] Trial 59 finished with value: 0.23389830508474582 and parameters: {'n_estimators': 1149, 'num_leaves': 2509, 'max_depth': 262, 'learning_rate': 0.06917706173734534, 'min_child_samples': 205}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:57:34,033] Trial 60 finished with value: 0.20899470899470898 and parameters: {'n_estimators': 2005, 'num_leaves': 1348, 'max_depth': 147, 'learning_rate': 0.0910278348780102, 'min_child_samples': 183}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:58:01,063] Trial 61 finished with value: 0.24416517055655296 and parameters: {'n_estimators': 944, 'num_leaves': 1464, 'max_depth': 279, 'learning_rate': 0.06410215372205101, 'min_child_samples': 242}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:58:32,478] Trial 62 finished with value: 0.21708185053380782 and parameters: {'n_estimators': 1031, 'num_leaves': 1607, 'max_depth': 294, 'learning_rate': 0.07473145844672516, 'min_child_samples': 264}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:58:58,023] Trial 63 finished with value: 0.21978021978021975 and parameters: {'n_estimators': 919, 'num_leaves': 1786, 'max_depth': 274, 'learning_rate': 0.05740572685293721, 'min_child_samples': 248}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:59:18,551] Trial 64 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 807, 'num_leaves': 1328, 'max_depth': 263, 'learning_rate': 0.0632007797217737, 'min_child_samples': 220}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:59:34,735] Trial 65 finished with value: 0.21892393320964748 and parameters: {'n_estimators': 706, 'num_leaves': 2348, 'max_depth': 234, 'learning_rate': 0.06565746878221536, 'min_child_samples': 270}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 08:59:45,880] Trial 66 finished with value: 0.20599250936329588 and parameters: {'n_estimators': 570, 'num_leaves': 1098, 'max_depth': 128, 'learning_rate': 0.03592970469406636, 'min_child_samples': 248}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 09:00:16,978] Trial 67 finished with value: 0.2509090909090909 and parameters: {'n_estimators': 1087, 'num_leaves': 1482, 'max_depth': 95, 'learning_rate': 0.049934380062210154, 'min_child_samples': 237}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:00:47,910] Trial 68 finished with value: 0.2449725776965265 and parameters: {'n_estimators': 1092, 'num_leaves': 1611, 'max_depth': 101, 'learning_rate': 0.04698360506689388, 'min_child_samples': 235}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:02:07,233] Trial 69 finished with value: 0.21498371335504884 and parameters: {'n_estimators': 2463, 'num_leaves': 1657, 'max_depth': 95, 'learning_rate': 0.050747882191026404, 'min_child_samples': 292}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:03:04,722] Trial 70 finished with value: 0.22595419847328246 and parameters: {'n_estimators': 1437, 'num_leaves': 1600, 'max_depth': 100, 'learning_rate': 0.046695997727184614, 'min_child_samples': 118}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:03:35,904] Trial 71 finished with value: 0.2363636363636364 and parameters: {'n_estimators': 1109, 'num_leaves': 1455, 'max_depth': 85, 'learning_rate': 0.038979193412565644, 'min_child_samples': 232}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:04:09,083] Trial 72 finished with value: 0.2185185185185185 and parameters: {'n_estimators': 1214, 'num_leaves': 1510, 'max_depth': 111, 'learning_rate': 0.029815153338735842, 'min_child_samples': 255}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:04:33,747] Trial 73 finished with value: 0.20626151012891347 and parameters: {'n_estimators': 988, 'num_leaves': 1219, 'max_depth': 56, 'learning_rate': 0.024225949671046597, 'min_child_samples': 237}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:04:54,059] Trial 74 finished with value: 0.21441774491682067 and parameters: {'n_estimators': 847, 'num_leaves': 1899, 'max_depth': 119, 'learning_rate': 0.04316803713931301, 'min_child_samples': 282}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:05:25,939] Trial 75 finished with value: 0.21908127208480566 and parameters: {'n_estimators': 1075, 'num_leaves': 1298, 'max_depth': 138, 'learning_rate': 0.07782109341454735, 'min_child_samples': 270}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:06:17,517] Trial 76 finished with value: 0.2367066895368782 and parameters: {'n_estimators': 1566, 'num_leaves': 1434, 'max_depth': 67, 'learning_rate': 0.04756675914591748, 'min_child_samples': 212}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:06:45,097] Trial 77 finished with value: 0.2464285714285714 and parameters: {'n_estimators': 925, 'num_leaves': 1791, 'max_depth': 290, 'learning_rate': 0.06975914659681426, 'min_child_samples': 225}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:07:16,711] Trial 78 finished with value: 0.20522388059701493 and parameters: {'n_estimators': 1192, 'num_leaves': 2036, 'max_depth': 209, 'learning_rate': 0.013610046706865027, 'min_child_samples': 227}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:08:25,353] Trial 79 finished with value: 0.22451612903225807 and parameters: {'n_estimators': 1308, 'num_leaves': 1794, 'max_depth': 84, 'learning_rate': 0.03605361302215946, 'min_child_samples': 46}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:09:00,582] Trial 80 finished with value: 0.23467600700525396 and parameters: {'n_estimators': 1033, 'num_leaves': 2215, 'max_depth': 159, 'learning_rate': 0.056309684229049785, 'min_child_samples': 168}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:09:27,346] Trial 81 finished with value: 0.22182468694096602 and parameters: {'n_estimators': 925, 'num_leaves': 1614, 'max_depth': 292, 'learning_rate': 0.07295906148855524, 'min_child_samples': 253}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:09:44,538] Trial 82 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 695, 'num_leaves': 1497, 'max_depth': 286, 'learning_rate': 0.06975165022403743, 'min_child_samples': 240}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:10:10,457] Trial 83 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 874, 'num_leaves': 1565, 'max_depth': 279, 'learning_rate': 0.06397049848245562, 'min_child_samples': 219}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:10:40,454] Trial 84 finished with value: 0.23297491039426524 and parameters: {'n_estimators': 953, 'num_leaves': 1775, 'max_depth': 269, 'learning_rate': 0.058257058145861615, 'min_child_samples': 190}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:11:05,114] Trial 85 finished with value: 0.23550087873462217 and parameters: {'n_estimators': 804, 'num_leaves': 1852, 'max_depth': 247, 'learning_rate': 0.08046892942287634, 'min_child_samples': 197}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:11:20,348] Trial 86 finished with value: 0.23985239852398524 and parameters: {'n_estimators': 608, 'num_leaves': 1713, 'max_depth': 100, 'learning_rate': 0.06748809192972516, 'min_child_samples': 207}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:11:41,976] Trial 87 finished with value: 0.24131627056672758 and parameters: {'n_estimators': 754, 'num_leaves': 1957, 'max_depth': 120, 'learning_rate': 0.051424213514228684, 'min_child_samples': 178}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:12:12,322] Trial 88 finished with value: 0.24344569288389514 and parameters: {'n_estimators': 1021, 'num_leaves': 1374, 'max_depth': 299, 'learning_rate': 0.020256063922808296, 'min_child_samples': 145}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:12:47,370] Trial 89 finished with value: 0.23407917383820995 and parameters: {'n_estimators': 1091, 'num_leaves': 1225, 'max_depth': 71, 'learning_rate': 0.07061344551561131, 'min_child_samples': 226}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:13:08,779] Trial 90 finished with value: 0.2141623488773748 and parameters: {'n_estimators': 885, 'num_leaves': 1665, 'max_depth': 141, 'learning_rate': 0.006170232778669207, 'min_child_samples': 240}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:13:25,827] Trial 91 finished with value: 0.2449725776965265 and parameters: {'n_estimators': 670, 'num_leaves': 2133, 'max_depth': 127, 'learning_rate': 0.06231048661454314, 'min_child_samples': 232}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:13:42,646] Trial 92 finished with value: 0.22058823529411764 and parameters: {'n_estimators': 695, 'num_leaves': 2095, 'max_depth': 126, 'learning_rate': 0.06144815495071291, 'min_child_samples': 250}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:14:03,274] Trial 93 finished with value: 0.2449725776965265 and parameters: {'n_estimators': 781, 'num_leaves': 2160, 'max_depth': 114, 'learning_rate': 0.0653142288039266, 'min_child_samples': 232}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:14:26,422] Trial 94 finished with value: 0.24460431654676257 and parameters: {'n_estimators': 822, 'num_leaves': 2236, 'max_depth': 107, 'learning_rate': 0.07685012680471398, 'min_child_samples': 231}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:14:37,590] Trial 95 finished with value: 0.2402957486136784 and parameters: {'n_estimators': 524, 'num_leaves': 2140, 'max_depth': 96, 'learning_rate': 0.07343474409505363, 'min_child_samples': 223}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:15:00,101] Trial 96 finished with value: 0.2385964912280702 and parameters: {'n_estimators': 757, 'num_leaves': 2348, 'max_depth': 114, 'learning_rate': 0.06613267202044243, 'min_child_samples': 157}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:15:12,362] Trial 97 finished with value: 0.21441774491682067 and parameters: {'n_estimators': 583, 'num_leaves': 2038, 'max_depth': 89, 'learning_rate': 0.05923223060504424, 'min_child_samples': 260}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:15:28,084] Trial 98 finished with value: 0.241635687732342 and parameters: {'n_estimators': 644, 'num_leaves': 2174, 'max_depth': 125, 'learning_rate': 0.04493942053548401, 'min_child_samples': 168}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:15:45,074] Trial 99 finished with value: 0.24074074074074078 and parameters: {'n_estimators': 671, 'num_leaves': 2294, 'max_depth': 115, 'learning_rate': 0.053992893167074875, 'min_child_samples': 213}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:16:17,228] Trial 100 finished with value: 0.24829931972789115 and parameters: {'n_estimators': 867, 'num_leaves': 2444, 'max_depth': 133, 'learning_rate': 0.041419138254109526, 'min_child_samples': 91}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:16:48,701] Trial 101 finished with value: 0.2325581395348837 and parameters: {'n_estimators': 849, 'num_leaves': 2428, 'max_depth': 135, 'learning_rate': 0.04952273485672565, 'min_child_samples': 91}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:17:21,283] Trial 102 finished with value: 0.2305389221556886 and parameters: {'n_estimators': 761, 'num_leaves': 2674, 'max_depth': 161, 'learning_rate': 0.041319467819480454, 'min_child_samples': 50}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:17:50,989] Trial 103 finished with value: 0.24416517055655296 and parameters: {'n_estimators': 979, 'num_leaves': 1896, 'max_depth': 108, 'learning_rate': 0.06751469181069635, 'min_child_samples': 234}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:18:41,040] Trial 104 finished with value: 0.22824536376604848 and parameters: {'n_estimators': 893, 'num_leaves': 2510, 'max_depth': 146, 'learning_rate': 0.023251453435971056, 'min_child_samples': 28}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:19:20,119] Trial 105 finished with value: 0.24548736462093862 and parameters: {'n_estimators': 1170, 'num_leaves': 2412, 'max_depth': 82, 'learning_rate': 0.030632408634590106, 'min_child_samples': 137}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:20:02,846] Trial 106 finished with value: 0.23655913978494622 and parameters: {'n_estimators': 1248, 'num_leaves': 2398, 'max_depth': 82, 'learning_rate': 0.02934283130551411, 'min_child_samples': 137}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:20:48,592] Trial 107 finished with value: 0.23240589198036002 and parameters: {'n_estimators': 1172, 'num_leaves': 2573, 'max_depth': 54, 'learning_rate': 0.0330320034383048, 'min_child_samples': 90}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:23:04,027] Trial 108 finished with value: 0.22099447513812157 and parameters: {'n_estimators': 2975, 'num_leaves': 2996, 'max_depth': 88, 'learning_rate': 0.026955441104432203, 'min_child_samples': 106}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:23:36,335] Trial 109 finished with value: 0.22467771639042355 and parameters: {'n_estimators': 1125, 'num_leaves': 2478, 'max_depth': 42, 'learning_rate': 0.037569492247431016, 'min_child_samples': 244}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:24:25,982] Trial 110 finished with value: 0.21161290322580645 and parameters: {'n_estimators': 1025, 'num_leaves': 1991, 'max_depth': 101, 'learning_rate': 0.07523370218007057, 'min_child_samples': 66}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:24:50,957] Trial 111 finished with value: 0.2 and parameters: {'n_estimators': 950, 'num_leaves': 2092, 'max_depth': 132, 'learning_rate': 0.016606640596178127, 'min_child_samples': 188}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:25:15,160] Trial 112 finished with value: 0.24444444444444444 and parameters: {'n_estimators': 811, 'num_leaves': 2293, 'max_depth': 118, 'learning_rate': 0.02645807159824035, 'min_child_samples': 119}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:25:33,943] Trial 113 finished with value: 0.24581005586592178 and parameters: {'n_estimators': 724, 'num_leaves': 2668, 'max_depth': 151, 'learning_rate': 0.031533411700360794, 'min_child_samples': 175}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:25:50,070] Trial 114 finished with value: 0.2152133580705009 and parameters: {'n_estimators': 718, 'num_leaves': 2777, 'max_depth': 167, 'learning_rate': 0.040738027116704774, 'min_child_samples': 267}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:26:26,420] Trial 115 finished with value: 0.22984562607204115 and parameters: {'n_estimators': 1071, 'num_leaves': 2640, 'max_depth': 149, 'learning_rate': 0.072386293053508, 'min_child_samples': 200}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:26:52,694] Trial 116 finished with value: 0.24581005586592178 and parameters: {'n_estimators': 880, 'num_leaves': 2771, 'max_depth': 190, 'learning_rate': 0.03274218428691999, 'min_child_samples': 174}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:27:19,608] Trial 117 finished with value: 0.24860853432282007 and parameters: {'n_estimators': 896, 'num_leaves': 2780, 'max_depth': 185, 'learning_rate': 0.03375089424066865, 'min_child_samples': 172}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:27:45,633] Trial 118 finished with value: 0.2453531598513011 and parameters: {'n_estimators': 898, 'num_leaves': 2825, 'max_depth': 179, 'learning_rate': 0.030855214456491076, 'min_child_samples': 177}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:28:12,814] Trial 119 finished with value: 0.24399260628465805 and parameters: {'n_estimators': 897, 'num_leaves': 2836, 'max_depth': 192, 'learning_rate': 0.03276990247353813, 'min_child_samples': 176}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:28:43,424] Trial 120 finished with value: 0.2430939226519337 and parameters: {'n_estimators': 994, 'num_leaves': 2881, 'max_depth': 182, 'learning_rate': 0.03089338531278694, 'min_child_samples': 160}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:29:11,122] Trial 121 finished with value: 0.24814814814814817 and parameters: {'n_estimators': 948, 'num_leaves': 2700, 'max_depth': 203, 'learning_rate': 0.03119320474156411, 'min_child_samples': 172}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:29:36,449] Trial 122 finished with value: 0.24354243542435422 and parameters: {'n_estimators': 868, 'num_leaves': 2708, 'max_depth': 215, 'learning_rate': 0.034974439955054656, 'min_child_samples': 172}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:30:02,744] Trial 123 finished with value: 0.241635687732342 and parameters: {'n_estimators': 929, 'num_leaves': 2721, 'max_depth': 198, 'learning_rate': 0.0312526905672628, 'min_child_samples': 183}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:30:32,919] Trial 124 finished with value: 0.23897058823529413 and parameters: {'n_estimators': 960, 'num_leaves': 2779, 'max_depth': 178, 'learning_rate': 0.027919323222431704, 'min_child_samples': 150}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:31:36,578] Trial 125 finished with value: 0.22521008403361348 and parameters: {'n_estimators': 1747, 'num_leaves': 2587, 'max_depth': 174, 'learning_rate': 0.037503244580496184, 'min_child_samples': 165}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:31:58,310] Trial 126 finished with value: 0.24015009380863037 and parameters: {'n_estimators': 832, 'num_leaves': 2828, 'max_depth': 190, 'learning_rate': 0.022569336598773304, 'min_child_samples': 154}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:32:28,139] Trial 127 finished with value: 0.24118738404452691 and parameters: {'n_estimators': 1027, 'num_leaves': 2749, 'max_depth': 166, 'learning_rate': 0.02865547802193313, 'min_child_samples': 170}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:32:45,571] Trial 128 finished with value: 0.22467771639042355 and parameters: {'n_estimators': 731, 'num_leaves': 2678, 'max_depth': 200, 'learning_rate': 0.025352889932644902, 'min_child_samples': 180}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:33:11,030] Trial 129 finished with value: 0.24253731343283585 and parameters: {'n_estimators': 926, 'num_leaves': 2948, 'max_depth': 217, 'learning_rate': 0.033420595245263016, 'min_child_samples': 194}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:33:34,535] Trial 130 finished with value: 0.23985239852398524 and parameters: {'n_estimators': 795, 'num_leaves': 2867, 'max_depth': 186, 'learning_rate': 0.0355619760506828, 'min_child_samples': 143}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:34:08,902] Trial 131 finished with value: 0.23315118397085607 and parameters: {'n_estimators': 1079, 'num_leaves': 2802, 'max_depth': 210, 'learning_rate': 0.04487399221906836, 'min_child_samples': 187}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:34:43,938] Trial 132 finished with value: 0.24354243542435422 and parameters: {'n_estimators': 1130, 'num_leaves': 2619, 'max_depth': 230, 'learning_rate': 0.030868108063792563, 'min_child_samples': 176}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:35:16,954] Trial 133 finished with value: 0.23971377459749552 and parameters: {'n_estimators': 985, 'num_leaves': 2559, 'max_depth': 203, 'learning_rate': 0.03957021915508974, 'min_child_samples': 132}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:36:24,293] Trial 134 finished with value: 0.22772277227722773 and parameters: {'n_estimators': 1833, 'num_leaves': 2946, 'max_depth': 241, 'learning_rate': 0.036841671446329355, 'min_child_samples': 161}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:36:50,535] Trial 135 finished with value: 0.24637681159420288 and parameters: {'n_estimators': 859, 'num_leaves': 1413, 'max_depth': 71, 'learning_rate': 0.04816173649786761, 'min_child_samples': 165}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:37:14,450] Trial 136 finished with value: 0.24444444444444444 and parameters: {'n_estimators': 865, 'num_leaves': 1323, 'max_depth': 152, 'learning_rate': 0.03145082883268565, 'min_child_samples': 172}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:37:44,031] Trial 137 finished with value: 0.2445255474452555 and parameters: {'n_estimators': 903, 'num_leaves': 2713, 'max_depth': 68, 'learning_rate': 0.04369210043945939, 'min_child_samples': 163}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[I 2024-09-29 09:38:10,065] Trial 138 finished with value: 0.2445255474452555 and parameters: {'n_estimators': 838, 'num_leaves': 2908, 'max_depth': 174, 'learning_rate': 0.041926154511651166, 'min_child_samples': 153}. Best is trial 67 with value: 0.2509090909090909.\n",
      "[W 2024-09-29 09:38:14,110] Trial 139 failed with parameters: {'n_estimators': 771, 'num_leaves': 1425, 'max_depth': 58, 'learning_rate': 0.025087919596097727, 'min_child_samples': 179} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_25048\\704068152.py\", line 46, in <lambda>\n",
      "    study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_25048\\704068152.py\", line 27, in objectiveLGBM_dart\n",
      "    model.fit(x_tr, y_tr)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1298, in fit\n",
      "    init_model=init_model,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 963, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\", line 4138, in update\n",
      "    ctypes.byref(is_finished),\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-29 09:38:14,111] Trial 139 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25048\\704068152.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25048\\704068152.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25048\\704068152.py\u001b[0m in \u001b[0;36mobjectiveLGBM_dart\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 양성 클래스 확률\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_proba\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 스레드홀드에 따른 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4136\u001b[0m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m                 )\n\u001b[0;32m   4140\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_fill2['target'] = train_data_fill2['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill2.drop(\"target\", axis=1),\n",
    "    train_data_fill2[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc88d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
