{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2340621",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a199baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61f88",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a9dac",
   "metadata": {},
   "source": [
    "### 데이터 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb6716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# csv 불러오기\n",
    "train_data = pd.read_csv('./data/train_data_0827.csv')\n",
    "test_data = pd.read_csv('./data/test_data_0827.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f46868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f123dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d65710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7366d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc4696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d402be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82f331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 40\n",
      "train_data_dam DataFrame의 칼럼 수: 23\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 41\n",
      "test_data_dam DataFrame의 칼럼 수: 24\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2649161",
   "metadata": {},
   "source": [
    "모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b835f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996208b",
   "metadata": {},
   "source": [
    "공정별 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cffef",
   "metadata": {},
   "source": [
    "lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e14939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_dam 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill1 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'lgbm', train_data_dam\n",
    "    , n_estimators=2470\n",
    "    , num_leaves=2454\n",
    "    , max_depth=26\n",
    "    , learning_rate=0.06067228197373452\n",
    "    , min_child_samples=134\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'lgbm', train_data_autoclave\n",
    "    , n_estimators=731\n",
    "    , num_leaves=996\n",
    "    , max_depth=273\n",
    "    , learning_rate=0.0912254393922836\n",
    "    , min_child_samples=195\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill1\n",
    "    , n_estimators=821\n",
    "    , num_leaves=1400\n",
    "    , max_depth=52\n",
    "    , learning_rate=0.002743887584386348\n",
    "    , min_child_samples=231\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill2\n",
    "    , n_estimators=1005\n",
    "    , num_leaves=2304\n",
    "    , max_depth=293\n",
    "    , learning_rate=0.08460539739469425\n",
    "    , min_child_samples=272\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'lgbm', train_data\n",
    "#     , n_estimators=1496\n",
    "#     , num_leaves=1611\n",
    "#     , max_depth=148\n",
    "#     , learning_rate=0.0822880159816304\n",
    "#     , min_child_samples=194\n",
    "#     , boosting_type='dart'\n",
    "#     , random_state=RANDOM_STATE\n",
    "#     , verbose=-1\n",
    "# )\n",
    "\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "lgbm_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcdb03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "855\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(lgbm_probs, method='soft', threshold=0.22)\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_lgbm(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d478c0",
   "metadata": {},
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99425fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습 완료\n",
      "xgb 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill1 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1244\n",
    "    , learning_rate = 0.1258535425769987\n",
    "    , max_depth = 26\n",
    "    , alpha = 2.1820842842359597e-06\n",
    "    , gamma = 0.00010809657684921935\n",
    "    , reg_alpha = 0.5844029076359536\n",
    "    , reg_lambda = 0.4748752246073433\n",
    "    , colsample_bytree = 0.9607659760060685\n",
    "    , subsample = 0.7147741317935203\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1152, \n",
    "    learning_rate = 0.02466611382982541, \n",
    "    max_depth = 29, \n",
    "    alpha = 2.9180083404308157e-05, \n",
    "    gamma = 0.00012667501319666823, \n",
    "    reg_alpha = 0.6903592486292155, \n",
    "    reg_lambda = 0.5638873235014423, \n",
    "    colsample_bytree = 0.9432782030604233, \n",
    "    subsample = 0.19192246128663584,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1899, \n",
    "    learning_rate = 0.011878583548993711, \n",
    "    max_depth = 12, \n",
    "    alpha = 0.004515243354832891,\n",
    "    gamma = 0.0015693650802180896,\n",
    "    reg_alpha = 0.7484424912256998, \n",
    "    reg_lambda = 0.27164326303977143, \n",
    "    colsample_bytree = 0.7901385059430825,\n",
    "    subsample = 0.9924662032617025,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1162, \n",
    "    learning_rate = 0.014523070494025153, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.00012198482017902725, \n",
    "    gamma = 0.001236902841680112, \n",
    "    reg_alpha = 0.7331637000614692, \n",
    "    reg_lambda = 0.5237223061096699, \n",
    "    colsample_bytree = 0.8250374170841293, \n",
    "    subsample = 0.31906427054137687,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'xgb', train_data,\n",
    "#     n_estimators = 2427,\n",
    "#     learning_rate = 0.010774204513905965, \n",
    "#     max_depth = 17, \n",
    "#     alpha = 0.0005233654110538582, \n",
    "#     gamma = 5.551445919277608e-05, \n",
    "#     reg_alpha = 0.9652805882189326, \n",
    "#     reg_lambda = 0.3542856398135083, \n",
    "#     colsample_bytree = 0.9094884645797131, \n",
    "#     subsample = 0.1733751790853043,\n",
    "#     objective = 'binary:logistic',  # 이진 분류\n",
    "#     tree_method = \"exact\", \n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "xgb_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428c4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(xgb_probs, method='soft', threshold=0.3)\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_xgb(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdb454",
   "metadata": {},
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365f699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 모델이 train_data_dam 데이터로 학습 완료\n",
      "cat 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill1 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'cat', train_data_dam,\n",
    "    iterations = 1478, \n",
    "    learning_rate = 0.009068953796649421, \n",
    "    depth = 11, \n",
    "    min_data_in_leaf = 2,\n",
    "    l2_leaf_reg = 1.187291687951122,\n",
    "    random_strength = 0.43102541391012816, \n",
    "    bagging_temperature = 3.1790702578164853, \n",
    "    border_count = 155, \n",
    "    scale_pos_weight = 1.4418307437388553,\n",
    "    grow_policy = 'Depthwise',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'cat', train_data_autoclave,\n",
    "    iterations = 1299, \n",
    "    learning_rate =  0.03808793470493637, \n",
    "    depth = 9, \n",
    "    min_data_in_leaf = 5,\n",
    "    l2_leaf_reg = 4.942829707223811, \n",
    "    random_strength = 3.804933757402697, \n",
    "    bagging_temperature = 1.3151583440997139, \n",
    "    border_count = 286, \n",
    "    scale_pos_weight = 1.9749286362629779,\n",
    "    grow_policy = 'SymmetricTree',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill1,\n",
    "    iterations = 2842, \n",
    "    learning_rate = 0.01099464761153367, \n",
    "    depth = 4, \n",
    "    min_data_in_leaf = 3,\n",
    "    l2_leaf_reg = 3.7373183252945945, \n",
    "    random_strength = 9.3675281753561, \n",
    "    bagging_temperature = 4.750112155842117, \n",
    "    border_count = 160, \n",
    "    scale_pos_weight = 2.53860325765727,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill2,\n",
    "    iterations = 1458, \n",
    "    learning_rate = 0.004706507801075929, \n",
    "    depth = 13, \n",
    "    min_data_in_leaf = 4,\n",
    "    l2_leaf_reg = 1.909987690181427, \n",
    "    random_strength = 9.047942432889677, \n",
    "    bagging_temperature = 3.545210494821586, \n",
    "    border_count = 300, \n",
    "    scale_pos_weight = 3.4781865667208467,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'cat', train_data,\n",
    "#     iterations=1349,\n",
    "#     learning_rate=0.012526639112437014,\n",
    "#     depth=9,\n",
    "#     min_data_in_leaf=4,\n",
    "#     l2_leaf_reg=2.245006704049574,\n",
    "#     random_strength=0.6922797458293842,\n",
    "#     bagging_temperature=8.230635636022027,\n",
    "#     border_count=211,\n",
    "#     scale_pos_weight=2.0709015241138236,\n",
    "#     grow_policy='Depthwise',\n",
    "    \n",
    "#     random_state=RANDOM_STATE,\n",
    "#     eval_metric='F1',\n",
    "#     logging_level='Silent',\n",
    "#     boosting_type='Plain'\n",
    "# )\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "cat_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9b2fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(cat_probs, method='soft', threshold=0.28)\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_cat(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b8cbf",
   "metadata": {},
   "source": [
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902e6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et 모델이 train_data_dam 데이터로 학습 완료\n",
      "et 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "et 모델이 train_data_fill1 데이터로 학습 완료\n",
      "et 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'et', train_data_dam,\n",
    "    n_estimators = 1532,\n",
    "    max_depth = 25,\n",
    "    min_samples_split = 3,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'et', train_data_autoclave,\n",
    "    n_estimators = 1943,\n",
    "    max_depth = 34,\n",
    "    min_samples_split = 6,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'et', train_data_fill1,\n",
    "    n_estimators = 2040,\n",
    "    max_depth = 25,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'et', train_data_fill2\n",
    "    , n_estimators = 709\n",
    "    , max_depth = 44\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , bootstrap = False\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'et', train_data,\n",
    "#     n_estimators = 1085,\n",
    "#     max_depth = 30,\n",
    "#     min_samples_split = 3,\n",
    "#     min_samples_leaf = 1,\n",
    "#     criterion = 'entropy',\n",
    "#     bootstrap = False,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "et_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f271a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(et_probs, method='soft', threshold=0.3)\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_et(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4552f0",
   "metadata": {},
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be548a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf 모델이 train_data_dam 데이터로 학습 완료\n",
      "rf 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "rf 모델이 train_data_fill1 데이터로 학습 완료\n",
      "rf 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'rf', train_data_dam\n",
    "    , n_estimators = 1113\n",
    "    , max_depth = 43\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'rf', train_data_autoclave\n",
    "    , n_estimators = 2744\n",
    "    , max_depth = 27\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'rf', train_data_fill1\n",
    "    , n_estimators = 1071\n",
    "    , max_depth = 61\n",
    "    , min_samples_split = 4\n",
    "    , min_samples_leaf = 3\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'rf', train_data_fill2\n",
    "    , n_estimators = 2535\n",
    "    , max_depth = 100\n",
    "    , min_samples_split = 5\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'rf', train_data\n",
    "#     , n_estimators = 1047\n",
    "#     , max_depth = 39\n",
    "#     , min_samples_split = 4\n",
    "#     , min_samples_leaf = 1\n",
    "#     , criterion = 'entropy'\n",
    "#     , class_weight = 'balanced'\n",
    "#     , random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "rf_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfb90512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(rf_probs, method='soft', threshold=0.32)  \n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_rf(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68101399",
   "metadata": {},
   "source": [
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe6192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습 완료\n",
      "ada 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill1 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=27,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.8675781747711193,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Dam = fit_all_train_data_function(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=833\n",
    "    , learning_rate=0.9817802538802249\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.16617258789907924,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=118\n",
    "    , learning_rate=0.4047552485696655\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=12,\n",
    "    min_samples_split=27,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6030749544065899,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=400\n",
    "    , learning_rate=0.48125695338518293\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.8686759201566782,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=517\n",
    "    , learning_rate=0.25710844249446485\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# base_estimator = DecisionTreeClassifier(\n",
    "#     max_depth=6,\n",
    "#     min_samples_split=30,\n",
    "#     min_samples_leaf=12,\n",
    "#     max_features=0.8457354826252363,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "#     'ada', train_data\n",
    "#     , estimator=base_estimator\n",
    "#     , n_estimators=541\n",
    "#     , learning_rate=0.3430292944431681\n",
    "#     , random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "ada_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , train_model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4b0791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(ada_probs, method='soft', threshold=0.26)\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_ada(4).csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e2abe",
   "metadata": {},
   "source": [
    "Hard voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d3119",
   "metadata": {},
   "source": [
    "공정구분하여 학습한 개별 모델들에 대해서 hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "502c838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def read_submission_files(file_paths):\n",
    "    \"\"\"\n",
    "    제출 파일을 읽어와서 예측 결과를 반환합니다.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list of str): 제출 파일 경로 리스트\n",
    "\n",
    "    Returns:\n",
    "    list of np.array: 각 제출 파일의 예측 결과 리스트\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        preds = df['target'].apply(lambda x: 1 if x == 'AbNormal' else 0).values\n",
    "        predictions.append(preds)\n",
    "    return predictions\n",
    "\n",
    "def hard_voting(preds):\n",
    "    \"\"\"\n",
    "    하드 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds (list of np.array): 각 모델의 예측 배열 리스트\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    # 각 샘플의 예측 결과를 문자열로 변환하여 리스트에 저장\n",
    "    sample_predictions = [''.join(map(str, x)) for x in preds.T]\n",
    "    \n",
    "    # 각 예측 결과의 빈도수를 계산\n",
    "    prediction_counts = Counter(sample_predictions)\n",
    "    \n",
    "    # 빈도수 출력\n",
    "    for pred, count in prediction_counts.items():\n",
    "        print(f\"Prediction {pred}: {count} times\")\n",
    "    \n",
    "    # 하드 보팅을 통해 최종 예측을 계산\n",
    "    final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6bbee",
   "metadata": {},
   "source": [
    "csv 파일로 hard voting 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce3adc5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/data0827_xgb(4).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m add_common_path(file_names, common_path)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 제출 파일에서 예측 결과 읽어오기\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mread_submission_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 하드 보팅 결과\u001b[39;00m\n\u001b[1;32m     31\u001b[0m final_predictions_hard \u001b[38;5;241m=\u001b[39m hard_voting(predictions)\n",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m, in \u001b[0;36mread_submission_files\u001b[0;34m(file_paths)\u001b[0m\n\u001b[1;32m     15\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[0;32m---> 17\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     preds \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbNormal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     19\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(preds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/data0827_xgb(4).csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 공통 경로\n",
    "common_path = \"./data/\"\n",
    "\n",
    "# 제출 파일 이름 리스트\n",
    "file_names = [\n",
    "    \"data0827_lgbm(4).csv\"\n",
    "    , \"data0827_lgbm(4).csv\"\n",
    "    , \"data0827_xgb(4).csv\"\n",
    "    , \"data0827_xgb(4).csv\"\n",
    "    , \"data0827_cat(4).csv\"\n",
    "    , \"data0827_cat(4).csv\"\n",
    "    , \"data0827_et(4).csv\"\n",
    "    , \"data0827_rf(4).csv\"\n",
    "    , \"data0827_ada(4).csv\"   \n",
    "    # 파일 추가 가능  <----- 파일 필요시 추가하세요!!\n",
    "]\n",
    "\n",
    "# 경로를 추가하는 함수\n",
    "def add_common_path(file_names, common_path):\n",
    "    return [common_path + file_name for file_name in file_names]\n",
    "\n",
    "# 경로가 추가된 파일 리스트\n",
    "file_paths = add_common_path(file_names, common_path)\n",
    "\n",
    "# 제출 파일에서 예측 결과 읽어오기\n",
    "predictions = read_submission_files(file_paths)\n",
    "\n",
    "# 하드 보팅 결과\n",
    "final_predictions_hard = hard_voting(predictions)\n",
    "\n",
    "# 결과를 새로운 제출 파일로 저장할 파일 이름\n",
    "output_file_name = \"model_name_change_submission.csv\" # <----- 파일 이름을 변경하세요!!\n",
    "\n",
    "# 결과를 새로운 제출 파일로 저장\n",
    "df_sub = pd.read_csv(file_paths[0])\n",
    "df_sub[\"target\"] = final_predictions_hard\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "df_sub.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(f\"최종 제출 파일이 '{output_file_name}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9bfc5627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID    target\n",
       "0  0001be084fbc4aaa9d921f39e595961b    Normal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80    Normal\n",
       "2  000948934c4140d883d670adcb609584    Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7    Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95    Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2    Normal\n",
       "6  0020734a7b29472298358ad58645a0c9    Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135    Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  AbNormal\n",
       "9  002d904240d84b188d410d16383a9c3a    Normal"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d5658",
   "metadata": {},
   "source": [
    "우측 상단의 제출 버튼을 클릭해 결과를 확인하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7d5f7",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
