{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_0827.csv\")\n",
    "test_data = pd.read_csv(\"test_data_0827.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edfc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dd7eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3b003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a333ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "141cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ffec39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be86915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 40\n",
      "train_data_dam DataFrame의 칼럼 수: 23\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 41\n",
      "test_data_dam DataFrame의 칼럼 수: 24\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d288bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     fn_indices = np.where((y_val == 1) & (y_val_pred == 0))[0]\n",
    "#     fn_array = np.array(fn_indices)\n",
    "\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af914",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15f2a7",
   "metadata": {},
   "source": [
    "Dam 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c98a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습한 결과:\n",
      "F1 Score: 0.228099173553719\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7566   96]\n",
      " [ 371   69]]\n",
      "---\n",
      "Accuracy: 0.9423599111330536\n",
      "Precision: 0.41818181818181815\n",
      "Recall: 0.15681818181818183\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=27,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.8675781747711193,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Dam = train_and_evaluate_model(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=833\n",
    "    , learning_rate=0.9817802538802249\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b184d",
   "metadata": {},
   "source": [
    "AutoClave 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7cbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
      "F1 Score: 0.19047619047619044\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[6943  719]\n",
      " [ 318  122]]\n",
      "---\n",
      "Accuracy: 0.8720069118736115\n",
      "Precision: 0.1450653983353151\n",
      "Recall: 0.2772727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.16617258789907924,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_AutoClave = train_and_evaluate_model(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=118\n",
    "    , learning_rate=0.4047552485696655\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357e142",
   "metadata": {},
   "source": [
    "Fill1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a1e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill1 데이터로 학습한 결과:\n",
      "F1 Score: 0.19525065963060687\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7418  244]\n",
      " [ 366   74]]\n",
      "---\n",
      "Accuracy: 0.9247099481609479\n",
      "Precision: 0.23270440251572327\n",
      "Recall: 0.16818181818181818\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=12,\n",
    "    min_samples_split=27,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6030749544065899,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill1 = train_and_evaluate_model(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=400\n",
    "    , learning_rate=0.48125695338518293\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98025a2",
   "metadata": {},
   "source": [
    "Fill2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274a5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill2 데이터로 학습한 결과:\n",
      "F1 Score: 0.18980169971671387\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7463  199]\n",
      " [ 373   67]]\n",
      "---\n",
      "Accuracy: 0.9294001481115773\n",
      "Precision: 0.2518796992481203\n",
      "Recall: 0.15227272727272728\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.8686759201566782,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill2 = train_and_evaluate_model(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=517\n",
    "    , learning_rate=0.25710844249446485\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb4d",
   "metadata": {},
   "source": [
    "전체공정 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6f551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data 데이터로 학습한 결과:\n",
      "F1 Score: 0.11070780399274045\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[ 815 6847]\n",
      " [  13  427]]\n",
      "---\n",
      "Accuracy: 0.15329548259688966\n",
      "Precision: 0.0587022271102557\n",
      "Recall: 0.9704545454545455\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base_estimator = DecisionTreeClassifier(\n",
    "#     max_depth=6,\n",
    "#     min_samples_split=30,\n",
    "#     min_samples_leaf=12,\n",
    "#     max_features=0.8457354826252363,\n",
    "#     # n_estimators=517,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# train_model_All = train_and_evaluate_model(\n",
    "#     'ada', train_data\n",
    "#     , estimator=base_estimator\n",
    "#     , n_estimators=541\n",
    "#     , learning_rate=0.3430292944431681\n",
    "#     , random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a59250",
   "metadata": {},
   "source": [
    "soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da1d05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.19494584837545126\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7602   60]\n",
      " [ 386   54]]\n",
      "---\n",
      "Accuracy: 0.9449518637373489\n",
      "Precision: 0.47368421052631576\n",
      "Recall: 0.12272727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 사용 \n",
    "estimators = [\n",
    "    ('dam', train_model_Dam)\n",
    "    , ('autoclave', train_model_AutoClave)\n",
    "    , ('fill1', train_model_Fill1)\n",
    "    , ('fill2', train_model_Fill2)\n",
    "#     , ('all', train_model_All)\n",
    "]\n",
    "\n",
    "# VotingClassifier 학습 및 평가\n",
    "# voting_clf_hard = voting_function(train_data, estimators, voting='hard')\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d54a92a8-64ae-4b78-a2af-e9e563c3cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.19298245614035087\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7587   75]\n",
      " [ 385   55]]\n",
      "---\n",
      "Accuracy: 0.9432238953344854\n",
      "Precision: 0.4230769230769231\n",
      "Recall: 0.125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f23c02e-f3e5-41cf-8990-ff9583d58da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.1904761904761905\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7589   73]\n",
      " [ 386   54]]\n",
      "---\n",
      "Accuracy: 0.9433473216489756\n",
      "Precision: 0.4251968503937008\n",
      "Recall: 0.12272727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "14428afe-89f2-43a2-8e08-9ef7e8890d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.19354838709677422\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7598   64]\n",
      " [ 386   54]]\n",
      "---\n",
      "Accuracy: 0.9444581584793879\n",
      "Precision: 0.4576271186440678\n",
      "Recall: 0.12272727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b439ce62-fc48-4423-b9ef-412120e3f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.19285714285714287\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7596   66]\n",
      " [ 386   54]]\n",
      "---\n",
      "Accuracy: 0.9442113058504074\n",
      "Precision: 0.45\n",
      "Recall: 0.12272727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf96314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.20512820512820512\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7542  120]\n",
      " [ 376   64]]\n",
      "---\n",
      "Accuracy: 0.9387805480128364\n",
      "Precision: 0.34782608695652173\n",
      "Recall: 0.14545454545454545\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ecd798f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m voting_clf_soft \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 116\u001b[0m, in \u001b[0;36mvoting_function\u001b[0;34m(data, estimators, voting, threshold)\u001b[0m\n\u001b[1;32m    113\u001b[0m voting_clf \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39mestimators, voting\u001b[38;5;241m=\u001b[39mvoting)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[43mvoting_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m voting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# 소프트 보팅의 경우 확률 예측\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     y_val_pred_proba \u001b[38;5;241m=\u001b[39m voting_clf\u001b[38;5;241m.\u001b[39mpredict_proba(x_val)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:346\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    344\u001b[0m transformed_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mle_\u001b[38;5;241m.\u001b[39mtransform(y)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_voting.py:81\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of `estimators` and weights must be equal; got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_single_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVoting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdrop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_base.py:46\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 46\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:162\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    159\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:569\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \n\u001b[1;32m    532\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:578\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    576\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m--> 578\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "### 모델 학습(train 데이터 전체 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa25b4",
   "metadata": {},
   "source": [
    "위의 모델학습 코드에서 함수명만 바뀌고 들어가는 값들은 동일  \n",
    "-> 위의 코드 복붙한다음 함수명만 바꿔주면 사용하기 편함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39c08dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습 완료\n",
      "ada 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill1 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=27,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.8675781747711193,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Dam = fit_all_train_data_function(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=833\n",
    "    , learning_rate=0.9817802538802249\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.16617258789907924,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_AutoClave = fit_all_train_data_function(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=118\n",
    "    , learning_rate=0.4047552485696655\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=12,\n",
    "    min_samples_split=27,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6030749544065899,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill1 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=400\n",
    "    , learning_rate=0.48125695338518293\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.8686759201566782,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill2 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=517\n",
    "    , learning_rate=0.25710844249446485\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# base_estimator = DecisionTreeClassifier(\n",
    "#     max_depth=6,\n",
    "#     min_samples_split=30,\n",
    "#     min_samples_leaf=12,\n",
    "#     max_features=0.8457354826252363,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# train_model_All = fit_all_train_data_function(\n",
    "#     'ada', train_data\n",
    "#     , estimator=base_estimator\n",
    "#     , n_estimators=541\n",
    "#     , learning_rate=0.3430292944431681\n",
    "#     , random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8b158",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5ee55c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1a08e10-1df1-4a99-ae66-f0f1940b1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dam.fillna(0, inplace=True)\n",
    "x_test_autoclave.fillna(0, inplace=True)\n",
    "x_test_fill1.fillna(0, inplace=True)\n",
    "x_test_fill2.fillna(0, inplace=True)\n",
    "x_test_all.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d855e",
   "metadata": {},
   "source": [
    "Voting(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98f3e1",
   "metadata": {},
   "source": [
    "4개의 모델중 다수의 모델이 판단한 값을 타겟값으로 가져감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c7f911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 예측 리스트 (하드 보팅용)\\npreds = [\\n    model_Dam.predict(x_test_dam)\\n    , model_AutoClave.predict(x_test_autoclave)\\n    , model_Fill1.predict(x_test_fill1)\\n    , model_Fill2.predict(x_test_fill2)\\n    # , model_All.predict(x_test_all)\\n]\\n\\n# 하드 보팅 결과\\nfinal_predictions = voting(preds, method='hard')\\nprint(sum(final_predictions))\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 예측 리스트 (하드 보팅용)\n",
    "preds = [\n",
    "    model_Dam.predict(x_test_dam)\n",
    "    , model_AutoClave.predict(x_test_autoclave)\n",
    "    , model_Fill1.predict(x_test_fill1)\n",
    "    , model_Fill2.predict(x_test_fill2)\n",
    "    # , model_All.predict(x_test_all)\n",
    "]\n",
    "\n",
    "# 하드 보팅 결과\n",
    "final_predictions = voting(preds, method='hard')\n",
    "print(sum(final_predictions))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287a3c3",
   "metadata": {},
   "source": [
    "Voting(soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a4ed1",
   "metadata": {},
   "source": [
    "4개의 모델의 확률의 합에 대한 평균이 일정 수치(스레스홀드) 값을 넘으면 AbNormal 값을 가짐  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5151edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "probs = [\n",
    "    train_model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , train_model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , train_model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , train_model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "#     , train_model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n",
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.3)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "754986da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_sub \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubmission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_sub[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m final_predictions\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# df_sub['target'] 값을 문자열 레이블로 변환\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'submission.csv'"
     ]
    }
   ],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efee1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13774-7498-474c-90d5-254178b9be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 제출 F1 score = 0.1990881"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899379df",
   "metadata": {},
   "source": [
    "모델을 통해 예측해 낸 정답지(csv) 파일의 결과값을 불러와 voting 하는 방식  \n",
    "이때의 voting은 hard방식만 가능(예측확률은 저장되어있지 않음으로 soft 보팅은 불가능)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03053beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def read_submission_files(file_paths):\n",
    "#     \"\"\"\n",
    "#     제출 파일을 읽어와서 예측 결과를 반환합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     file_paths (list of str): 제출 파일 경로 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     list of np.array: 각 제출 파일의 예측 결과 리스트\n",
    "#     \"\"\"\n",
    "#     predictions = []\n",
    "#     for file_path in file_paths:\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         preds = df['target'].apply(lambda x: 1 if x == 'AbNormal' else 0).values\n",
    "#         predictions.append(preds)\n",
    "#     return predictions\n",
    "\n",
    "# def hard_voting(preds):\n",
    "#     \"\"\"\n",
    "#     하드 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     preds (list of np.array): 각 모델의 예측 배열 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: 최종 예측 결과\n",
    "#     \"\"\"\n",
    "#     preds = np.array(preds)\n",
    "#     final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "#     return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae7de4",
   "metadata": {},
   "source": [
    "submission_file 에서 csv 파일을 불러와 hard voting 하는 알고리즘  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 공통 경로\n",
    "# common_path = \"../submission_file/\"\n",
    "\n",
    "# # 제출 파일 이름 리스트\n",
    "# file_names = [\n",
    "#     \"data0816_light_cutoff0.28_submission.csv\",\n",
    "#     \"submission_score0.23.csv\"\n",
    "#     # 파일 추가 가능  <----- 파일 필요시 추가하세요!!\n",
    "# ]\n",
    "\n",
    "# # 경로를 추가하는 함수\n",
    "# def add_common_path(file_names, common_path):\n",
    "#     return [common_path + file_name for file_name in file_names]\n",
    "\n",
    "# # 경로가 추가된 파일 리스트\n",
    "# file_paths = add_common_path(file_names, common_path)\n",
    "\n",
    "# # 제출 파일에서 예측 결과 읽어오기\n",
    "# predictions = read_submission_files(file_paths)\n",
    "\n",
    "# # 하드 보팅 결과\n",
    "# final_predictions_hard = hard_voting(predictions)\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장할 파일 이름\n",
    "# output_file_name = \"final_submission.csv\" # <----- 파일 이름을 변경하세요!!\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장\n",
    "# df_sub = pd.read_csv(file_paths[0])\n",
    "# df_sub[\"target\"] = final_predictions_hard\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "# df_sub.to_csv(output_file_name, index=False)\n",
    "\n",
    "# print(f\"최종 제출 파일이 '{output_file_name}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc9069-e143-4606-ac2c-14f8c28e9b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
