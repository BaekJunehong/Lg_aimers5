{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2340621",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a199baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d61f88",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3a9dac",
   "metadata": {},
   "source": [
    "### 데이터 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb6716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "# csv 불러오기\n",
    "train_data = pd.read_csv('./data/train_data_0827.csv')\n",
    "test_data = pd.read_csv('./data/test_data_0827.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f46868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49f123dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9d65710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7366d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc4696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d402be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82f331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 40\n",
      "train_data_dam DataFrame의 칼럼 수: 23\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 41\n",
      "test_data_dam DataFrame의 칼럼 수: 24\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2649161",
   "metadata": {},
   "source": [
    "모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b835f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a996208b",
   "metadata": {},
   "source": [
    "공정별 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cffef",
   "metadata": {},
   "source": [
    "lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50e14939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_dam 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill1 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill2 데이터로 학습 완료\n",
      "lgbm 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'lgbm', train_data_dam\n",
    "    , n_estimators=2470\n",
    "    , num_leaves=2454\n",
    "    , max_depth=26\n",
    "    , learning_rate=0.06067228197373452\n",
    "    , min_child_samples=134\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'lgbm', train_data_autoclave\n",
    "    , n_estimators=731\n",
    "    , num_leaves=996\n",
    "    , max_depth=273\n",
    "    , learning_rate=0.0912254393922836\n",
    "    , min_child_samples=195\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill1\n",
    "    , n_estimators=821\n",
    "    , num_leaves=1400\n",
    "    , max_depth=52\n",
    "    , learning_rate=0.002743887584386348\n",
    "    , min_child_samples=231\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill2\n",
    "    , n_estimators=1005\n",
    "    , num_leaves=2304\n",
    "    , max_depth=293\n",
    "    , learning_rate=0.08460539739469425\n",
    "    , min_child_samples=272\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'lgbm', train_data\n",
    "    , n_estimators=1496\n",
    "    , num_leaves=1611\n",
    "    , max_depth=148\n",
    "    , learning_rate=0.0822880159816304\n",
    "    , min_child_samples=194\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "lgbm_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcdb03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(lgbm_probs, method='soft', threshold=0.24) # 4개공정만 사용할때는 0.28\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d478c0",
   "metadata": {},
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c99425fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습 완료\n",
      "xgb 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill1 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill2 데이터로 학습 완료\n",
      "xgb 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1244\n",
    "    , learning_rate = 0.1258535425769987\n",
    "    , max_depth = 26\n",
    "    , alpha = 2.1820842842359597e-06\n",
    "    , gamma = 0.00010809657684921935\n",
    "    , reg_alpha = 0.5844029076359536\n",
    "    , reg_lambda = 0.4748752246073433\n",
    "    , colsample_bytree = 0.9607659760060685\n",
    "    , subsample = 0.7147741317935203\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1152, \n",
    "    learning_rate = 0.02466611382982541, \n",
    "    max_depth = 29, \n",
    "    alpha = 2.9180083404308157e-05, \n",
    "    gamma = 0.00012667501319666823, \n",
    "    reg_alpha = 0.6903592486292155, \n",
    "    reg_lambda = 0.5638873235014423, \n",
    "    colsample_bytree = 0.9432782030604233, \n",
    "    subsample = 0.19192246128663584,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1899, \n",
    "    learning_rate = 0.011878583548993711, \n",
    "    max_depth = 12, \n",
    "    alpha = 0.004515243354832891,\n",
    "    gamma = 0.0015693650802180896,\n",
    "    reg_alpha = 0.7484424912256998, \n",
    "    reg_lambda = 0.27164326303977143, \n",
    "    colsample_bytree = 0.7901385059430825,\n",
    "    subsample = 0.9924662032617025,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1162, \n",
    "    learning_rate = 0.014523070494025153, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.00012198482017902725, \n",
    "    gamma = 0.001236902841680112, \n",
    "    reg_alpha = 0.7331637000614692, \n",
    "    reg_lambda = 0.5237223061096699, \n",
    "    colsample_bytree = 0.8250374170841293, \n",
    "    subsample = 0.31906427054137687,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'xgb', train_data,\n",
    "    n_estimators = 2427,\n",
    "    learning_rate = 0.010774204513905965, \n",
    "    max_depth = 17, \n",
    "    alpha = 0.0005233654110538582, \n",
    "    gamma = 5.551445919277608e-05, \n",
    "    reg_alpha = 0.9652805882189326, \n",
    "    reg_lambda = 0.3542856398135083, \n",
    "    colsample_bytree = 0.9094884645797131, \n",
    "    subsample = 0.1733751790853043,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "xgb_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "428c4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(xgb_probs, method='soft', threshold=0.3)  # 4개공정만 사용할때는 0.26\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_xgb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdb454",
   "metadata": {},
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "365f699a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat 모델이 train_data_dam 데이터로 학습 완료\n",
      "cat 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill1 데이터로 학습 완료\n",
      "cat 모델이 train_data_fill2 데이터로 학습 완료\n",
      "cat 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'cat', train_data_dam,\n",
    "    iterations = 1478, \n",
    "    learning_rate = 0.009068953796649421, \n",
    "    depth = 11, \n",
    "    min_data_in_leaf = 2,\n",
    "    l2_leaf_reg = 1.187291687951122,\n",
    "    random_strength = 0.43102541391012816, \n",
    "    bagging_temperature = 3.1790702578164853, \n",
    "    border_count = 155, \n",
    "    scale_pos_weight = 1.4418307437388553,\n",
    "    grow_policy = 'Depthwise',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'cat', train_data_autoclave,\n",
    "    iterations = 1299, \n",
    "    learning_rate =  0.03808793470493637, \n",
    "    depth = 9, \n",
    "    min_data_in_leaf = 5,\n",
    "    l2_leaf_reg = 4.942829707223811, \n",
    "    random_strength = 3.804933757402697, \n",
    "    bagging_temperature = 1.3151583440997139, \n",
    "    border_count = 286, \n",
    "    scale_pos_weight = 1.9749286362629779,\n",
    "    grow_policy = 'SymmetricTree',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill1,\n",
    "    iterations = 2842, \n",
    "    learning_rate = 0.01099464761153367, \n",
    "    depth = 4, \n",
    "    min_data_in_leaf = 3,\n",
    "    l2_leaf_reg = 3.7373183252945945, \n",
    "    random_strength = 9.3675281753561, \n",
    "    bagging_temperature = 4.750112155842117, \n",
    "    border_count = 160, \n",
    "    scale_pos_weight = 2.53860325765727,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'cat', train_data_fill2,\n",
    "    iterations = 1458, \n",
    "    learning_rate = 0.004706507801075929, \n",
    "    depth = 13, \n",
    "    min_data_in_leaf = 4,\n",
    "    l2_leaf_reg = 1.909987690181427, \n",
    "    random_strength = 9.047942432889677, \n",
    "    bagging_temperature = 3.545210494821586, \n",
    "    border_count = 300, \n",
    "    scale_pos_weight = 3.4781865667208467,\n",
    "    grow_policy = 'Lossguide',\n",
    "\n",
    "\n",
    "    random_state = RANDOM_STATE,\n",
    "    eval_metric = 'F1',\n",
    "    logging_level = 'Silent',\n",
    "    boosting_type = 'Plain'\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'cat', train_data,\n",
    "    iterations=1349,\n",
    "    learning_rate=0.012526639112437014,\n",
    "    depth=9,\n",
    "    min_data_in_leaf=4,\n",
    "    l2_leaf_reg=2.245006704049574,\n",
    "    random_strength=0.6922797458293842,\n",
    "    bagging_temperature=8.230635636022027,\n",
    "    border_count=211,\n",
    "    scale_pos_weight=2.0709015241138236,\n",
    "    grow_policy='Depthwise',\n",
    "    \n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='F1',\n",
    "    logging_level='Silent',\n",
    "    boosting_type='Plain'\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "cat_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9b2fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(cat_probs, method='soft', threshold=0.3) # 4개공정만 사용할때는 0.29\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_cat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b8cbf",
   "metadata": {},
   "source": [
    "et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "902e6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et 모델이 train_data_dam 데이터로 학습 완료\n",
      "et 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "et 모델이 train_data_fill1 데이터로 학습 완료\n",
      "et 모델이 train_data_fill2 데이터로 학습 완료\n",
      "et 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'et', train_data_dam,\n",
    "    n_estimators = 1532,\n",
    "    max_depth = 25,\n",
    "    min_samples_split = 3,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'et', train_data_autoclave,\n",
    "    n_estimators = 1943,\n",
    "    max_depth = 34,\n",
    "    min_samples_split = 6,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'et', train_data_fill1,\n",
    "    n_estimators = 2040,\n",
    "    max_depth = 25,\n",
    "    min_samples_split = 4,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'et', train_data_fill2\n",
    "    , n_estimators = 709\n",
    "    , max_depth = 44\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , bootstrap = False\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'et', train_data,\n",
    "    n_estimators = 1085,\n",
    "    max_depth = 30,\n",
    "    min_samples_split = 3,\n",
    "    min_samples_leaf = 1,\n",
    "    criterion = 'entropy',\n",
    "    bootstrap = False,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "et_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f271a8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(et_probs, method='soft', threshold=0.3) # 4개공정만 사용할때 동일하게 0.26\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_et.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4552f0",
   "metadata": {},
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be548a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf 모델이 train_data_dam 데이터로 학습 완료\n",
      "rf 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "rf 모델이 train_data_fill1 데이터로 학습 완료\n",
      "rf 모델이 train_data_fill2 데이터로 학습 완료\n",
      "rf 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'rf', train_data_dam\n",
    "    , n_estimators = 1113\n",
    "    , max_depth = 43\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'rf', train_data_autoclave\n",
    "    , n_estimators = 2744\n",
    "    , max_depth = 27\n",
    "    , min_samples_split = 3\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'rf', train_data_fill1\n",
    "    , n_estimators = 1071\n",
    "    , max_depth = 61\n",
    "    , min_samples_split = 4\n",
    "    , min_samples_leaf = 3\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'rf', train_data_fill2\n",
    "    , n_estimators = 2535\n",
    "    , max_depth = 100\n",
    "    , min_samples_split = 5\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'rf', train_data\n",
    "    , n_estimators = 1047\n",
    "    , max_depth = 39\n",
    "    , min_samples_split = 4\n",
    "    , min_samples_leaf = 1\n",
    "    , criterion = 'entropy'\n",
    "    , class_weight = 'balanced'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "rf_probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb90512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "955\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(rf_probs, method='soft', threshold=0.32)  # 4개공정만 사용할때 동일하게 0.28\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68101399",
   "metadata": {},
   "source": [
    "ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbe6192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습 완료\n",
      "ada 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill1 데이터로 학습 완료\n",
      "ada 모델이 train_data_fill2 데이터로 학습 완료\n",
      "ada 모델이 train_data 데이터로 학습 완료\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74/2326922689.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mx_test_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Set ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# 예측 확률 리스트 (소프트 보팅용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m ada_probs = [\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtrain_data_dam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_dam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mtrain_model_AutoClave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_autoclave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mtrain_model_Fill1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fill1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mtrain_model_Fill2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_fill2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=27,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=0.8675781747711193,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Dam = fit_all_train_data_function(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=833\n",
    "    , learning_rate=0.9817802538802249\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=15,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.16617258789907924,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_AutoClave = fit_all_train_data_function(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=118\n",
    "    , learning_rate=0.4047552485696655\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=12,\n",
    "    min_samples_split=27,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6030749544065899,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill1 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=400\n",
    "    , learning_rate=0.48125695338518293\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.8686759201566782,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill2 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=517\n",
    "    , learning_rate=0.25710844249446485\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=12,\n",
    "    max_features=0.8457354826252363,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_All = fit_all_train_data_function(\n",
    "    'ada', train_data\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=541\n",
    "    , learning_rate=0.3430292944431681\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)\n",
    "\n",
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "ada_probs = [\n",
    "    train_data_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , train_model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , train_model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , train_model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , train_model_All.predict_proba(x_test_all)[:, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb30b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "ada_probs = [\n",
    "    train_model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , train_model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , train_model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , train_model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , train_model_All.predict_proba(x_test_all)[:, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4b0791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3204\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(ada_probs, method='soft', threshold=0.24)  # 4개공정만 사용할때 0.22\n",
    "print(sum(final_predictions))\n",
    "\n",
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"./data/data0827_ada.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e2abe",
   "metadata": {},
   "source": [
    "Hard voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d3119",
   "metadata": {},
   "source": [
    "공정구분하여 학습한 개별 모델들에 대해서 hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "502c838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def read_submission_files(file_paths):\n",
    "    \"\"\"\n",
    "    제출 파일을 읽어와서 예측 결과를 반환합니다.\n",
    "\n",
    "    Parameters:\n",
    "    file_paths (list of str): 제출 파일 경로 리스트\n",
    "\n",
    "    Returns:\n",
    "    list of np.array: 각 제출 파일의 예측 결과 리스트\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        preds = df['target'].apply(lambda x: 1 if x == 'AbNormal' else 0).values\n",
    "        predictions.append(preds)\n",
    "    return predictions\n",
    "\n",
    "def hard_voting(preds):\n",
    "    \"\"\"\n",
    "    하드 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds (list of np.array): 각 모델의 예측 배열 리스트\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    # 각 샘플의 예측 결과를 문자열로 변환하여 리스트에 저장\n",
    "    sample_predictions = [''.join(map(str, x)) for x in preds.T]\n",
    "    \n",
    "    # 각 예측 결과의 빈도수를 계산\n",
    "    prediction_counts = Counter(sample_predictions)\n",
    "    \n",
    "    # 빈도수 출력\n",
    "    for pred, count in prediction_counts.items():\n",
    "        print(f\"Prediction {pred}: {count} times\")\n",
    "    \n",
    "    # 하드 보팅을 통해 최종 예측을 계산\n",
    "    final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6bbee",
   "metadata": {},
   "source": [
    "csv 파일로 hard voting 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce3adc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 000000001: 2231 times\n",
      "Prediction 000000000: 13980 times\n",
      "Prediction 000011000: 19 times\n",
      "Prediction 000000011: 249 times\n",
      "Prediction 000011011: 56 times\n",
      "Prediction 111111111: 199 times\n",
      "Prediction 110011011: 72 times\n",
      "Prediction 110000000: 39 times\n",
      "Prediction 111100111: 6 times\n",
      "Prediction 111111011: 56 times\n",
      "Prediction 111100011: 30 times\n",
      "Prediction 000011001: 34 times\n",
      "Prediction 000000010: 58 times\n",
      "Prediction 110000011: 74 times\n",
      "Prediction 110011000: 8 times\n",
      "Prediction 111100000: 1 times\n",
      "Prediction 110000001: 66 times\n",
      "Prediction 110011111: 48 times\n",
      "Prediction 000011010: 14 times\n",
      "Prediction 000011111: 19 times\n",
      "Prediction 000011110: 1 times\n",
      "Prediction 110011110: 4 times\n",
      "Prediction 111100001: 7 times\n",
      "Prediction 000000110: 6 times\n",
      "Prediction 110000010: 6 times\n",
      "Prediction 000000111: 26 times\n",
      "Prediction 111111010: 4 times\n",
      "Prediction 110011001: 15 times\n",
      "Prediction 110011010: 9 times\n",
      "Prediction 111111001: 2 times\n",
      "Prediction 110000111: 8 times\n",
      "Prediction 000000100: 1 times\n",
      "Prediction 001100111: 1 times\n",
      "Prediction 111111000: 1 times\n",
      "Prediction 111100010: 4 times\n",
      "Prediction 110000110: 1 times\n",
      "Prediction 001100011: 2 times\n",
      "Prediction 001100001: 1 times\n",
      "Prediction 001111111: 1 times\n",
      "Prediction 111111110: 1 times\n",
      "Prediction 000000101: 1 times\n",
      "최종 제출 파일이 '0827_model_name_change_submission.csv'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 공통 경로\n",
    "common_path = \"./data/\"\n",
    "\n",
    "# 제출 파일 이름 리스트\n",
    "file_names = [\n",
    "    \"data0827_lgbm.csv\"\n",
    "    , \"data0827_lgbm.csv\"\n",
    "    , \"data0827_xgb.csv\"\n",
    "    , \"data0827_xgb.csv\"\n",
    "    , \"data0827_cat.csv\"\n",
    "    , \"data0827_cat.csv\"\n",
    "    , \"data0827_et.csv\"\n",
    "    , \"data0827_rf.csv\"\n",
    "    , \"data0827_ada.csv\"   \n",
    "    # 파일 추가 가능  <----- 파일 필요시 추가하세요!!\n",
    "]\n",
    "\n",
    "# 경로를 추가하는 함수\n",
    "def add_common_path(file_names, common_path):\n",
    "    return [common_path + file_name for file_name in file_names]\n",
    "\n",
    "# 경로가 추가된 파일 리스트\n",
    "file_paths = add_common_path(file_names, common_path)\n",
    "\n",
    "# 제출 파일에서 예측 결과 읽어오기\n",
    "predictions = read_submission_files(file_paths)\n",
    "\n",
    "# 하드 보팅 결과\n",
    "final_predictions_hard = hard_voting(predictions)\n",
    "\n",
    "# 결과를 새로운 제출 파일로 저장할 파일 이름\n",
    "output_file_name = \"0827_model_name_change_submission.csv\" # <----- 파일 이름을 변경하세요!!\n",
    "\n",
    "# 결과를 새로운 제출 파일로 저장\n",
    "df_sub = pd.read_csv(file_paths[0])\n",
    "df_sub[\"target\"] = final_predictions_hard\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "df_sub.to_csv(output_file_name, index=False)\n",
    "\n",
    "print(f\"최종 제출 파일이 '{output_file_name}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ffa68af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      16874\n",
       "AbNormal      487\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bfc5627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID  target\n",
       "0  0001be084fbc4aaa9d921f39e595961b  Normal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80  Normal\n",
       "2  000948934c4140d883d670adcb609584  Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7  Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95  Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2  Normal\n",
       "6  0020734a7b29472298358ad58645a0c9  Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135  Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  Normal\n",
       "9  002d904240d84b188d410d16383a9c3a  Normal"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d5658",
   "metadata": {},
   "source": [
    "우측 상단의 제출 버튼을 클릭해 결과를 확인하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e7d5f7",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
