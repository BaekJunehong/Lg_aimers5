{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4c41e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==2.1.1 in c:\\users\\kimdongyoung\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\kimdongyoung\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost==2.1.1) (1.26.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kimdongyoung\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost==2.1.1) (1.11.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train_data_0827.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_data_0827.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Receip_No_encoded',\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]\n",
    "\n",
    "# 전체 공통 변수\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a333ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "141cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffec39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be86915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 40\n",
      "train_data_dam DataFrame의 칼럼 수: 23\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 41\n",
      "test_data_dam DataFrame의 칼럼 수: 24\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d288bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af914",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15f2a7",
   "metadata": {},
   "source": [
    "Dam 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c98a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습한 결과:\n",
      "F1 Score: 0.21862348178137653\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7442  220]\n",
      " [ 359   81]]\n",
      "---\n",
      "Accuracy: 0.9285361639101456\n",
      "Precision: 0.2691029900332226\n",
      "Recall: 0.18409090909090908\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Dam = train_and_evaluate_model(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1244\n",
    "    , learning_rate = 0.1258535425769987\n",
    "    , max_depth = 26\n",
    "    , alpha = 2.1820842842359597e-06\n",
    "    , gamma = 0.00010809657684921935\n",
    "    , reg_alpha = 0.5844029076359536\n",
    "    , reg_lambda = 0.4748752246073433\n",
    "    , colsample_bytree = 0.9607659760060685\n",
    "    , subsample = 0.7147741317935203\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b184d",
   "metadata": {},
   "source": [
    "AutoClave 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7cbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
      "F1 Score: 0.24687933425797504\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7470  192]\n",
      " [ 351   89]]\n",
      "---\n",
      "Accuracy: 0.9329795112317946\n",
      "Precision: 0.3167259786476868\n",
      "Recall: 0.20227272727272727\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_AutoClave = train_and_evaluate_model(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1152, \n",
    "    learning_rate = 0.02466611382982541, \n",
    "    max_depth = 29, \n",
    "    alpha = 2.9180083404308157e-05, \n",
    "    gamma = 0.00012667501319666823, \n",
    "    reg_alpha = 0.6903592486292155, \n",
    "    reg_lambda = 0.5638873235014423, \n",
    "    colsample_bytree = 0.9432782030604233, \n",
    "    subsample = 0.19192246128663584,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357e142",
   "metadata": {},
   "source": [
    "Fill1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3a1e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_fill1 데이터로 학습한 결과:\n",
      "F1 Score: 0.20890937019969277\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7519  143]\n",
      " [ 372   68]]\n",
      "---\n",
      "Accuracy: 0.9364354480375215\n",
      "Precision: 0.3222748815165877\n",
      "Recall: 0.15454545454545454\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Fill1 = train_and_evaluate_model(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1899, \n",
    "    learning_rate = 0.011878583548993711, \n",
    "    max_depth = 12, \n",
    "    alpha = 0.004515243354832891,\n",
    "    gamma = 0.0015693650802180896,\n",
    "    reg_alpha = 0.7484424912256998, \n",
    "    reg_lambda = 0.27164326303977143, \n",
    "    colsample_bytree = 0.7901385059430825,\n",
    "    subsample = 0.9924662032617025,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98025a2",
   "metadata": {},
   "source": [
    "Fill2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "274a5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_fill2 데이터로 학습한 결과:\n",
      "F1 Score: 0.21731748726655348\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7577   85]\n",
      " [ 376   64]]\n",
      "---\n",
      "Accuracy: 0.9431004690199951\n",
      "Precision: 0.42953020134228187\n",
      "Recall: 0.14545454545454545\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Fill2 = train_and_evaluate_model(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1162, \n",
    "    learning_rate = 0.014523070494025153, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.00012198482017902725, \n",
    "    gamma = 0.001236902841680112, \n",
    "    reg_alpha = 0.7331637000614692, \n",
    "    reg_lambda = 0.5237223061096699, \n",
    "    colsample_bytree = 0.8250374170841293, \n",
    "    subsample = 0.31906427054137687,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb4d",
   "metadata": {},
   "source": [
    "전체공정 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef6f551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data 데이터로 학습한 결과:\n",
      "F1 Score: 0.2608695652173913\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7542  120]\n",
      " [ 356   84]]\n",
      "---\n",
      "Accuracy: 0.9412490743026414\n",
      "Precision: 0.4117647058823529\n",
      "Recall: 0.19090909090909092\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_All = train_and_evaluate_model(\n",
    "    'xgb', train_data,\n",
    "    n_estimators = 2427,\n",
    "    learning_rate = 0.010774204513905965, \n",
    "    max_depth = 17, \n",
    "    alpha = 0.0005233654110538582, \n",
    "    gamma = 5.551445919277608e-05, \n",
    "    reg_alpha = 0.9652805882189326, \n",
    "    reg_lambda = 0.3542856398135083, \n",
    "    colsample_bytree = 0.9094884645797131, \n",
    "    subsample = 0.1733751790853043,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a59250",
   "metadata": {},
   "source": [
    "soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1d05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.23529411764705888\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7532  130]\n",
      " [ 364   76]]\n",
      "---\n",
      "Accuracy: 0.9390274006418169\n",
      "Precision: 0.36893203883495146\n",
      "Recall: 0.17272727272727273\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 사용 \n",
    "estimators = [\n",
    "      ('dam', train_model_Dam)\n",
    "    , ('autoclave', train_model_AutoClave)\n",
    "    , ('fill1', train_model_Fill1)\n",
    "    , ('fill2', train_model_Fill2)\n",
    "    # , ('all', train_model_All)\n",
    "]\n",
    "\n",
    "# VotingClassifier 학습 및 평가\n",
    "# voting_clf_hard = voting_function(train_data, estimators, voting='hard')\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2bb2eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.22950819672131145\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7508  154]\n",
      " [ 363   77]]\n",
      "---\n",
      "Accuracy: 0.936188595408541\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.175\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e907e055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.22544283413848631\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7551  111]\n",
      " [ 370   70]]\n",
      "---\n",
      "Accuracy: 0.9406319427301901\n",
      "Precision: 0.3867403314917127\n",
      "Recall: 0.1590909090909091\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d329d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e3ad24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "### 모델 학습(train 데이터 전체 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa25b4",
   "metadata": {},
   "source": [
    "위의 모델학습 코드에서 함수명만 바뀌고 들어가는 값들은 동일  \n",
    "-> 위의 코드 복붙한다음 함수명만 바꿔주면 사용하기 편함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c08dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습 완료\n",
      "xgb 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill1 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill2 데이터로 학습 완료\n",
      "xgb 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1244\n",
    "    , learning_rate = 0.1258535425769987\n",
    "    , max_depth = 26\n",
    "    , alpha = 2.1820842842359597e-06\n",
    "    , gamma = 0.00010809657684921935\n",
    "    , reg_alpha = 0.5844029076359536\n",
    "    , reg_lambda = 0.4748752246073433\n",
    "    , colsample_bytree = 0.9607659760060685\n",
    "    , subsample = 0.7147741317935203\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1152, \n",
    "    learning_rate = 0.02466611382982541, \n",
    "    max_depth = 29, \n",
    "    alpha = 2.9180083404308157e-05, \n",
    "    gamma = 0.00012667501319666823, \n",
    "    reg_alpha = 0.6903592486292155, \n",
    "    reg_lambda = 0.5638873235014423, \n",
    "    colsample_bytree = 0.9432782030604233, \n",
    "    subsample = 0.19192246128663584,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1899, \n",
    "    learning_rate = 0.011878583548993711, \n",
    "    max_depth = 12, \n",
    "    alpha = 0.004515243354832891,\n",
    "    gamma = 0.0015693650802180896,\n",
    "    reg_alpha = 0.7484424912256998, \n",
    "    reg_lambda = 0.27164326303977143, \n",
    "    colsample_bytree = 0.7901385059430825,\n",
    "    subsample = 0.9924662032617025,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1162, \n",
    "    learning_rate = 0.014523070494025153, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.00012198482017902725, \n",
    "    gamma = 0.001236902841680112, \n",
    "    reg_alpha = 0.7331637000614692, \n",
    "    reg_lambda = 0.5237223061096699, \n",
    "    colsample_bytree = 0.8250374170841293, \n",
    "    subsample = 0.31906427054137687,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "# 'xgb', train_data,\n",
    "#     n_estimators = 2427,\n",
    "#     learning_rate = 0.010774204513905965, \n",
    "#     max_depth = 17, \n",
    "#     alpha = 0.0005233654110538582, \n",
    "#     gamma = 5.551445919277608e-05, \n",
    "#     reg_alpha = 0.9652805882189326, \n",
    "#     reg_lambda = 0.3542856398135083, \n",
    "#     colsample_bytree = 0.9094884645797131, \n",
    "#     subsample = 0.1733751790853043,\n",
    "#     objective = 'binary:logistic',  # 이진 분류\n",
    "#     tree_method = \"exact\", \n",
    "#     random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8b158",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee55c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d855e",
   "metadata": {},
   "source": [
    "Voting(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98f3e1",
   "metadata": {},
   "source": [
    "4개의 모델중 다수의 모델이 판단한 값을 타겟값으로 가져감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c7f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측 리스트 (하드 보팅용)\n",
    "# preds = [\n",
    "#     model_Dam.predict(x_test_dam)\n",
    "#     , model_AutoClave.predict(x_test_autoclave)\n",
    "#     , model_Fill1.predict(x_test_fill1)\n",
    "#     , model_Fill2.predict(x_test_fill2)\n",
    "#     , model_All.predict(x_test_all)\n",
    "# ]\n",
    "\n",
    "# # 하드 보팅 결과\n",
    "# final_predictions = voting(preds, method='hard')\n",
    "# print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287a3c3",
   "metadata": {},
   "source": [
    "Voting(soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a4ed1",
   "metadata": {},
   "source": [
    "4개의 모델의 확률의 합에 대한 평균이 일정 수치(스레스홀드) 값을 넘으면 AbNormal 값을 가짐  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5151edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    # , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n",
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.3)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d825264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.28)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc7b86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.26)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ac35926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.24)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170f013",
   "metadata": {},
   "source": [
    "=== Message ===\n",
    "\n",
    "작성하신 답안 제출이 완료되었습니다.\n",
    "\n",
    "Public Score : 0.22973"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"./data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"Data0827_xgb(4)_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9efee1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8a8f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b240214",
   "metadata": {},
   "source": [
    "## 5. ETC..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899379df",
   "metadata": {},
   "source": [
    "모델을 통해 예측해 낸 정답지(csv) 파일의 결과값을 불러와 voting 하는 방식  \n",
    "이때의 voting은 hard방식만 가능(예측확률은 저장되어있지 않음으로 soft 보팅은 불가능)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03053beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def read_submission_files(file_paths):\n",
    "#     \"\"\"\n",
    "#     제출 파일을 읽어와서 예측 결과를 반환합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     file_paths (list of str): 제출 파일 경로 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     list of np.array: 각 제출 파일의 예측 결과 리스트\n",
    "#     \"\"\"\n",
    "#     predictions = []\n",
    "#     for file_path in file_paths:\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         preds = df['target'].apply(lambda x: 1 if x == 'AbNormal' else 0).values\n",
    "#         predictions.append(preds)\n",
    "#     return predictions\n",
    "\n",
    "# def hard_voting(preds):\n",
    "#     \"\"\"\n",
    "#     하드 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     preds (list of np.array): 각 모델의 예측 배열 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: 최종 예측 결과\n",
    "#     \"\"\"\n",
    "#     preds = np.array(preds)\n",
    "#     final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "#     return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae7de4",
   "metadata": {},
   "source": [
    "submission_file 에서 csv 파일을 불러와 hard voting 하는 알고리즘  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d98d36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 공통 경로\n",
    "# common_path = \"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/submission_file/\"\n",
    "\n",
    "# # 제출 파일 이름 리스트\n",
    "# file_names = [\n",
    "#     \"data0816_light_cutoff0.28_submission.csv\",\n",
    "#     \"submission_score0.23.csv\"\n",
    "#     # 파일 추가 가능  <----- 파일 필요시 추가하세요!!\n",
    "# ]\n",
    "\n",
    "# # 경로를 추가하는 함수\n",
    "# def add_common_path(file_names, common_path):\n",
    "#     return [common_path + file_name for file_name in file_names]\n",
    "\n",
    "# # 경로가 추가된 파일 리스트\n",
    "# file_paths = add_common_path(file_names, common_path)\n",
    "\n",
    "# # 제출 파일에서 예측 결과 읽어오기\n",
    "# predictions = read_submission_files(file_paths)\n",
    "\n",
    "# # 하드 보팅 결과\n",
    "# final_predictions_hard = hard_voting(predictions)\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장할 파일 이름\n",
    "# output_file_name = \"final_submission.csv\" # <----- 파일 이름을 변경하세요!!\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장\n",
    "# df_sub = pd.read_csv(file_paths[0])\n",
    "# df_sub[\"target\"] = final_predictions_hard\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "# df_sub.to_csv(output_file_name, index=False)\n",
    "\n",
    "# print(f\"최종 제출 파일이 '{output_file_name}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d826211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2138cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
