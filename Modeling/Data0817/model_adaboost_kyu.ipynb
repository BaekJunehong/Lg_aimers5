{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"train_data_0817.csv\")\n",
    "test_data = pd.read_csv(\"test_data_0817.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd7eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ffec39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be86915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 38\n",
      "train_data_dam DataFrame의 칼럼 수: 21\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 13\n",
      "train_data_fill2 DataFrame의 칼럼 수: 13\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 39\n",
      "test_data_dam DataFrame의 칼럼 수: 22\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 14\n",
      "test_data_fill2 DataFrame의 칼럼 수: 14\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d288bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af914",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15f2a7",
   "metadata": {},
   "source": [
    "Dam 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c98a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습한 결과:\n",
      "F1 Score: 0.1781818181818182\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7601   43]\n",
      " [ 409   49]]\n",
      "---\n",
      "Accuracy: 0.9442113058504074\n",
      "Precision: 0.532608695652174\n",
      "Recall: 0.10698689956331878\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=22,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.9449544624225188,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Dam = train_and_evaluate_model(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=439\n",
    "    , learning_rate=0.30985993372769294\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b184d",
   "metadata": {},
   "source": [
    "AutoClave 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7cbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
      "F1 Score: 0.1627006087437742\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[4782 2862]\n",
      " [ 164  294]]\n",
      "---\n",
      "Accuracy: 0.6265119723525056\n",
      "Precision: 0.09315589353612168\n",
      "Recall: 0.6419213973799127\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=34,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=0.7473309094470472,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_AutoClave = train_and_evaluate_model(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=570\n",
    "    , learning_rate=0.2040105705276999\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357e142",
   "metadata": {},
   "source": [
    "Fill1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a1e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill1 데이터로 학습한 결과:\n",
      "F1 Score: 0.17503217503217502\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7393  251]\n",
      " [ 390   68]]\n",
      "---\n",
      "Accuracy: 0.9208837324117501\n",
      "Precision: 0.21316614420062696\n",
      "Recall: 0.14847161572052403\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=14,\n",
    "    min_samples_split=33,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.7113128413756866,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill1 = train_and_evaluate_model(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=913\n",
    "    , learning_rate=0.055237331816147595\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98025a2",
   "metadata": {},
   "source": [
    "Fill2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274a5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill2 데이터로 학습한 결과:\n",
      "F1 Score: 0.12788461538461537\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[2261 5383]\n",
      " [  59  399]]\n",
      "---\n",
      "Accuracy: 0.3283139965440632\n",
      "Precision: 0.06900726392251816\n",
      "Recall: 0.87117903930131\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=7,\n",
    "    min_samples_split=13,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6266118401157937,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_Fill2 = train_and_evaluate_model(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=293\n",
    "    , learning_rate=0.620377973483163\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb4d",
   "metadata": {},
   "source": [
    "전체공정 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6f551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data 데이터로 학습한 결과:\n",
      "F1 Score: 0.11603131818765242\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[ 763 6881]\n",
      " [   6  452]]\n",
      "---\n",
      "Accuracy: 0.14996297210565293\n",
      "Precision: 0.06163916541660985\n",
      "Recall: 0.9868995633187773\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    min_samples_split=28,\n",
    "    min_samples_leaf=7,\n",
    "    max_features=0.7331591188366589,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_model_All = train_and_evaluate_model(\n",
    "    'ada', train_data\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=677\n",
    "    , learning_rate=0.6713565955468803\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a59250",
   "metadata": {},
   "source": [
    "soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1d05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.17418351477449456\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7515  129]\n",
      " [ 402   56]]\n",
      "---\n",
      "Accuracy: 0.9344606270056776\n",
      "Precision: 0.3027027027027027\n",
      "Recall: 0.1222707423580786\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 사용 \n",
    "estimators = [\n",
    "    ('dam', train_model_Dam)\n",
    "    , ('autoclave', train_model_AutoClave)\n",
    "    , ('fill1', train_model_Fill1)\n",
    "    , ('fill2', train_model_Fill2)\n",
    "    , ('all', train_model_All)\n",
    "]\n",
    "\n",
    "# VotingClassifier 학습 및 평가\n",
    "# voting_clf_hard = voting_function(train_data, estimators, voting='hard')\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d54a92a8-64ae-4b78-a2af-e9e563c3cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.18114143920595532\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7369  275]\n",
      " [ 385   73]]\n",
      "---\n",
      "Accuracy: 0.9185386324364354\n",
      "Precision: 0.20977011494252873\n",
      "Recall: 0.15938864628820962\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f23c02e-f3e5-41cf-8990-ff9583d58da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.18915159944367177\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7451  193]\n",
      " [ 390   68]]\n",
      "---\n",
      "Accuracy: 0.9280424586521846\n",
      "Precision: 0.26053639846743293\n",
      "Recall: 0.14847161572052403\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14428afe-89f2-43a2-8e08-9ef7e8890d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.19089574155653452\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7486  158]\n",
      " [ 393   65]]\n",
      "---\n",
      "Accuracy: 0.9319921007158726\n",
      "Precision: 0.2914798206278027\n",
      "Recall: 0.14192139737991266\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b439ce62-fc48-4423-b9ef-412120e3f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier로 학습한 결과:\n",
      "F1 Score: 0.15815485996705106\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7543  101]\n",
      " [ 410   48]]\n",
      "---\n",
      "Accuracy: 0.9369291532954825\n",
      "Precision: 0.3221476510067114\n",
      "Recall: 0.10480349344978165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VotingClassifier 학습 및 평가\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "### 모델 학습(train 데이터 전체 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa25b4",
   "metadata": {},
   "source": [
    "위의 모델학습 코드에서 함수명만 바뀌고 들어가는 값들은 동일  \n",
    "-> 위의 코드 복붙한다음 함수명만 바꿔주면 사용하기 편함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39c08dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_dam 데이터로 학습 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_autoclave 데이터로 학습 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill1 데이터로 학습 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoboy22/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=22,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=0.9449544624225188,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Dam = fit_all_train_data_function(\n",
    "    'ada', train_data_dam\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=439\n",
    "    , learning_rate=0.30985993372769294\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=13,\n",
    "    min_samples_split=34,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=0.7473309094470472,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'ada', train_data_autoclave\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=570\n",
    "    , learning_rate=0.2040105705276999\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=14,\n",
    "    min_samples_split=33,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.7113128413756866,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill1\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=913\n",
    "    , learning_rate=0.055237331816147595\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=7,\n",
    "    min_samples_split=13,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=0.6266118401157937,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'ada', train_data_fill2\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=293\n",
    "    , learning_rate=0.620377973483163\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(\n",
    "    max_depth=6,\n",
    "    min_samples_split=28,\n",
    "    min_samples_leaf=7,\n",
    "    max_features=0.7331591188366589,\n",
    "    # n_estimators=517,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'ada', train_data\n",
    "    , estimator=base_estimator\n",
    "    , n_estimators=677\n",
    "    , learning_rate=0.6713565955468803\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8b158",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ee55c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a08e10-1df1-4a99-ae66-f0f1940b1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dam.fillna(0, inplace=True)\n",
    "x_test_autoclave.fillna(0, inplace=True)\n",
    "x_test_fill1.fillna(0, inplace=True)\n",
    "x_test_fill2.fillna(0, inplace=True)\n",
    "x_test_all.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d855e",
   "metadata": {},
   "source": [
    "Voting(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98f3e1",
   "metadata": {},
   "source": [
    "4개의 모델중 다수의 모델이 판단한 값을 타겟값으로 가져감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c7f911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 예측 리스트 (하드 보팅용)\\npreds = [\\n    model_Dam.predict(x_test_dam)\\n    , model_AutoClave.predict(x_test_autoclave)\\n    , model_Fill1.predict(x_test_fill1)\\n    , model_Fill2.predict(x_test_fill2)\\n    # , model_All.predict(x_test_all)\\n]\\n\\n# 하드 보팅 결과\\nfinal_predictions = voting(preds, method='hard')\\nprint(sum(final_predictions))\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 예측 리스트 (하드 보팅용)\n",
    "preds = [\n",
    "    model_Dam.predict(x_test_dam)\n",
    "    , model_AutoClave.predict(x_test_autoclave)\n",
    "    , model_Fill1.predict(x_test_fill1)\n",
    "    , model_Fill2.predict(x_test_fill2)\n",
    "    # , model_All.predict(x_test_all)\n",
    "]\n",
    "\n",
    "# 하드 보팅 결과\n",
    "final_predictions = voting(preds, method='hard')\n",
    "print(sum(final_predictions))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287a3c3",
   "metadata": {},
   "source": [
    "Voting(soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a4ed1",
   "metadata": {},
   "source": [
    "4개의 모델의 확률의 합에 대한 평균이 일정 수치(스레스홀드) 값을 넘으면 AbNormal 값을 가짐  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5151edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n",
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.3)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cf207",
   "metadata": {},
   "source": [
    "=== Message ===\n",
    "\n",
    "작성하신 답안 제출이 완료되었습니다.\n",
    "\n",
    "Public Score : 0.19908814"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      15761\n",
       "AbNormal     1600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9efee1fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>AbNormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID    target\n",
       "0  0001be084fbc4aaa9d921f39e595961b  AbNormal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80    Normal\n",
       "2  000948934c4140d883d670adcb609584    Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7    Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95    Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2    Normal\n",
       "6  0020734a7b29472298358ad58645a0c9    Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135    Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  AbNormal\n",
       "9  002d904240d84b188d410d16383a9c3a    Normal"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5eccc7",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
