{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "570f8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/train_data_0817.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/test_data_0817.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fcef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6619bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2e311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df3b81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb5b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af8da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a82ed5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 38\n",
      "train_data_dam DataFrame의 칼럼 수: 21\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 13\n",
      "train_data_fill2 DataFrame의 칼럼 수: 13\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 39\n",
      "test_data_dam DataFrame의 칼럼 수: 22\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 14\n",
      "test_data_fill2 DataFrame의 칼럼 수: 14\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "# train_data_autoclave['target'] = train_data_autoclave['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# # 스레드홀드 설정\n",
    "# THRESHOLD = 0.3\n",
    "\n",
    "\n",
    "# def objectiveXGB(trial, x_tr, y_tr, x_val, y_val):\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1200, 3200)\n",
    "#         , 'learning_rate': trial.suggest_float('learning_rate', 0.002, 0.2)\n",
    "#         , 'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "#         , 'alpha': trial.suggest_float('alpha', 0.00001, 0.01, log=True)\n",
    "#         , 'gamma': trial.suggest_float('gamma', 0.00001, 0.01, log=True)\n",
    "\n",
    "#         , 'reg_alpha' : trial.suggest_float('reg_alpha', 0.01, 1)\n",
    "#         , 'reg_lambda' : trial.suggest_float('reg_lambda', 0.01, 1)\n",
    "        \n",
    "#         , 'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.01, 1)\n",
    "#         , 'subsample' : trial.suggest_float('subsample', 0.03, 1)\n",
    "#         , 'objective': 'binary:logistic'  # 이진 분류\n",
    "#         , 'tree_method' : \"exact\"        \n",
    "#         , 'random_state': RANDOM_STATE\n",
    "#     }\n",
    "       \n",
    "#     model = XGBClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data_autoclave.drop(\"target\", axis=1),\n",
    "#     train_data_autoclave[\"target\"],\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveXGB(trial, x_train, y_train, x_val, y_val), n_trials=400)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151be8c",
   "metadata": {},
   "source": [
    "Best trial: score 0.25604551920341395\n",
    "\n",
    "params {'n_estimators': 1707, 'learning_rate': 0.0321470219836192, 'max_depth': 7, 'alpha': 7.368872823521818e-05, 'gamma': 0.0007930035188326916, 'reg_alpha': 0.644199314174124, 'reg_lambda': 0.588270569327407, 'colsample_bytree': 0.883929103208459, 'subsample': 0.2534703342501092}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f3fc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name]\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e257145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
      "F1 Score: 0.24411764705882352\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7505  157]\n",
      " [ 357   83]]\n",
      "---\n",
      "Accuracy: 0.9365588743520118\n",
      "Precision: 0.3458333333333333\n",
      "Recall: 0.18863636363636363\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1707, \n",
    "    learning_rate = 0.0321470219836192, \n",
    "    max_depth = 7, \n",
    "    alpha = 7.368872823521818e-05, \n",
    "    gamma = 0.0007930035188326916, \n",
    "    reg_alpha = 0.644199314174124, \n",
    "    reg_lambda = 0.588270569327407, \n",
    "    colsample_bytree = 0.883929103208459, \n",
    "    subsample = 0.2534703342501092,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75d3b0",
   "metadata": {},
   "source": [
    "xgb 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
    "F1 Score: 0.24411764705882352"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc88d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
