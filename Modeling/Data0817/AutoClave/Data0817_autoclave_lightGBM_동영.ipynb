{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10de8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/train_data_0817.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/test_data_0817.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84efc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d32b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442983c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e9739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f043481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b7b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746f1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 38\n",
      "train_data_dam DataFrame의 칼럼 수: 21\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 13\n",
      "train_data_fill2 DataFrame의 칼럼 수: 13\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 39\n",
      "test_data_dam DataFrame의 칼럼 수: 22\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 14\n",
      "test_data_fill2 DataFrame의 칼럼 수: 14\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimDongyoung\\AppData\\Local\\Temp\\ipykernel_15816\\1825128303.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_autoclave['target'] = train_data_autoclave['target'].map({'Normal': 0, 'AbNormal': 1})\n",
      "[I 2024-08-20 15:08:12,891] A new study created in memory with name: no-name-9ed389be-38c5-405c-ac7e-bf9e04264412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 15:08:39,661] Trial 0 finished with value: 0.1923714759535655 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.1923714759535655.\n",
      "[I 2024-08-20 15:12:11,831] Trial 1 finished with value: 0.18126272912423624 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 0 with value: 0.1923714759535655.\n",
      "[I 2024-08-20 15:13:03,344] Trial 2 finished with value: 0.20860495436766624 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 2 with value: 0.20860495436766624.\n",
      "[I 2024-08-20 15:14:07,434] Trial 3 finished with value: 0.16666666666666669 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 2 with value: 0.20860495436766624.\n",
      "[I 2024-08-20 15:15:06,400] Trial 4 finished with value: 0.218091697645601 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 4 with value: 0.218091697645601.\n",
      "[I 2024-08-20 15:15:25,731] Trial 5 finished with value: 0.22255192878338279 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:18:35,388] Trial 6 finished with value: 0.18108651911468815 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:20:27,939] Trial 7 finished with value: 0.20761245674740483 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:22:12,084] Trial 8 finished with value: 0.1851851851851852 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:22:24,701] Trial 9 finished with value: 0.16417910447761194 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:22:59,292] Trial 10 finished with value: 0.18571428571428572 and parameters: {'n_estimators': 1010, 'num_leaves': 1104, 'max_depth': 286, 'learning_rate': 0.03483524235844172, 'min_child_samples': 190}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:25:29,207] Trial 11 finished with value: 0.18575851393188852 and parameters: {'n_estimators': 1047, 'num_leaves': 2985, 'max_depth': 300, 'learning_rate': 0.040338453467110603, 'min_child_samples': 8}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:25:44,491] Trial 12 finished with value: 0.17915904936014623 and parameters: {'n_estimators': 535, 'num_leaves': 1405, 'max_depth': 239, 'learning_rate': 0.03161674828966635, 'min_child_samples': 106}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:27:58,215] Trial 13 finished with value: 0.21317365269461078 and parameters: {'n_estimators': 2922, 'num_leaves': 2607, 'max_depth': 234, 'learning_rate': 0.05157600011836352, 'min_child_samples': 212}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:28:58,450] Trial 14 finished with value: 0.21437908496732028 and parameters: {'n_estimators': 1253, 'num_leaves': 1783, 'max_depth': 132, 'learning_rate': 0.06917770034003733, 'min_child_samples': 166}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:29:34,865] Trial 15 finished with value: 0.16845878136200718 and parameters: {'n_estimators': 857, 'num_leaves': 902, 'max_depth': 210, 'learning_rate': 0.021286247942479245, 'min_child_samples': 97}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:31:21,693] Trial 16 finished with value: 0.20537897310513448 and parameters: {'n_estimators': 1929, 'num_leaves': 2008, 'max_depth': 265, 'learning_rate': 0.045199108304042376, 'min_child_samples': 147}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:32:05,421] Trial 17 finished with value: 0.14258188824662815 and parameters: {'n_estimators': 1309, 'num_leaves': 1652, 'max_depth': 12, 'learning_rate': 0.025827793874381135, 'min_child_samples': 263}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:32:46,338] Trial 18 finished with value: 0.1959910913140312 and parameters: {'n_estimators': 759, 'num_leaves': 2602, 'max_depth': 150, 'learning_rate': 0.05630759019570967, 'min_child_samples': 50}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:34:51,533] Trial 19 finished with value: 0.19395203336809175 and parameters: {'n_estimators': 1864, 'num_leaves': 1630, 'max_depth': 266, 'learning_rate': 0.07201988843509977, 'min_child_samples': 87}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:36:07,734] Trial 20 finished with value: 0.18238993710691825 and parameters: {'n_estimators': 1144, 'num_leaves': 871, 'max_depth': 91, 'learning_rate': 0.09913196298727578, 'min_child_samples': 3}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:37:05,326] Trial 21 finished with value: 0.2090322580645161 and parameters: {'n_estimators': 1311, 'num_leaves': 1440, 'max_depth': 146, 'learning_rate': 0.06777093772662052, 'min_child_samples': 160}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:38:23,597] Trial 22 finished with value: 0.20047732696897375 and parameters: {'n_estimators': 1553, 'num_leaves': 1935, 'max_depth': 125, 'learning_rate': 0.07693446206523272, 'min_child_samples': 171}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:39:25,295] Trial 23 finished with value: 0.2027534418022528 and parameters: {'n_estimators': 1253, 'num_leaves': 2575, 'max_depth': 212, 'learning_rate': 0.058500254576989014, 'min_child_samples': 129}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:39:52,101] Trial 24 finished with value: 0.17247706422018347 and parameters: {'n_estimators': 867, 'num_leaves': 1706, 'max_depth': 87, 'learning_rate': 0.043298115092161034, 'min_child_samples': 239}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:41:27,966] Trial 25 finished with value: 0.1941747572815534 and parameters: {'n_estimators': 1644, 'num_leaves': 2139, 'max_depth': 168, 'learning_rate': 0.08145867327444366, 'min_child_samples': 110}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:41:50,327] Trial 26 finished with value: 0.18918918918918917 and parameters: {'n_estimators': 651, 'num_leaves': 1451, 'max_depth': 217, 'learning_rate': 0.047009374131657775, 'min_child_samples': 144}. Best is trial 5 with value: 0.22255192878338279.\n",
      "[I 2024-08-20 15:43:17,070] Trial 27 finished with value: 0.2231292517006803 and parameters: {'n_estimators': 2000, 'num_leaves': 2792, 'max_depth': 141, 'learning_rate': 0.03594768881913926, 'min_child_samples': 172}. Best is trial 27 with value: 0.2231292517006803.\n",
      "[I 2024-08-20 15:45:10,746] Trial 28 finished with value: 0.20689655172413796 and parameters: {'n_estimators': 2624, 'num_leaves': 2803, 'max_depth': 96, 'learning_rate': 0.03681115490994363, 'min_child_samples': 184}. Best is trial 27 with value: 0.2231292517006803.\n",
      "[I 2024-08-20 15:46:04,961] Trial 29 finished with value: 0.20602218700475436 and parameters: {'n_estimators': 1992, 'num_leaves': 2378, 'max_depth': 264, 'learning_rate': 0.02808809869301697, 'min_child_samples': 211}. Best is trial 27 with value: 0.2231292517006803.\n",
      "[I 2024-08-20 15:47:50,876] Trial 30 finished with value: 0.19382321618743345 and parameters: {'n_estimators': 2065, 'num_leaves': 2771, 'max_depth': 191, 'learning_rate': 0.016710037398694512, 'min_child_samples': 32}. Best is trial 27 with value: 0.2231292517006803.\n",
      "[I 2024-08-20 15:48:48,214] Trial 31 finished with value: 0.21124828532235937 and parameters: {'n_estimators': 1819, 'num_leaves': 2084, 'max_depth': 138, 'learning_rate': 0.06012623137474468, 'min_child_samples': 236}. Best is trial 27 with value: 0.2231292517006803.\n",
      "[I 2024-08-20 15:49:37,213] Trial 32 finished with value: 0.22598870056497175 and parameters: {'n_estimators': 1400, 'num_leaves': 2261, 'max_depth': 104, 'learning_rate': 0.05177074594683166, 'min_child_samples': 170}. Best is trial 32 with value: 0.22598870056497175.\n",
      "[I 2024-08-20 15:51:23,957] Trial 33 finished with value: 0.2013729977116705 and parameters: {'n_estimators': 2148, 'num_leaves': 2453, 'max_depth': 103, 'learning_rate': 0.04715106136148795, 'min_child_samples': 139}. Best is trial 32 with value: 0.22598870056497175.\n",
      "[I 2024-08-20 15:52:31,263] Trial 34 finished with value: 0.19657142857142856 and parameters: {'n_estimators': 1658, 'num_leaves': 2250, 'max_depth': 58, 'learning_rate': 0.05392163893959906, 'min_child_samples': 114}. Best is trial 32 with value: 0.22598870056497175.\n",
      "[I 2024-08-20 15:53:13,666] Trial 35 finished with value: 0.22839506172839508 and parameters: {'n_estimators': 1432, 'num_leaves': 2708, 'max_depth': 166, 'learning_rate': 0.04003157876822068, 'min_child_samples': 184}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:53:56,416] Trial 36 finished with value: 0.215962441314554 and parameters: {'n_estimators': 1469, 'num_leaves': 2730, 'max_depth': 168, 'learning_rate': 0.0356489006836591, 'min_child_samples': 183}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:55:01,138] Trial 37 finished with value: 0.1955403087478559 and parameters: {'n_estimators': 2369, 'num_leaves': 2912, 'max_depth': 111, 'learning_rate': 0.01427760097670723, 'min_child_samples': 196}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:56:26,570] Trial 38 finished with value: 0.2167741935483871 and parameters: {'n_estimators': 2622, 'num_leaves': 2663, 'max_depth': 30, 'learning_rate': 0.05022239438612429, 'min_child_samples': 221}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:57:35,057] Trial 39 finished with value: 0.2031063321385902 and parameters: {'n_estimators': 1734, 'num_leaves': 2502, 'max_depth': 80, 'learning_rate': 0.06358496957002802, 'min_child_samples': 160}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:58:14,411] Trial 40 finished with value: 0.191904047976012 and parameters: {'n_estimators': 1073, 'num_leaves': 2303, 'max_depth': 73, 'learning_rate': 0.0034143468752438483, 'min_child_samples': 175}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 15:59:56,858] Trial 41 finished with value: 0.19683257918552033 and parameters: {'n_estimators': 1415, 'num_leaves': 2863, 'max_depth': 159, 'learning_rate': 0.04005744782317339, 'min_child_samples': 72}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:00:49,970] Trial 42 finished with value: 0.19791666666666666 and parameters: {'n_estimators': 932, 'num_leaves': 2265, 'max_depth': 184, 'learning_rate': 0.030727733910443075, 'min_child_samples': 127}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:02:40,152] Trial 43 finished with value: 0.20023282887077998 and parameters: {'n_estimators': 1596, 'num_leaves': 2944, 'max_depth': 109, 'learning_rate': 0.04055600984109543, 'min_child_samples': 95}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:04:32,821] Trial 44 finished with value: 0.1945945945945946 and parameters: {'n_estimators': 1387, 'num_leaves': 686, 'max_depth': 177, 'learning_rate': 0.050272116214893844, 'min_child_samples': 63}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:05:21,239] Trial 45 finished with value: 0.20069204152249134 and parameters: {'n_estimators': 1159, 'num_leaves': 2649, 'max_depth': 201, 'learning_rate': 0.03409586629360753, 'min_child_samples': 199}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:08:58,632] Trial 46 finished with value: 0.1900739176346357 and parameters: {'n_estimators': 2187, 'num_leaves': 2509, 'max_depth': 158, 'learning_rate': 0.024503596804621657, 'min_child_samples': 44}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:09:27,152] Trial 47 finished with value: 0.18962432915921287 and parameters: {'n_estimators': 659, 'num_leaves': 1122, 'max_depth': 230, 'learning_rate': 0.04074014430550599, 'min_child_samples': 136}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:11:16,275] Trial 48 finished with value: 0.20807833537331702 and parameters: {'n_estimators': 1807, 'num_leaves': 1937, 'max_depth': 118, 'learning_rate': 0.05454015192498642, 'min_child_samples': 158}. Best is trial 35 with value: 0.22839506172839508.\n",
      "[I 2024-08-20 16:13:49,535] Trial 49 finished with value: 0.19334049409237378 and parameters: {'n_estimators': 1956, 'num_leaves': 2348, 'max_depth': 135, 'learning_rate': 0.04603552484806058, 'min_child_samples': 81}. Best is trial 35 with value: 0.22839506172839508.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.22839506172839508, \n",
      "params {'n_estimators': 1432, 'num_leaves': 2708, 'max_depth': 166, 'learning_rate': 0.04003157876822068, 'min_child_samples': 184}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_autoclave['target'] = train_data_autoclave['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_autoclave.drop(\"target\", axis=1),\n",
    "    train_data_autoclave[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=50)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a624db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name]\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "554d68ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_autoclave\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1707\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0321470219836192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7.368872823521818e-05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0007930035188326916\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreg_alpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.644199314174124\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreg_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.588270569327407\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolsample_bytree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.883929103208459\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2534703342501092\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 35\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model_name, data, **params)\u001b[0m\n\u001b[0;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\u001b[39;00m\n\u001b[0;32m     38\u001b[0m data_name \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;129;01mis\u001b[39;00m data][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\KimDongyoung\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KimDongyoung\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [nan]"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1707, \n",
    "    learning_rate = 0.0321470219836192, \n",
    "    max_depth = 7, \n",
    "    alpha = 7.368872823521818e-05, \n",
    "    gamma = 0.0007930035188326916, \n",
    "    reg_alpha = 0.644199314174124, \n",
    "    reg_lambda = 0.588270569327407, \n",
    "    colsample_bytree = 0.883929103208459, \n",
    "    subsample = 0.2534703342501092,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc88d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
