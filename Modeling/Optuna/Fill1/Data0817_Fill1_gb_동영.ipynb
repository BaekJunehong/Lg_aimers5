{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5cd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "def get_clf_eval(y_test, y_pred_proba, threshold=0.5):\n",
    "    # 확률을 기준으로 예측 레이블 생성\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)  # 0.5 이상의 확률을 양성으로 간주\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03981606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "## --- 해당하는 데이터로 변경해주기!! --- ##\n",
    "train_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/train_data_0817.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/test_data_0817.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d13d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3803747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207e8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c666baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f6c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f031d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 3. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e56224",
   "metadata": {},
   "source": [
    "### optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc134a0",
   "metadata": {},
   "source": [
    "1. lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a75b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "#         'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "#         'boosting_type': 'dart', \n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         'verbose': -1\n",
    "#     }\n",
    "       \n",
    "#     model = LGBMClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1), # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],              # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa857a77",
   "metadata": {},
   "source": [
    "2. xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab290efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveXGB(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1200, 3200)\n",
    "#         , 'learning_rate': trial.suggest_float('learning_rate', 0.002, 0.2)\n",
    "#         , 'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "\n",
    "#         , 'alpha': trial.suggest_float('alpha', 0.00001, 0.01, log=True)\n",
    "#         , 'gamma': trial.suggest_float('gamma', 0.00001, 0.01, log=True)\n",
    "\n",
    "#         , 'reg_alpha' : trial.suggest_float('reg_alpha', 0.01, 1)\n",
    "#         , 'reg_lambda' : trial.suggest_float('reg_lambda', 0.01, 1)\n",
    "        \n",
    "#         , 'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.01, 1)\n",
    "#         , 'subsample' : trial.suggest_float('subsample', 0.03, 1)\n",
    "#         , 'objective': 'binary:logistic'  \n",
    "#         , 'tree_method' : \"exact\"        \n",
    "#         , 'random_state': RANDOM_STATE\n",
    "#     }\n",
    "       \n",
    "#     model = XGBClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),  # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],               # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveXGB(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef424b5",
   "metadata": {},
   "source": [
    "3. catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9a82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveCatBoost(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "#     param = {\n",
    "#         'iterations': trial.suggest_int('iterations', 400, 1500),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.4),\n",
    "#         'depth': trial.suggest_int('depth', 3, 14),\n",
    "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.05, 5.0, log=True),\n",
    "#         'random_strength': trial.suggest_float('random_strength', 0.1, 10.0),\n",
    "#         'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 10.0),\n",
    "#         'border_count': trial.suggest_int('border_count', 70, 270),\n",
    "#         'scale_pos_weight': trial.suggest_float('scale_pos_weight', 0.5, 1.2),\n",
    "\n",
    "#         'random_seed': RANDOM_STATE,\n",
    "#         'eval_metric': 'F1',\n",
    "#         'logging_level': 'Silent',\n",
    "#         'boosting_type': 'Plain'\n",
    "#     }\n",
    "\n",
    "#     model = CatBoostClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),  # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],               # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveCatBoost(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b26796",
   "metadata": {},
   "source": [
    "4. randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a92217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveRandomForestClassifier(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1000, 2500)\n",
    "#         , 'max_depth': trial.suggest_int('max_depth', 2, 50)\n",
    "#         , 'min_samples_split': trial.suggest_int('min_samples_split', 2, 12)\n",
    "#         , 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 7)\n",
    "#         , 'criterion': trial.suggest_categorical('criterion', ['entropy'])\n",
    "#         , 'bootstrap': trial.suggest_categorical('bootstrap', [False])\n",
    "#         , 'random_state': RANDOM_STATE\n",
    "#     }\n",
    "    \n",
    "#     model = RandomForestClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),  # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],               # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveRandomForestClassifier(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04b824",
   "metadata": {},
   "source": [
    "5. extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80be75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def objectiveExtraTreesClassifier(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 1000, 2500)\n",
    "#         , 'max_depth': trial.suggest_int('max_depth', 2, 50)\n",
    "#         , 'min_samples_split': trial.suggest_int('min_samples_split', 2, 12)\n",
    "#         , 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 7)\n",
    "#         , 'criterion': trial.suggest_categorical('criterion', ['entropy'])\n",
    "#         , 'bootstrap': trial.suggest_categorical('bootstrap', [False])\n",
    "#         , 'random_state': RANDOM_STATE\n",
    "#     }\n",
    "    \n",
    "#     model = ExtraTreesClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),  # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],               # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveExtraTreesClassifier(trial, x_train, y_train, x_val, y_val), n_trials=400)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238c03b",
   "metadata": {},
   "source": [
    "6. adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ca6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveAdaBoost(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "#     # Base Estimator 설정\n",
    "#     base_estimator = DecisionTreeClassifier(\n",
    "#         max_depth=trial.suggest_int('max_depth', 1, 10),\n",
    "#         min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#         max_features=trial.suggest_float('max_features', 0.1, 1.0),\n",
    "#         random_state=RANDOM_STATE  \n",
    "#     )\n",
    "\n",
    "#     # AdaBoost 모델 설정\n",
    "#     param = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "#         'base_estimator': base_estimator,\n",
    "#         'random_state': RANDOM_STATE  \n",
    "#     }\n",
    "    \n",
    "#     model = AdaBoostClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred = model.predict(x_val)\n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1),  # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],               # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveAdaBoost(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658237fd",
   "metadata": {},
   "source": [
    "7. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3ba5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-23 23:34:18,257] A new study created in memory with name: no-name-7e63d327-57d7-4b70-be2f-1807a0b3ae2a\n",
      "[I 2024-08-23 23:38:11,815] Trial 0 finished with value: 0.21534320323014805 and parameters: {'n_estimators': 790, 'max_depth': 199, 'learning_rate': 0.038183309313687845, 'min_samples_split': 185, 'min_samples_leaf': 68}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-23 23:53:09,899] Trial 1 finished with value: 0.19287833827893175 and parameters: {'n_estimators': 2206, 'max_depth': 287, 'learning_rate': 0.06408507099977911, 'min_samples_split': 155, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:02:21,157] Trial 2 finished with value: 0.21022727272727273 and parameters: {'n_estimators': 1469, 'max_depth': 89, 'learning_rate': 0.014404705911514527, 'min_samples_split': 5, 'min_samples_leaf': 42}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:04:32,839] Trial 3 finished with value: 0.19662921348314608 and parameters: {'n_estimators': 1731, 'max_depth': 9, 'learning_rate': 0.05639149688396562, 'min_samples_split': 25, 'min_samples_leaf': 41}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:12:45,259] Trial 4 finished with value: 0.20425531914893616 and parameters: {'n_estimators': 1285, 'max_depth': 232, 'learning_rate': 0.06050095819207001, 'min_samples_split': 126, 'min_samples_leaf': 34}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:14:42,189] Trial 5 finished with value: 0.19742489270386268 and parameters: {'n_estimators': 562, 'max_depth': 29, 'learning_rate': 0.08555435121723459, 'min_samples_split': 148, 'min_samples_leaf': 25}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:30:14,337] Trial 6 finished with value: 0.20373027259684362 and parameters: {'n_estimators': 2403, 'max_depth': 163, 'learning_rate': 0.03917592676400414, 'min_samples_split': 194, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:34:39,787] Trial 7 finished with value: 0.197869101978691 and parameters: {'n_estimators': 2273, 'max_depth': 14, 'learning_rate': 0.06039260026994052, 'min_samples_split': 62, 'min_samples_leaf': 25}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:43:21,592] Trial 8 finished with value: 0.2033898305084746 and parameters: {'n_estimators': 1498, 'max_depth': 215, 'learning_rate': 0.07945176670763587, 'min_samples_split': 269, 'min_samples_leaf': 23}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:45:16,660] Trial 9 finished with value: 0.19165378670788255 and parameters: {'n_estimators': 532, 'max_depth': 229, 'learning_rate': 0.019083553963246288, 'min_samples_split': 239, 'min_samples_leaf': 96}. Best is trial 0 with value: 0.21534320323014805.\n",
      "[I 2024-08-24 00:49:54,648] Trial 10 finished with value: 0.21837549933422104 and parameters: {'n_estimators': 996, 'max_depth': 126, 'learning_rate': 0.033227280782341925, 'min_samples_split': 292, 'min_samples_leaf': 70}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 00:54:34,227] Trial 11 finished with value: 0.21657754010695188 and parameters: {'n_estimators': 972, 'max_depth': 147, 'learning_rate': 0.03814688257955925, 'min_samples_split': 299, 'min_samples_leaf': 68}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 00:59:32,862] Trial 12 finished with value: 0.20560747663551404 and parameters: {'n_estimators': 1029, 'max_depth': 102, 'learning_rate': 0.031648939157612264, 'min_samples_split': 279, 'min_samples_leaf': 68}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:12:42,301] Trial 13 finished with value: 0.2059238363892807 and parameters: {'n_estimators': 2922, 'max_depth': 116, 'learning_rate': 0.0064483997737703365, 'min_samples_split': 295, 'min_samples_leaf': 66}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:17:33,009] Trial 14 finished with value: 0.1959183673469388 and parameters: {'n_estimators': 1094, 'max_depth': 155, 'learning_rate': 0.026979431856743803, 'min_samples_split': 234, 'min_samples_leaf': 90}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:21:26,960] Trial 15 finished with value: 0.20634920634920634 and parameters: {'n_estimators': 880, 'max_depth': 59, 'learning_rate': 0.04553206253832122, 'min_samples_split': 238, 'min_samples_leaf': 81}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:30:51,251] Trial 16 finished with value: 0.21081081081081082 and parameters: {'n_estimators': 1858, 'max_depth': 143, 'learning_rate': 0.07465016738909322, 'min_samples_split': 300, 'min_samples_leaf': 57}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:36:42,183] Trial 17 finished with value: 0.20652173913043476 and parameters: {'n_estimators': 1236, 'max_depth': 183, 'learning_rate': 0.09689305160196446, 'min_samples_split': 207, 'min_samples_leaf': 84}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:38:20,798] Trial 18 finished with value: 0.16666666666666669 and parameters: {'n_estimators': 773, 'max_depth': 68, 'learning_rate': 0.002216038382328995, 'min_samples_split': 259, 'min_samples_leaf': 55}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:47:42,256] Trial 19 finished with value: 0.21399176954732513 and parameters: {'n_estimators': 1864, 'max_depth': 123, 'learning_rate': 0.0479770128346133, 'min_samples_split': 98, 'min_samples_leaf': 78}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:54:21,511] Trial 20 finished with value: 0.19946091644204852 and parameters: {'n_estimators': 1515, 'max_depth': 260, 'learning_rate': 0.02436955007304367, 'min_samples_split': 206, 'min_samples_leaf': 100}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 01:58:51,194] Trial 21 finished with value: 0.2085048010973937 and parameters: {'n_estimators': 855, 'max_depth': 187, 'learning_rate': 0.0361493529216676, 'min_samples_split': 177, 'min_samples_leaf': 64}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:02:14,872] Trial 22 finished with value: 0.20054200542005418 and parameters: {'n_estimators': 719, 'max_depth': 198, 'learning_rate': 0.04185376427453582, 'min_samples_split': 252, 'min_samples_leaf': 74}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:07:38,408] Trial 23 finished with value: 0.21166892808683854 and parameters: {'n_estimators': 1055, 'max_depth': 137, 'learning_rate': 0.029757560982192857, 'min_samples_split': 281, 'min_samples_leaf': 50}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:14:00,188] Trial 24 finished with value: 0.21468926553672318 and parameters: {'n_estimators': 1325, 'max_depth': 165, 'learning_rate': 0.01356143558567548, 'min_samples_split': 104, 'min_samples_leaf': 70}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:17:27,693] Trial 25 finished with value: 0.20457604306864066 and parameters: {'n_estimators': 664, 'max_depth': 259, 'learning_rate': 0.05493343163139085, 'min_samples_split': 221, 'min_samples_leaf': 60}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:21:56,195] Trial 26 finished with value: 0.20242914979757085 and parameters: {'n_estimators': 967, 'max_depth': 83, 'learning_rate': 0.03443562070955211, 'min_samples_split': 163, 'min_samples_leaf': 87}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:27:35,711] Trial 27 finished with value: 0.20193637621023514 and parameters: {'n_estimators': 1149, 'max_depth': 205, 'learning_rate': 0.022284243200629817, 'min_samples_split': 300, 'min_samples_leaf': 51}. Best is trial 10 with value: 0.21837549933422104.\n",
      "[I 2024-08-24 02:30:10,943] Trial 28 finished with value: 0.22615803814713897 and parameters: {'n_estimators': 518, 'max_depth': 176, 'learning_rate': 0.05075849990891461, 'min_samples_split': 74, 'min_samples_leaf': 74}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:32:43,010] Trial 29 finished with value: 0.21428571428571427 and parameters: {'n_estimators': 512, 'max_depth': 125, 'learning_rate': 0.07005966834357025, 'min_samples_split': 51, 'min_samples_leaf': 75}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:35:54,058] Trial 30 finished with value: 0.21164021164021163 and parameters: {'n_estimators': 705, 'max_depth': 180, 'learning_rate': 0.05100680000476934, 'min_samples_split': 73, 'min_samples_leaf': 92}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:40:26,553] Trial 31 finished with value: 0.22496570644718794 and parameters: {'n_estimators': 845, 'max_depth': 163, 'learning_rate': 0.04366124271188972, 'min_samples_split': 137, 'min_samples_leaf': 63}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:45:15,845] Trial 32 finished with value: 0.21300138312586445 and parameters: {'n_estimators': 871, 'max_depth': 145, 'learning_rate': 0.04304477659090705, 'min_samples_split': 135, 'min_samples_leaf': 62}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:48:38,716] Trial 33 finished with value: 0.21399176954732513 and parameters: {'n_estimators': 675, 'max_depth': 167, 'learning_rate': 0.048140443262947516, 'min_samples_split': 105, 'min_samples_leaf': 74}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 02:54:18,065] Trial 34 finished with value: 0.21971830985915494 and parameters: {'n_estimators': 921, 'max_depth': 110, 'learning_rate': 0.06527041059576427, 'min_samples_split': 26, 'min_samples_leaf': 44}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:02:52,270] Trial 35 finished with value: 0.19971056439942111 and parameters: {'n_estimators': 1399, 'max_depth': 103, 'learning_rate': 0.06595440619695626, 'min_samples_split': 23, 'min_samples_leaf': 47}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:09:07,759] Trial 36 finished with value: 0.20256776034236806 and parameters: {'n_estimators': 1189, 'max_depth': 53, 'learning_rate': 0.0535714043875753, 'min_samples_split': 32, 'min_samples_leaf': 41}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:19:31,316] Trial 37 finished with value: 0.20549927641099858 and parameters: {'n_estimators': 1603, 'max_depth': 93, 'learning_rate': 0.059706442496553644, 'min_samples_split': 80, 'min_samples_leaf': 37}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:23:46,985] Trial 38 finished with value: 0.20031796502384738 and parameters: {'n_estimators': 651, 'max_depth': 130, 'learning_rate': 0.08917844232637026, 'min_samples_split': 42, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:38:32,177] Trial 39 finished with value: 0.19568345323741007 and parameters: {'n_estimators': 2647, 'max_depth': 76, 'learning_rate': 0.0665250565510225, 'min_samples_split': 3, 'min_samples_leaf': 47}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:43:47,639] Trial 40 finished with value: 0.20170454545454547 and parameters: {'n_estimators': 820, 'max_depth': 109, 'learning_rate': 0.07178735070901802, 'min_samples_split': 128, 'min_samples_leaf': 31}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:49:04,308] Trial 41 finished with value: 0.220708446866485 and parameters: {'n_estimators': 957, 'max_depth': 147, 'learning_rate': 0.03966759798809322, 'min_samples_split': 17, 'min_samples_leaf': 70}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:54:54,087] Trial 42 finished with value: 0.20470262793914248 and parameters: {'n_estimators': 941, 'max_depth': 172, 'learning_rate': 0.05849534501171986, 'min_samples_split': 19, 'min_samples_leaf': 56}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 03:57:39,286] Trial 43 finished with value: 0.21546961325966849 and parameters: {'n_estimators': 547, 'max_depth': 154, 'learning_rate': 0.04053209770574413, 'min_samples_split': 62, 'min_samples_leaf': 80}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 04:03:59,221] Trial 44 finished with value: 0.21862348178137653 and parameters: {'n_estimators': 1106, 'max_depth': 220, 'learning_rate': 0.05163057968127198, 'min_samples_split': 14, 'min_samples_leaf': 70}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 04:12:01,624] Trial 45 finished with value: 0.2050561797752809 and parameters: {'n_estimators': 1303, 'max_depth': 240, 'learning_rate': 0.06338285284408754, 'min_samples_split': 14, 'min_samples_leaf': 60}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 04:24:15,288] Trial 46 finished with value: 0.21052631578947367 and parameters: {'n_estimators': 2104, 'max_depth': 219, 'learning_rate': 0.05370855336578968, 'min_samples_split': 44, 'min_samples_leaf': 72}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 04:31:00,923] Trial 47 finished with value: 0.2051983584131327 and parameters: {'n_estimators': 1122, 'max_depth': 195, 'learning_rate': 0.0790693816108248, 'min_samples_split': 31, 'min_samples_leaf': 66}. Best is trial 28 with value: 0.22615803814713897.\n",
      "[I 2024-08-24 04:34:19,305] Trial 48 finished with value: 0.22764227642276422 and parameters: {'n_estimators': 616, 'max_depth': 246, 'learning_rate': 0.044380389416634275, 'min_samples_split': 84, 'min_samples_leaf': 78}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:37:08,492] Trial 49 finished with value: 0.21241379310344827 and parameters: {'n_estimators': 565, 'max_depth': 293, 'learning_rate': 0.044781175409413586, 'min_samples_split': 117, 'min_samples_leaf': 86}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:43:17,564] Trial 50 finished with value: 0.1964809384164223 and parameters: {'n_estimators': 770, 'max_depth': 273, 'learning_rate': 0.03807606670847369, 'min_samples_split': 88, 'min_samples_leaf': 15}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:46:35,116] Trial 51 finished with value: 0.220708446866485 and parameters: {'n_estimators': 606, 'max_depth': 242, 'learning_rate': 0.04992616643599103, 'min_samples_split': 60, 'min_samples_leaf': 77}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:49:54,240] Trial 52 finished with value: 0.2185792349726776 and parameters: {'n_estimators': 602, 'max_depth': 239, 'learning_rate': 0.04692744927694142, 'min_samples_split': 62, 'min_samples_leaf': 77}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:52:26,759] Trial 53 finished with value: 0.21122994652406418 and parameters: {'n_estimators': 505, 'max_depth': 281, 'learning_rate': 0.05768099051920315, 'min_samples_split': 56, 'min_samples_leaf': 82}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 04:56:10,217] Trial 54 finished with value: 0.208955223880597 and parameters: {'n_estimators': 778, 'max_depth': 257, 'learning_rate': 0.030801713347470866, 'min_samples_split': 71, 'min_samples_leaf': 91}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:01:32,766] Trial 55 finished with value: 0.2068965517241379 and parameters: {'n_estimators': 916, 'max_depth': 241, 'learning_rate': 0.06272014827627652, 'min_samples_split': 92, 'min_samples_leaf': 65}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:04:58,910] Trial 56 finished with value: 0.2135135135135135 and parameters: {'n_estimators': 642, 'max_depth': 156, 'learning_rate': 0.0496269526762603, 'min_samples_split': 36, 'min_samples_leaf': 78}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:10:03,111] Trial 57 finished with value: 0.21337126600284495 and parameters: {'n_estimators': 797, 'max_depth': 206, 'learning_rate': 0.04130659171756353, 'min_samples_split': 47, 'min_samples_leaf': 52}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:13:06,481] Trial 58 finished with value: 0.19337016574585636 and parameters: {'n_estimators': 605, 'max_depth': 138, 'learning_rate': 0.03664833843715877, 'min_samples_split': 145, 'min_samples_leaf': 83}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:19:31,136] Trial 59 finished with value: 0.20949720670391062 and parameters: {'n_estimators': 1037, 'max_depth': 115, 'learning_rate': 0.04480926341962755, 'min_samples_split': 115, 'min_samples_leaf': 59}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:22:39,046] Trial 60 finished with value: 0.20454545454545456 and parameters: {'n_estimators': 746, 'max_depth': 38, 'learning_rate': 0.025589249036949657, 'min_samples_split': 80, 'min_samples_leaf': 68}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:27:37,562] Trial 61 finished with value: 0.2076502732240437 and parameters: {'n_estimators': 881, 'max_depth': 228, 'learning_rate': 0.05145003671815263, 'min_samples_split': 7, 'min_samples_leaf': 71}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:33:44,494] Trial 62 finished with value: 0.20441988950276244 and parameters: {'n_estimators': 1015, 'max_depth': 216, 'learning_rate': 0.05701590179114, 'min_samples_split': 13, 'min_samples_leaf': 63}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:37:34,636] Trial 63 finished with value: 0.21282401091405184 and parameters: {'n_estimators': 706, 'max_depth': 249, 'learning_rate': 0.051841583765093166, 'min_samples_split': 26, 'min_samples_leaf': 76}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:44:44,445] Trial 64 finished with value: 0.2125340599455041 and parameters: {'n_estimators': 1243, 'max_depth': 276, 'learning_rate': 0.04830758651541245, 'min_samples_split': 38, 'min_samples_leaf': 69}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:50:00,213] Trial 65 finished with value: 0.21862348178137653 and parameters: {'n_estimators': 946, 'max_depth': 179, 'learning_rate': 0.033819077699773145, 'min_samples_split': 54, 'min_samples_leaf': 73}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 05:57:26,451] Trial 66 finished with value: 0.21745350500715308 and parameters: {'n_estimators': 1099, 'max_depth': 226, 'learning_rate': 0.042819817918362195, 'min_samples_split': 70, 'min_samples_leaf': 45}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:01:51,682] Trial 67 finished with value: 0.20188425302826382 and parameters: {'n_estimators': 869, 'max_depth': 194, 'learning_rate': 0.039135841502964876, 'min_samples_split': 184, 'min_samples_leaf': 88}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:06:20,227] Trial 68 finished with value: 0.21428571428571427 and parameters: {'n_estimators': 618, 'max_depth': 265, 'learning_rate': 0.05585250406546656, 'min_samples_split': 2, 'min_samples_leaf': 37}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:15:11,640] Trial 69 finished with value: 0.2103786816269285 and parameters: {'n_estimators': 1380, 'max_depth': 209, 'learning_rate': 0.06865590083003413, 'min_samples_split': 23, 'min_samples_leaf': 54}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:24:54,662] Trial 70 finished with value: 0.208955223880597 and parameters: {'n_estimators': 1746, 'max_depth': 299, 'learning_rate': 0.07632926965345514, 'min_samples_split': 86, 'min_samples_leaf': 79}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:30:29,722] Trial 71 finished with value: 0.2149659863945578 and parameters: {'n_estimators': 985, 'max_depth': 189, 'learning_rate': 0.0347675088321504, 'min_samples_split': 55, 'min_samples_leaf': 73}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:34:38,406] Trial 72 finished with value: 0.20979020979020976 and parameters: {'n_estimators': 725, 'max_depth': 167, 'learning_rate': 0.03251310206561335, 'min_samples_split': 61, 'min_samples_leaf': 67}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:39:57,933] Trial 73 finished with value: 0.20821917808219179 and parameters: {'n_estimators': 936, 'max_depth': 180, 'learning_rate': 0.045765246948147, 'min_samples_split': 47, 'min_samples_leaf': 71}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:43:57,525] Trial 74 finished with value: 0.20136054421768707 and parameters: {'n_estimators': 822, 'max_depth': 172, 'learning_rate': 0.029120142896862586, 'min_samples_split': 14, 'min_samples_leaf': 94}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:50:04,201] Trial 75 finished with value: 0.21709633649932158 and parameters: {'n_estimators': 1159, 'max_depth': 159, 'learning_rate': 0.06066700372749428, 'min_samples_split': 33, 'min_samples_leaf': 85}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:52:18,655] Trial 76 finished with value: 0.1981981981981982 and parameters: {'n_estimators': 510, 'max_depth': 247, 'learning_rate': 0.019030349025384488, 'min_samples_split': 165, 'min_samples_leaf': 76}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 06:58:10,666] Trial 77 finished with value: 0.215633423180593 and parameters: {'n_estimators': 1081, 'max_depth': 150, 'learning_rate': 0.04301895757516823, 'min_samples_split': 102, 'min_samples_leaf': 80}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:10:31,084] Trial 78 finished with value: 0.19915848527349228 and parameters: {'n_estimators': 2060, 'max_depth': 225, 'learning_rate': 0.08570432991161928, 'min_samples_split': 75, 'min_samples_leaf': 63}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:19:52,921] Trial 79 finished with value: 0.2165087956698241 and parameters: {'n_estimators': 1618, 'max_depth': 177, 'learning_rate': 0.03843639727992085, 'min_samples_split': 26, 'min_samples_leaf': 74}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:24:03,077] Trial 80 finished with value: 0.21448467966573814 and parameters: {'n_estimators': 682, 'max_depth': 132, 'learning_rate': 0.05346779925941098, 'min_samples_split': 113, 'min_samples_leaf': 59}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:27:10,767] Trial 81 finished with value: 0.2210386151797603 and parameters: {'n_estimators': 584, 'max_depth': 237, 'learning_rate': 0.04615382241872377, 'min_samples_split': 59, 'min_samples_leaf': 77}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:30:05,780] Trial 82 finished with value: 0.2072678331090175 and parameters: {'n_estimators': 574, 'max_depth': 200, 'learning_rate': 0.049379603717410514, 'min_samples_split': 66, 'min_samples_leaf': 82}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:34:45,670] Trial 83 finished with value: 0.2219178082191781 and parameters: {'n_estimators': 828, 'max_depth': 251, 'learning_rate': 0.03575810666386265, 'min_samples_split': 53, 'min_samples_leaf': 69}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:39:30,592] Trial 84 finished with value: 0.21182943603851445 and parameters: {'n_estimators': 833, 'max_depth': 234, 'learning_rate': 0.04616045353772397, 'min_samples_split': 81, 'min_samples_leaf': 69}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:43:18,203] Trial 85 finished with value: 0.21448467966573814 and parameters: {'n_estimators': 648, 'max_depth': 253, 'learning_rate': 0.04023582475258289, 'min_samples_split': 38, 'min_samples_leaf': 65}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:47:19,109] Trial 86 finished with value: 0.2219215155615697 and parameters: {'n_estimators': 748, 'max_depth': 262, 'learning_rate': 0.04372912751467909, 'min_samples_split': 96, 'min_samples_leaf': 78}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:52:50,796] Trial 87 finished with value: 0.22 and parameters: {'n_estimators': 759, 'max_depth': 261, 'learning_rate': 0.04396646150885683, 'min_samples_split': 94, 'min_samples_leaf': 31}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 07:58:24,835] Trial 88 finished with value: 0.21707670043415336 and parameters: {'n_estimators': 737, 'max_depth': 263, 'learning_rate': 0.03649162358576432, 'min_samples_split': 94, 'min_samples_leaf': 23}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 08:01:29,302] Trial 89 finished with value: 0.21458046767537828 and parameters: {'n_estimators': 576, 'max_depth': 267, 'learning_rate': 0.042217222435395094, 'min_samples_split': 126, 'min_samples_leaf': 78}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 08:20:43,809] Trial 90 finished with value: 0.20520231213872836 and parameters: {'n_estimators': 2507, 'max_depth': 287, 'learning_rate': 0.044370552830703354, 'min_samples_split': 98, 'min_samples_leaf': 16}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 08:26:07,799] Trial 91 finished with value: 0.20114942528735635 and parameters: {'n_estimators': 776, 'max_depth': 246, 'learning_rate': 0.04728586293238019, 'min_samples_split': 107, 'min_samples_leaf': 34}. Best is trial 48 with value: 0.22764227642276422.\n",
      "[I 2024-08-24 08:30:37,577] Trial 92 finished with value: 0.22784810126582278 and parameters: {'n_estimators': 675, 'max_depth': 271, 'learning_rate': 0.04044877940480404, 'min_samples_split': 84, 'min_samples_leaf': 43}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:33:54,809] Trial 93 finished with value: 0.19887955182072833 and parameters: {'n_estimators': 680, 'max_depth': 274, 'learning_rate': 0.02780676861045794, 'min_samples_split': 142, 'min_samples_leaf': 88}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:37:46,355] Trial 94 finished with value: 0.22510822510822512 and parameters: {'n_estimators': 539, 'max_depth': 283, 'learning_rate': 0.04015823194085849, 'min_samples_split': 85, 'min_samples_leaf': 31}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:41:30,278] Trial 95 finished with value: 0.21997105643994214 and parameters: {'n_estimators': 510, 'max_depth': 270, 'learning_rate': 0.040192562666305366, 'min_samples_split': 78, 'min_samples_leaf': 27}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:45:45,962] Trial 96 finished with value: 0.22507122507122507 and parameters: {'n_estimators': 618, 'max_depth': 284, 'learning_rate': 0.037934869707924, 'min_samples_split': 67, 'min_samples_leaf': 39}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:49:32,994] Trial 97 finished with value: 0.22630834512022632 and parameters: {'n_estimators': 579, 'max_depth': 283, 'learning_rate': 0.03581163969904906, 'min_samples_split': 86, 'min_samples_leaf': 39}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:53:20,274] Trial 98 finished with value: 0.2190201729106628 and parameters: {'n_estimators': 563, 'max_depth': 282, 'learning_rate': 0.035202326468315774, 'min_samples_split': 86, 'min_samples_leaf': 40}. Best is trial 92 with value: 0.22784810126582278.\n",
      "[I 2024-08-24 08:57:46,423] Trial 99 finished with value: 0.22028985507246376 and parameters: {'n_estimators': 632, 'max_depth': 287, 'learning_rate': 0.03237444321983355, 'min_samples_split': 69, 'min_samples_leaf': 37}. Best is trial 92 with value: 0.22784810126582278.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.22784810126582278, \n",
      "params {'n_estimators': 675, 'max_depth': 271, 'learning_rate': 0.04044877940480404, 'min_samples_split': 84, 'min_samples_leaf': 43}\n"
     ]
    }
   ],
   "source": [
    "def objectiveGBM(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "    # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "    y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "    y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 300),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    "       \n",
    "    model = GradientBoostingClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill1.drop(\"target\", axis=1), # <--- 해당하는 데이터로 변경해주기!!\n",
    "    train_data_fill1[\"target\"],              # <--- 해당하는 데이터로 변경해주기!!\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveGBM(trial, x_train, y_train, x_val, y_val), n_trials=100)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd7021",
   "metadata": {},
   "source": [
    "8. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1058caca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objectiveDecisionTree(trial, x_tr, y_tr, x_val, y_val):\n",
    "    \n",
    "#     # 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "#     y_tr = y_tr.map({'Normal': 0, 'AbNormal': 1})\n",
    "#     y_val = y_val.map({'Normal': 0, 'AbNormal': 1})\n",
    "    \n",
    "#     param = {\n",
    "#         'max_depth': trial.suggest_int('max_depth', 1, 30),\n",
    "#         'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "#         'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "#         'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None]),\n",
    "#         'random_state': RANDOM_STATE\n",
    "#     }\n",
    "       \n",
    "#     model = DecisionTreeClassifier(**param)\n",
    "#     model.fit(x_tr, y_tr)\n",
    "#     pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "#     pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "#     score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "#     return score\n",
    "\n",
    "# # 데이터셋 분할\n",
    "# x_train, x_val, y_train, y_val = train_test_split(\n",
    "#     train_data.drop(\"target\", axis=1), # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     train_data[\"target\"],              # <--- 해당하는 데이터로 변경해주기!!\n",
    "#     test_size=0.2,\n",
    "#     shuffle=True,\n",
    "#     random_state=RANDOM_STATE,\n",
    "# )\n",
    "\n",
    "# # 하이퍼 파라미터 튜닝\n",
    "# study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "# study.optimize(lambda trial: objectiveDecisionTree(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
    "\n",
    "# print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4418c3",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
