{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"../../data/train_data_0817.csv\")\n",
    "test_data = pd.read_csv(\"../../data/test_data_0817.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edfc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'WorkMode Collect Result'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dd7eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_encoded',\n",
    "    'workorder_receip_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a333ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "141cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ffec39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be86915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 38\n",
      "train_data_dam DataFrame의 칼럼 수: 21\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 13\n",
      "train_data_fill2 DataFrame의 칼럼 수: 13\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 39\n",
      "test_data_dam DataFrame의 칼럼 수: 22\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 14\n",
      "test_data_fill2 DataFrame의 칼럼 수: 14\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d288bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "def stacking(train_data, test_data, base_models, final_model):\n",
    "    \"\"\"\n",
    "    학습 데이터를 사용하여 모델을 학습하고, 테스트 데이터에 대해 예측 확률을 계산합니다.\n",
    "\n",
    "    Parameters:\n",
    "    train_data (pd.DataFrame): 학습 데이터 (특성 및 타겟 포함)\n",
    "    test_data (pd.DataFrame): 테스트 데이터 (특성만 포함)\n",
    "    base_models (list of tuples): 기본 모델 리스트 (이름, 모델 인스턴스)\n",
    "    final_model (estimator): 최종 메타 모델\n",
    "\n",
    "    Returns:\n",
    "    np.array: 테스트 데이터에 대한 예측 확률\n",
    "    StackingClassifier: 학습된 스태킹 모델\n",
    "    \"\"\"\n",
    "    # 학습 데이터에서 특성과 타겟 분리\n",
    "    X_train = train_data.drop([\"target\"], axis=1)\n",
    "    y_train = train_data[\"target\"].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "    # StackingClassifier 설정\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=final_model,\n",
    "        passthrough=True  # 원본 특성도 메타 모델에 전달\n",
    "    )\n",
    "\n",
    "    # StackingClassifier 학습\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "    # 테스트 데이터에 대해 예측 확률 계산\n",
    "    probabilities = stacking_clf.predict_proba(test_data)\n",
    "\n",
    "    return probabilities, stacking_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af914",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15f2a7",
   "metadata": {},
   "source": [
    "Dam 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24c98a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_dam 데이터로 학습한 결과:\n",
      "F1 Score: 0.2222222222222222\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7470  192]\n",
      " [ 361   79]]\n",
      "---\n",
      "Accuracy: 0.9317452480868921\n",
      "Precision: 0.2915129151291513\n",
      "Recall: 0.17954545454545454\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Dam = train_and_evaluate_model(\n",
    "    'lgbm', train_data_dam\n",
    "    , n_estimators=1467\n",
    "    , num_leaves=2545\n",
    "    , max_depth=37\n",
    "    , learning_rate=0.04353920224587149 \n",
    "    , min_child_samples=83\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b184d",
   "metadata": {},
   "source": [
    "AutoClave 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc7cbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_autoclave 데이터로 학습한 결과:\n",
      "F1 Score: 0.2511078286558346\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7510  152]\n",
      " [ 355   85]]\n",
      "---\n",
      "Accuracy: 0.9374228585534435\n",
      "Precision: 0.35864978902953587\n",
      "Recall: 0.19318181818181818\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_AutoClave = train_and_evaluate_model(\n",
    "    'lgbm', train_data_autoclave\n",
    "    , n_estimators=1563\n",
    "    , num_leaves=1885\n",
    "    , max_depth=15\n",
    "    , learning_rate=0.07033655355880039 \n",
    "    , min_child_samples=158\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357e142",
   "metadata": {},
   "source": [
    "Fill1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3a1e8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_fill1 데이터로 학습한 결과:\n",
      "F1 Score: 0.2260668973471742\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7333  329]\n",
      " [ 342   98]]\n",
      "---\n",
      "Accuracy: 0.9171809429770427\n",
      "Precision: 0.22950819672131148\n",
      "Recall: 0.22272727272727272\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Fill1 = train_and_evaluate_model(\n",
    "    'lgbm', train_data_fill1\n",
    "    , n_estimators=1452\n",
    "    , num_leaves=1581\n",
    "    , max_depth=22\n",
    "    , learning_rate=0.002000452888170992 \n",
    "    , min_child_samples=43\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98025a2",
   "metadata": {},
   "source": [
    "Fill2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "274a5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_fill2 데이터로 학습한 결과:\n",
      "F1 Score: 0.21999999999999997\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7568   94]\n",
      " [ 374   66]]\n",
      "---\n",
      "Accuracy: 0.9422364848185634\n",
      "Precision: 0.4125\n",
      "Recall: 0.15\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_Fill2 = train_and_evaluate_model(\n",
    "    'lgbm', train_data_fill2\n",
    "    , n_estimators=1632\n",
    "    , num_leaves=1426\n",
    "    , max_depth=8\n",
    "    , learning_rate=0.07487990991624197 \n",
    "    , min_child_samples=90\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb4d",
   "metadata": {},
   "source": [
    "전체공정 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef6f551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data 데이터로 학습한 결과:\n",
      "F1 Score: 0.24501424501424504\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7486  176]\n",
      " [ 354   86]]\n",
      "---\n",
      "Accuracy: 0.9345840533201678\n",
      "Precision: 0.3282442748091603\n",
      "Recall: 0.19545454545454546\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model_All = train_and_evaluate_model(\n",
    "    'lgbm', train_data\n",
    "    , n_estimators=2383\n",
    "    , num_leaves=2528\n",
    "    , max_depth=343\n",
    "    , learning_rate=0.04661896043153508\n",
    "    , min_child_samples=209\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a59250",
   "metadata": {},
   "source": [
    "stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0db2e",
   "metadata": {},
   "source": [
    "threshold 조절해보면서 f1-score 값이 높은것을 확인  \n",
    "-> threshold를 선택하는 기준으로서 f1-score을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da1d05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier F1 Score with threshold 0.3: 0.19413919413919412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(\"target\", axis=1),\n",
    "    train_data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# Base estimators 설정\n",
    "estimators = [\n",
    "    ('dam', train_model_Dam),\n",
    "    ('autoclave', train_model_AutoClave),\n",
    "    ('fill1', train_model_Fill1),\n",
    "    ('fill2', train_model_Fill2)\n",
    "]\n",
    "\n",
    "# 최종 메타 모델 설정 (train_model_All 사용)\n",
    "final_estimator = train_model_All\n",
    "\n",
    "# StackingClassifier 설정\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=final_estimator,\n",
    "    passthrough=True  # 원본 특성도 메타 모델에 전달\n",
    ")\n",
    "\n",
    "# StackingClassifier 학습\n",
    "stacking_clf.fit(x_train, y_train)\n",
    "\n",
    "# 예측 확률 계산\n",
    "probabilities = stacking_clf.predict_proba(x_val)\n",
    "\n",
    "# 임계값 적용 (예: 0.3)\n",
    "threshold = 0.3\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# 평가\n",
    "score = f1_score(y_val, predictions, average=\"binary\")\n",
    "conf_matrix = confusion_matrix(y_val, predictions)\n",
    "\n",
    "print(f\"Stacking Classifier F1 Score with threshold {threshold}: {score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ef3673f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier F1 Score with threshold 0.3: 0.19413919413919412\n",
      "Confusion Matrix:\n",
      "[[7609   53]\n",
      " [ 387   53]]\n"
     ]
    }
   ],
   "source": [
    "# 임계값 적용 \n",
    "threshold = 0.3\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# 평가\n",
    "score = f1_score(y_val, predictions, average=\"binary\")\n",
    "conf_matrix = confusion_matrix(y_val, predictions)\n",
    "\n",
    "print(f\"Stacking Classifier F1 Score with threshold {threshold}: {score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6c23216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier F1 Score with threshold 0.28: 0.19168173598553348\n",
      "Confusion Matrix:\n",
      "[[7602   60]\n",
      " [ 387   53]]\n"
     ]
    }
   ],
   "source": [
    "# 임계값 적용 \n",
    "threshold = 0.28\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# 평가\n",
    "score = f1_score(y_val, predictions, average=\"binary\")\n",
    "conf_matrix = confusion_matrix(y_val, predictions)\n",
    "\n",
    "print(f\"Stacking Classifier F1 Score with threshold {threshold}: {score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7183945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier F1 Score with threshold 0.26: 0.19320214669051877\n",
      "Confusion Matrix:\n",
      "[[7597   65]\n",
      " [ 386   54]]\n"
     ]
    }
   ],
   "source": [
    "# 임계값 적용\n",
    "threshold = 0.26\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# 평가\n",
    "score = f1_score(y_val, predictions, average=\"binary\")\n",
    "conf_matrix = confusion_matrix(y_val, predictions)\n",
    "\n",
    "print(f\"Stacking Classifier F1 Score with threshold {threshold}: {score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "### 모델 학습(train 데이터 전체 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa25b4",
   "metadata": {},
   "source": [
    "위의 모델학습 코드에서 함수명만 바뀌고 들어가는 값들은 동일  \n",
    "-> 위의 코드 복붙한다음 함수명만 바꿔주면 사용하기 편함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39c08dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm 모델이 train_data_dam 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill1 데이터로 학습 완료\n",
      "lgbm 모델이 train_data_fill2 데이터로 학습 완료\n",
      "lgbm 모델이 train_data 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "    'lgbm', train_data_dam\n",
    "    , n_estimators=1467\n",
    "    , num_leaves=2545\n",
    "    , max_depth=37\n",
    "    , learning_rate=0.04353920224587149 \n",
    "    , min_child_samples=83\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'lgbm', train_data_autoclave\n",
    "    , n_estimators=1563\n",
    "    , num_leaves=1885\n",
    "    , max_depth=15\n",
    "    , learning_rate=0.07033655355880039 \n",
    "    , min_child_samples=158\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill1\n",
    "    , n_estimators=1452\n",
    "    , num_leaves=1581\n",
    "    , max_depth=22\n",
    "    , learning_rate=0.002000452888170992 \n",
    "    , min_child_samples=43\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'lgbm', train_data_fill2\n",
    "    , n_estimators=1632\n",
    "    , num_leaves=1426\n",
    "    , max_depth=8\n",
    "    , learning_rate=0.07487990991624197 \n",
    "    , min_child_samples=90\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")\n",
    "\n",
    "model_All = fit_all_train_data_function(\n",
    "    'lgbm', train_data\n",
    "    , n_estimators=2383\n",
    "    , num_leaves=2528\n",
    "    , max_depth=343\n",
    "    , learning_rate=0.04661896043153508\n",
    "    , min_child_samples=209\n",
    "    , boosting_type='dart'\n",
    "    , random_state=RANDOM_STATE\n",
    "    , verbose=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8b158",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ee55c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f203e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Predictions: [0 0 0 ... 0 0 0]\n",
      "Sum of Final Predictions: 159\n"
     ]
    }
   ],
   "source": [
    "# Base estimators 설정\n",
    "base_models = [\n",
    "    ('dam', train_model_Dam),\n",
    "    ('autoclave', train_model_AutoClave),\n",
    "    ('fill1', train_model_Fill1),\n",
    "    ('fill2', train_model_Fill2)\n",
    "]\n",
    "final_model = train_model_All\n",
    "\n",
    "# 스태킹 기법을 사용하여 예측 확률 계산\n",
    "probabilities, stacking_clf = stacking(train_data, x_test_all, base_models, final_model)\n",
    "\n",
    "# 임계값 적용 (예: 0.3)\n",
    "threshold = 0.3\n",
    "final_predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Final Predictions: {final_predictions}')\n",
    "print(\"Sum of Final Predictions:\", sum(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9deb818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions with threshold 0.3: [0 0 0 ... 0 0 0]\n",
      "Sum of New Predictions: 159\n"
     ]
    }
   ],
   "source": [
    "# 임계값을 조절\n",
    "new_threshold = 0.3\n",
    "new_predictions = (probabilities[:, 1] >= new_threshold).astype(int)\n",
    "print(f'New Predictions with threshold {new_threshold}: {new_predictions}')\n",
    "print(\"Sum of New Predictions:\", sum(new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "464d4b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions with threshold 0.28: [0 0 0 ... 0 0 0]\n",
      "Sum of New Predictions: 176\n"
     ]
    }
   ],
   "source": [
    "# 임계값을 조절\n",
    "new_threshold = 0.28\n",
    "new_predictions = (probabilities[:, 1] >= new_threshold).astype(int)\n",
    "print(f'New Predictions with threshold {new_threshold}: {new_predictions}')\n",
    "print(\"Sum of New Predictions:\", sum(new_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71a2f17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions with threshold 0.26: [0 0 0 ... 0 0 0]\n",
      "Sum of New Predictions: 192\n"
     ]
    }
   ],
   "source": [
    "# 임계값을 조절\n",
    "new_threshold = 0.26\n",
    "new_predictions = (probabilities[:, 1] >= new_threshold).astype(int)\n",
    "print(f'New Predictions with threshold {new_threshold}: {new_predictions}')\n",
    "print(\"Sum of New Predictions:\", sum(new_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"../data/submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195168fc",
   "metadata": {},
   "source": [
    "'제출하기' 이전의 스레스홀드를 통해 조절해서 나온 AbNormal 갯수와 동일한지 재확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal      17234\n",
       "AbNormal      127\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9efee1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001be084fbc4aaa9d921f39e595961b</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005bbd180064abd99e63f9ed3e1ac80</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000948934c4140d883d670adcb609584</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a6bfd02874c6296dc7b2e9c5678a7</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0018e78ce91343678716e2ea27a51c95</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001fda4596f545d0a3b0ce85fbea77d2</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0020734a7b29472298358ad58645a0c9</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00234c5914cd4c4a888d13f8b3773135</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00297b6c93e44d49ac534758a23dc74e</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002d904240d84b188d410d16383a9c3a</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Set ID  target\n",
       "0  0001be084fbc4aaa9d921f39e595961b  Normal\n",
       "1  0005bbd180064abd99e63f9ed3e1ac80  Normal\n",
       "2  000948934c4140d883d670adcb609584  Normal\n",
       "3  000a6bfd02874c6296dc7b2e9c5678a7  Normal\n",
       "4  0018e78ce91343678716e2ea27a51c95  Normal\n",
       "5  001fda4596f545d0a3b0ce85fbea77d2  Normal\n",
       "6  0020734a7b29472298358ad58645a0c9  Normal\n",
       "7  00234c5914cd4c4a888d13f8b3773135  Normal\n",
       "8  00297b6c93e44d49ac534758a23dc74e  Normal\n",
       "9  002d904240d84b188d410d16383a9c3a  Normal"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d1bab",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
