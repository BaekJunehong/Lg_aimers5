{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5468dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./final_data/final_train_data_ver2.csv\")\n",
    "test_data = pd.read_csv(\"./final_data/final_test_data_ver2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84efc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result_encoded',\n",
    "    'WorkMode Collect Result',\n",
    "    'Receip_n_suffix_3',\n",
    "    'time_gap_All'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be6bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab42a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e7e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e81578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b2cfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ea40b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 44\n",
      "train_data_dam DataFrame의 칼럼 수: 25\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 16\n",
      "train_data_fill2 DataFrame의 칼럼 수: 16\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 45\n",
      "test_data_dam DataFrame의 칼럼 수: 26\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 17\n",
      "test_data_fill2 DataFrame의 칼럼 수: 17\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f1f651b-d56f-4b1b-90cc-12270e83463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "[I 2024-09-28 15:19:37,449] A new study created in memory with name: no-name-1993f9d3-ce77-4b9c-a718-370212bdf004\n",
      "[I 2024-09-28 15:20:00,843] Trial 0 finished with value: 0.20095693779904308 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.20095693779904308.\n",
      "[I 2024-09-28 15:23:09,733] Trial 1 finished with value: 0.23328149300155523 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 1 with value: 0.23328149300155523.\n",
      "[I 2024-09-28 15:23:57,378] Trial 2 finished with value: 0.2627406568516421 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:24:54,904] Trial 3 finished with value: 0.19831932773109245 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:25:47,081] Trial 4 finished with value: 0.20055710306406688 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:26:05,083] Trial 5 finished with value: 0.21671826625386997 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:28:51,029] Trial 6 finished with value: 0.22941176470588234 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:30:32,361] Trial 7 finished with value: 0.22160664819944598 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:32:01,805] Trial 8 finished with value: 0.23087621696801108 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:32:12,582] Trial 9 finished with value: 0.21105527638190955 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:32:40,979] Trial 10 finished with value: 0.19795221843003413 and parameters: {'n_estimators': 1143, 'num_leaves': 1208, 'max_depth': 10, 'learning_rate': 0.02761795588449953, 'min_child_samples': 182}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:35:53,638] Trial 11 finished with value: 0.23303457106274006 and parameters: {'n_estimators': 2032, 'num_leaves': 2985, 'max_depth': 299, 'learning_rate': 0.003834191934389869, 'min_child_samples': 12}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:39:19,145] Trial 12 finished with value: 0.2090032154340836 and parameters: {'n_estimators': 2853, 'num_leaves': 1311, 'max_depth': 52, 'learning_rate': 0.030890016914548447, 'min_child_samples': 3}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:41:25,763] Trial 13 finished with value: 0.1971465629053178 and parameters: {'n_estimators': 2662, 'num_leaves': 2971, 'max_depth': 120, 'learning_rate': 0.06580977858710242, 'min_child_samples': 152}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:42:39,754] Trial 14 finished with value: 0.19973368841544606 and parameters: {'n_estimators': 1858, 'num_leaves': 1325, 'max_depth': 232, 'learning_rate': 0.09937905186776663, 'min_child_samples': 238}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:44:04,427] Trial 15 finished with value: 0.19667590027700832 and parameters: {'n_estimators': 2141, 'num_leaves': 1698, 'max_depth': 71, 'learning_rate': 0.03652856030008557, 'min_child_samples': 141}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:45:33,749] Trial 16 finished with value: 0.22002820874471082 and parameters: {'n_estimators': 1645, 'num_leaves': 1060, 'max_depth': 209, 'learning_rate': 0.01571690985048357, 'min_child_samples': 34}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:46:02,895] Trial 17 finished with value: 0.20462046204620463 and parameters: {'n_estimators': 1062, 'num_leaves': 1652, 'max_depth': 12, 'learning_rate': 0.052316990778678, 'min_child_samples': 173}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:48:24,715] Trial 18 finished with value: 0.1972972972972973 and parameters: {'n_estimators': 2600, 'num_leaves': 2722, 'max_depth': 151, 'learning_rate': 0.07814861551114073, 'min_child_samples': 111}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:49:09,705] Trial 19 finished with value: 0.20123839009287928 and parameters: {'n_estimators': 1409, 'num_leaves': 1955, 'max_depth': 144, 'learning_rate': 0.049390405540335185, 'min_child_samples': 233}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:50:57,825] Trial 20 finished with value: 0.223463687150838 and parameters: {'n_estimators': 1914, 'num_leaves': 971, 'max_depth': 91, 'learning_rate': 0.01700203539270062, 'min_child_samples': 38}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:55:10,726] Trial 21 finished with value: 0.20562560620756545 and parameters: {'n_estimators': 2055, 'num_leaves': 2956, 'max_depth': 295, 'learning_rate': 0.0019440086572933277, 'min_child_samples': 3}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:57:37,008] Trial 22 finished with value: 0.23668639053254437 and parameters: {'n_estimators': 2489, 'num_leaves': 2613, 'max_depth': 293, 'learning_rate': 0.002752011923653999, 'min_child_samples': 30}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 15:59:13,546] Trial 23 finished with value: 0.2009419152276295 and parameters: {'n_estimators': 2462, 'num_leaves': 2669, 'max_depth': 268, 'learning_rate': 0.009688252579431634, 'min_child_samples': 98}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:02:39,720] Trial 24 finished with value: 0.23008849557522124 and parameters: {'n_estimators': 2953, 'num_leaves': 2723, 'max_depth': 213, 'learning_rate': 0.02441509266078929, 'min_child_samples': 34}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:04:45,342] Trial 25 finished with value: 0.22099447513812157 and parameters: {'n_estimators': 2254, 'num_leaves': 1451, 'max_depth': 32, 'learning_rate': 0.038218401519062514, 'min_child_samples': 54}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:05:51,436] Trial 26 finished with value: 0.23127035830618894 and parameters: {'n_estimators': 1675, 'num_leaves': 2564, 'max_depth': 90, 'learning_rate': 0.011055002124844312, 'min_child_samples': 89}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:07:22,351] Trial 27 finished with value: 0.20679012345679013 and parameters: {'n_estimators': 2692, 'num_leaves': 2126, 'max_depth': 274, 'learning_rate': 0.03260377959798806, 'min_child_samples': 297}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:09:02,923] Trial 28 finished with value: 0.2010723860589812 and parameters: {'n_estimators': 2315, 'num_leaves': 1541, 'max_depth': 217, 'learning_rate': 0.04446123082406568, 'min_child_samples': 130}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:09:26,687] Trial 29 finished with value: 0.20545746388443017 and parameters: {'n_estimators': 835, 'num_leaves': 2139, 'max_depth': 137, 'learning_rate': 0.05780684171846131, 'min_child_samples': 211}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:13:16,874] Trial 30 finished with value: 0.2175226586102719 and parameters: {'n_estimators': 2546, 'num_leaves': 1993, 'max_depth': 99, 'learning_rate': 0.07062128706212441, 'min_child_samples': 22}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:16:00,667] Trial 31 finished with value: 0.2503293807641634 and parameters: {'n_estimators': 1939, 'num_leaves': 2801, 'max_depth': 298, 'learning_rate': 0.0028494707702179326, 'min_child_samples': 17}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:17:39,649] Trial 32 finished with value: 0.23124999999999998 and parameters: {'n_estimators': 1819, 'num_leaves': 2841, 'max_depth': 282, 'learning_rate': 0.006537970324118724, 'min_child_samples': 51}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:19:51,549] Trial 33 finished with value: 0.2570462232243518 and parameters: {'n_estimators': 2132, 'num_leaves': 2499, 'max_depth': 253, 'learning_rate': 0.0014350414411011241, 'min_child_samples': 30}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:22:14,337] Trial 34 finished with value: 0.2288135593220339 and parameters: {'n_estimators': 1984, 'num_leaves': 2484, 'max_depth': 250, 'learning_rate': 0.016128924062028625, 'min_child_samples': 22}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:23:14,984] Trial 35 finished with value: 0.2624035281146637 and parameters: {'n_estimators': 1493, 'num_leaves': 2274, 'max_depth': 284, 'learning_rate': 0.0019311053320149323, 'min_child_samples': 64}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:24:21,741] Trial 36 finished with value: 0.22468354430379744 and parameters: {'n_estimators': 1528, 'num_leaves': 2295, 'max_depth': 261, 'learning_rate': 0.011573700605976686, 'min_child_samples': 65}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:25:10,311] Trial 37 finished with value: 0.1990369181380417 and parameters: {'n_estimators': 1248, 'num_leaves': 2268, 'max_depth': 167, 'learning_rate': 0.021228912845519386, 'min_child_samples': 115}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:26:07,178] Trial 38 finished with value: 0.2450592885375494 and parameters: {'n_estimators': 1389, 'num_leaves': 824, 'max_depth': 232, 'learning_rate': 0.001524413218113411, 'min_child_samples': 85}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:26:44,706] Trial 39 finished with value: 0.23014586709886553 and parameters: {'n_estimators': 941, 'num_leaves': 2799, 'max_depth': 285, 'learning_rate': 0.00950525717043408, 'min_child_samples': 60}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:28:04,932] Trial 40 finished with value: 0.21739130434782608 and parameters: {'n_estimators': 1589, 'num_leaves': 1812, 'max_depth': 251, 'learning_rate': 0.01438263462230992, 'min_child_samples': 44}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:28:55,813] Trial 41 finished with value: 0.1861619609059882 and parameters: {'n_estimators': 1373, 'num_leaves': 811, 'max_depth': 231, 'learning_rate': 0.00121453121321342, 'min_child_samples': 78}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:30:02,534] Trial 42 finished with value: 0.20435510887772193 and parameters: {'n_estimators': 1757, 'num_leaves': 815, 'max_depth': 196, 'learning_rate': 0.0057059284435043035, 'min_child_samples': 99}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:31:00,227] Trial 43 finished with value: 0.23148148148148145 and parameters: {'n_estimators': 1274, 'num_leaves': 1051, 'max_depth': 270, 'learning_rate': 0.02017116675987544, 'min_child_samples': 78}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:31:46,465] Trial 44 finished with value: 0.209106239460371 and parameters: {'n_estimators': 1428, 'num_leaves': 2446, 'max_depth': 240, 'learning_rate': 0.007407013179905787, 'min_child_samples': 155}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:32:26,524] Trial 45 finished with value: 0.18486900206064175 and parameters: {'n_estimators': 1118, 'num_leaves': 748, 'max_depth': 284, 'learning_rate': 0.0014541190427674062, 'min_child_samples': 86}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:34:10,933] Trial 46 finished with value: 0.2141823444283647 and parameters: {'n_estimators': 2104, 'num_leaves': 578, 'max_depth': 300, 'learning_rate': 0.012479875658531037, 'min_child_samples': 16}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:35:18,459] Trial 47 finished with value: 0.20102214650766612 and parameters: {'n_estimators': 1754, 'num_leaves': 977, 'max_depth': 249, 'learning_rate': 0.0067673036920712845, 'min_child_samples': 120}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:36:30,817] Trial 48 finished with value: 0.21198156682027652 and parameters: {'n_estimators': 1932, 'num_leaves': 1248, 'max_depth': 180, 'learning_rate': 0.01999930315342234, 'min_child_samples': 133}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:37:38,210] Trial 49 finished with value: 0.22772277227722773 and parameters: {'n_estimators': 1521, 'num_leaves': 2311, 'max_depth': 223, 'learning_rate': 0.006241856852732314, 'min_child_samples': 66}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:38:37,007] Trial 50 finished with value: 0.22499999999999995 and parameters: {'n_estimators': 1185, 'num_leaves': 1450, 'max_depth': 202, 'learning_rate': 0.012939859047674656, 'min_child_samples': 46}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:41:01,799] Trial 51 finished with value: 0.258252427184466 and parameters: {'n_estimators': 2322, 'num_leaves': 2621, 'max_depth': 290, 'learning_rate': 0.0011237328145597978, 'min_child_samples': 28}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:44:07,528] Trial 52 finished with value: 0.22086824067022084 and parameters: {'n_estimators': 2221, 'num_leaves': 2507, 'max_depth': 259, 'learning_rate': 0.0010531033041673177, 'min_child_samples': 13}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:46:33,573] Trial 53 finished with value: 0.21865889212827985 and parameters: {'n_estimators': 2348, 'num_leaves': 2838, 'max_depth': 277, 'learning_rate': 0.005384980868666636, 'min_child_samples': 27}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:47:59,616] Trial 54 finished with value: 0.19607843137254904 and parameters: {'n_estimators': 2156, 'num_leaves': 2376, 'max_depth': 265, 'learning_rate': 0.026082049781590386, 'min_child_samples': 106}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:48:54,177] Trial 55 finished with value: 0.22847682119205298 and parameters: {'n_estimators': 1357, 'num_leaves': 2650, 'max_depth': 289, 'learning_rate': 0.009141494958104485, 'min_child_samples': 72}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:50:22,280] Trial 56 finished with value: 0.22565687789799077 and parameters: {'n_estimators': 1706, 'num_leaves': 2004, 'max_depth': 239, 'learning_rate': 0.0044716518964994165, 'min_child_samples': 40}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:51:44,750] Trial 57 finished with value: 0.2298507462686567 and parameters: {'n_estimators': 1855, 'num_leaves': 647, 'max_depth': 276, 'learning_rate': 0.01782544948741391, 'min_child_samples': 89}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:55:26,133] Trial 58 finished with value: 0.21565731166912852 and parameters: {'n_estimators': 1629, 'num_leaves': 2736, 'max_depth': 300, 'learning_rate': 0.013760179749450291, 'min_child_samples': 4}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:57:05,034] Trial 59 finished with value: 0.22756410256410253 and parameters: {'n_estimators': 1995, 'num_leaves': 2560, 'max_depth': 53, 'learning_rate': 0.004044898440241992, 'min_child_samples': 52}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 16:58:35,768] Trial 60 finished with value: 0.20000000000000004 and parameters: {'n_estimators': 2388, 'num_leaves': 1156, 'max_depth': 26, 'learning_rate': 0.009542161231298764, 'min_child_samples': 142}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:01:21,229] Trial 61 finished with value: 0.25813692480359146 and parameters: {'n_estimators': 2457, 'num_leaves': 2644, 'max_depth': 292, 'learning_rate': 0.0012422981780957436, 'min_child_samples': 31}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:04:22,507] Trial 62 finished with value: 0.22747415066469717 and parameters: {'n_estimators': 2769, 'num_leaves': 2890, 'max_depth': 288, 'learning_rate': 0.002871474109785895, 'min_child_samples': 31}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:05:06,121] Trial 63 finished with value: 0.23622047244094488 and parameters: {'n_estimators': 644, 'num_leaves': 2608, 'max_depth': 270, 'learning_rate': 0.008396299838286776, 'min_child_samples': 15}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:07:07,935] Trial 64 finished with value: 0.2166405023547881 and parameters: {'n_estimators': 2451, 'num_leaves': 2201, 'max_depth': 254, 'learning_rate': 0.004993950731139587, 'min_child_samples': 57}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:08:15,676] Trial 65 finished with value: 0.19759679572763686 and parameters: {'n_estimators': 1481, 'num_leaves': 2396, 'max_depth': 294, 'learning_rate': 0.09928627300228748, 'min_child_samples': 165}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:10:24,137] Trial 66 finished with value: 0.25196850393700787 and parameters: {'n_estimators': 2207, 'num_leaves': 2929, 'max_depth': 278, 'learning_rate': 0.0011538709634523003, 'min_child_samples': 40}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:11:42,735] Trial 67 finished with value: 0.20504201680672268 and parameters: {'n_estimators': 2294, 'num_leaves': 2999, 'max_depth': 278, 'learning_rate': 0.011259029034750997, 'min_child_samples': 196}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:14:29,871] Trial 68 finished with value: 0.22816901408450704 and parameters: {'n_estimators': 2086, 'num_leaves': 2910, 'max_depth': 112, 'learning_rate': 0.017785132768746718, 'min_child_samples': 23}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:17:22,955] Trial 69 finished with value: 0.2296918767507003 and parameters: {'n_estimators': 2554, 'num_leaves': 2782, 'max_depth': 264, 'learning_rate': 0.023843304604371687, 'min_child_samples': 39}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:22:12,463] Trial 70 finished with value: 0.21520803443328548 and parameters: {'n_estimators': 2210, 'num_leaves': 2713, 'max_depth': 288, 'learning_rate': 0.007944721726948406, 'min_child_samples': 7}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:24:24,522] Trial 71 finished with value: 0.24789410348977134 and parameters: {'n_estimators': 2171, 'num_leaves': 2523, 'max_depth': 279, 'learning_rate': 0.0014203419658479213, 'min_child_samples': 43}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:26:53,525] Trial 72 finished with value: 0.21954887218045116 and parameters: {'n_estimators': 2180, 'num_leaves': 2554, 'max_depth': 280, 'learning_rate': 0.005049496236835473, 'min_child_samples': 32}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:28:36,030] Trial 73 finished with value: 0.24012638230647712 and parameters: {'n_estimators': 1951, 'num_leaves': 2675, 'max_depth': 293, 'learning_rate': 0.0033740366200933807, 'min_child_samples': 48}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:31:15,726] Trial 74 finished with value: 0.21629213483146068 and parameters: {'n_estimators': 2042, 'num_leaves': 2504, 'max_depth': 242, 'learning_rate': 0.010861243557634768, 'min_child_samples': 19}. Best is trial 2 with value: 0.2627406568516421.\n",
      "[I 2024-09-28 17:32:31,515] Trial 75 finished with value: 0.26951871657754006 and parameters: {'n_estimators': 2404, 'num_leaves': 2769, 'max_depth': 271, 'learning_rate': 0.0011233524385318504, 'min_child_samples': 258}. Best is trial 75 with value: 0.26951871657754006.\n",
      "[I 2024-09-28 17:34:00,502] Trial 76 finished with value: 0.2057335581787521 and parameters: {'n_estimators': 2643, 'num_leaves': 2916, 'max_depth': 258, 'learning_rate': 0.015408696595936086, 'min_child_samples': 269}. Best is trial 75 with value: 0.26951871657754006.\n",
      "[I 2024-09-28 17:35:07,378] Trial 77 finished with value: 0.21088435374149658 and parameters: {'n_estimators': 2420, 'num_leaves': 2783, 'max_depth': 130, 'learning_rate': 0.007291929954335495, 'min_child_samples': 259}. Best is trial 75 with value: 0.26951871657754006.\n",
      "[I 2024-09-28 17:36:36,702] Trial 78 finished with value: 0.21319796954314724 and parameters: {'n_estimators': 2503, 'num_leaves': 2627, 'max_depth': 300, 'learning_rate': 0.004495146236987396, 'min_child_samples': 233}. Best is trial 75 with value: 0.26951871657754006.\n",
      "[I 2024-09-28 17:38:06,103] Trial 79 finished with value: 0.2003338898163606 and parameters: {'n_estimators': 2287, 'num_leaves': 2853, 'max_depth': 270, 'learning_rate': 0.012422422012993498, 'min_child_samples': 184}. Best is trial 75 with value: 0.26951871657754006.\n",
      "[I 2024-09-28 17:40:32,062] Trial 80 finished with value: 0.2726146220570012 and parameters: {'n_estimators': 2726, 'num_leaves': 2349, 'max_depth': 157, 'learning_rate': 0.001182943764371799, 'min_child_samples': 58}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:42:06,661] Trial 81 finished with value: 0.21368948247078465 and parameters: {'n_estimators': 2592, 'num_leaves': 2408, 'max_depth': 286, 'learning_rate': 0.0035742464556327916, 'min_child_samples': 215}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:45:12,603] Trial 82 finished with value: 0.25170068027210885 and parameters: {'n_estimators': 2817, 'num_leaves': 2085, 'max_depth': 78, 'learning_rate': 0.0012150650112828267, 'min_child_samples': 26}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:48:29,597] Trial 83 finished with value: 0.22005571030640667 and parameters: {'n_estimators': 2881, 'num_leaves': 2242, 'max_depth': 165, 'learning_rate': 0.007901491615774046, 'min_child_samples': 34}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:50:39,945] Trial 84 finished with value: 0.2532005689900427 and parameters: {'n_estimators': 2742, 'num_leaves': 2061, 'max_depth': 68, 'learning_rate': 0.0014563599407093689, 'min_child_samples': 61}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:52:46,567] Trial 85 finished with value: 0.2181818181818182 and parameters: {'n_estimators': 2738, 'num_leaves': 2352, 'max_depth': 36, 'learning_rate': 0.006318174564970246, 'min_child_samples': 61}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:54:57,010] Trial 86 finished with value: 0.22674418604651161 and parameters: {'n_estimators': 2992, 'num_leaves': 1890, 'max_depth': 61, 'learning_rate': 0.009860373469307035, 'min_child_samples': 77}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 17:57:30,096] Trial 87 finished with value: 0.23109843081312412 and parameters: {'n_estimators': 2361, 'num_leaves': 2445, 'max_depth': 74, 'learning_rate': 0.0758926781599207, 'min_child_samples': 67}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:00:24,273] Trial 88 finished with value: 0.22063037249283665 and parameters: {'n_estimators': 2702, 'num_leaves': 2213, 'max_depth': 40, 'learning_rate': 0.05369176039717148, 'min_child_samples': 55}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:02:19,167] Trial 89 finished with value: 0.19765494137353434 and parameters: {'n_estimators': 2630, 'num_leaves': 1744, 'max_depth': 246, 'learning_rate': 0.004457381110237923, 'min_child_samples': 93}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:04:15,724] Trial 90 finished with value: 0.25991792065663477 and parameters: {'n_estimators': 2507, 'num_leaves': 2054, 'max_depth': 45, 'learning_rate': 0.0013977549258018859, 'min_child_samples': 73}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:06:32,843] Trial 91 finished with value: 0.225705329153605 and parameters: {'n_estimators': 2537, 'num_leaves': 2121, 'max_depth': 22, 'learning_rate': 0.0031196602009333028, 'min_child_samples': 47}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:08:50,293] Trial 92 finished with value: 0.2616352201257861 and parameters: {'n_estimators': 2903, 'num_leaves': 1904, 'max_depth': 47, 'learning_rate': 0.0011020203173738806, 'min_child_samples': 72}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:11:34,128] Trial 93 finished with value: 0.2225656877897991 and parameters: {'n_estimators': 2939, 'num_leaves': 2055, 'max_depth': 51, 'learning_rate': 0.00706115110275834, 'min_child_samples': 73}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:14:17,775] Trial 94 finished with value: 0.22903225806451616 and parameters: {'n_estimators': 2827, 'num_leaves': 1624, 'max_depth': 42, 'learning_rate': 0.0034296838254281384, 'min_child_samples': 61}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:17:11,923] Trial 95 finished with value: 0.21823204419889505 and parameters: {'n_estimators': 2782, 'num_leaves': 1869, 'max_depth': 48, 'learning_rate': 0.04151302431996422, 'min_child_samples': 82}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:19:22,020] Trial 96 finished with value: 0.22641509433962265 and parameters: {'n_estimators': 2699, 'num_leaves': 2000, 'max_depth': 58, 'learning_rate': 0.009687566130114454, 'min_child_samples': 69}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:20:58,254] Trial 97 finished with value: 0.203125 and parameters: {'n_estimators': 2463, 'num_leaves': 2161, 'max_depth': 16, 'learning_rate': 0.014235010863656241, 'min_child_samples': 106}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:23:17,358] Trial 98 finished with value: 0.21686746987951808 and parameters: {'n_estimators': 2922, 'num_leaves': 2312, 'max_depth': 83, 'learning_rate': 0.00578185670748684, 'min_child_samples': 56}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:24:55,408] Trial 99 finished with value: 0.19722222222222224 and parameters: {'n_estimators': 2348, 'num_leaves': 2038, 'max_depth': 69, 'learning_rate': 0.029642699514467383, 'min_child_samples': 122}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:25:53,042] Trial 100 finished with value: 0.17303935249790678 and parameters: {'n_estimators': 1580, 'num_leaves': 1769, 'max_depth': 100, 'learning_rate': 0.001002753826711317, 'min_child_samples': 91}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:27:59,536] Trial 101 finished with value: 0.22734254992319508 and parameters: {'n_estimators': 2246, 'num_leaves': 1922, 'max_depth': 271, 'learning_rate': 0.002825166509809033, 'min_child_samples': 36}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:30:13,232] Trial 102 finished with value: 0.2621145374449339 and parameters: {'n_estimators': 2591, 'num_leaves': 2587, 'max_depth': 67, 'learning_rate': 0.0011209959608051937, 'min_child_samples': 41}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:32:17,460] Trial 103 finished with value: 0.21460506706408347 and parameters: {'n_estimators': 2574, 'num_leaves': 2459, 'max_depth': 31, 'learning_rate': 0.006598714062772383, 'min_child_samples': 52}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:34:09,539] Trial 104 finished with value: 0.21954887218045116 and parameters: {'n_estimators': 2494, 'num_leaves': 1941, 'max_depth': 45, 'learning_rate': 0.00860466218103972, 'min_child_samples': 62}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:39:32,584] Trial 105 finished with value: 0.20054200542005418 and parameters: {'n_estimators': 2874, 'num_leaves': 2604, 'max_depth': 66, 'learning_rate': 0.004917327452548444, 'min_child_samples': 8}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:41:11,287] Trial 106 finished with value: 0.2273476112026359 and parameters: {'n_estimators': 2412, 'num_leaves': 2343, 'max_depth': 56, 'learning_rate': 0.0029645986479362556, 'min_child_samples': 74}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:43:58,682] Trial 107 finished with value: 0.22503516174402252 and parameters: {'n_estimators': 2632, 'num_leaves': 2180, 'max_depth': 92, 'learning_rate': 0.01201313626892302, 'min_child_samples': 29}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:45:42,083] Trial 108 finished with value: 0.2575406032482599 and parameters: {'n_estimators': 2729, 'num_leaves': 1825, 'max_depth': 185, 'learning_rate': 0.00108600055461674, 'min_child_samples': 97}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:47:10,858] Trial 109 finished with value: 0.19666666666666666 and parameters: {'n_estimators': 2670, 'num_leaves': 1820, 'max_depth': 147, 'learning_rate': 0.005770304305696659, 'min_child_samples': 139}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:48:44,229] Trial 110 finished with value: 0.1996779388083736 and parameters: {'n_estimators': 2521, 'num_leaves': 1593, 'max_depth': 177, 'learning_rate': 0.008238435656295841, 'min_child_samples': 101}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:51:03,454] Trial 111 finished with value: 0.22468354430379744 and parameters: {'n_estimators': 2729, 'num_leaves': 1720, 'max_depth': 158, 'learning_rate': 0.0028201256243002965, 'min_child_samples': 44}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:52:55,263] Trial 112 finished with value: 0.2641946697566628 and parameters: {'n_estimators': 2779, 'num_leaves': 2692, 'max_depth': 207, 'learning_rate': 0.0010302786005717203, 'min_child_samples': 83}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:53:43,843] Trial 113 finished with value: 0.10302036993678296 and parameters: {'n_estimators': 1325, 'num_leaves': 2672, 'max_depth': 208, 'learning_rate': 0.0010068761310790726, 'min_child_samples': 82}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:55:21,979] Trial 114 finished with value: 0.19666666666666666 and parameters: {'n_estimators': 2610, 'num_leaves': 2587, 'max_depth': 187, 'learning_rate': 0.004740481925061814, 'min_child_samples': 98}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:57:59,708] Trial 115 finished with value: 0.20190995907230558 and parameters: {'n_estimators': 2795, 'num_leaves': 2700, 'max_depth': 131, 'learning_rate': 0.0640494473239924, 'min_child_samples': 95}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 18:59:27,347] Trial 116 finished with value: 0.20952380952380953 and parameters: {'n_estimators': 2455, 'num_leaves': 2759, 'max_depth': 193, 'learning_rate': 0.010667190647184943, 'min_child_samples': 116}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 19:00:15,628] Trial 117 finished with value: 0.1996615905245347 and parameters: {'n_estimators': 1432, 'num_leaves': 2524, 'max_depth': 220, 'learning_rate': 0.0067943303994050085, 'min_child_samples': 109}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 19:02:18,461] Trial 118 finished with value: 0.22580645161290322 and parameters: {'n_estimators': 2866, 'num_leaves': 2479, 'max_depth': 156, 'learning_rate': 0.003058045932557177, 'min_child_samples': 68}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 19:03:44,761] Trial 119 finished with value: 0.20066889632107024 and parameters: {'n_estimators': 2572, 'num_leaves': 2553, 'max_depth': 226, 'learning_rate': 0.004710129880637831, 'min_child_samples': 128}. Best is trial 80 with value: 0.2726146220570012.\n",
      "[I 2024-09-28 19:05:01,206] Trial 120 finished with value: 0.273190621814475 and parameters: {'n_estimators': 2395, 'num_leaves': 1471, 'max_depth': 113, 'learning_rate': 0.0010583958780857154, 'min_child_samples': 150}. Best is trial 120 with value: 0.273190621814475.\n",
      "[I 2024-09-28 19:06:14,377] Trial 121 finished with value: 0.27705627705627706 and parameters: {'n_estimators': 2328, 'num_leaves': 1384, 'max_depth': 166, 'learning_rate': 0.0011349565587889664, 'min_child_samples': 163}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:07:30,158] Trial 122 finished with value: 0.21782178217821782 and parameters: {'n_estimators': 2321, 'num_leaves': 1382, 'max_depth': 168, 'learning_rate': 0.003162783617062327, 'min_child_samples': 161}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:08:42,953] Trial 123 finished with value: 0.2737967914438503 and parameters: {'n_estimators': 2390, 'num_leaves': 1252, 'max_depth': 162, 'learning_rate': 0.001118554978459863, 'min_child_samples': 179}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:10:03,494] Trial 124 finished with value: 0.21192052980132453 and parameters: {'n_estimators': 2395, 'num_leaves': 1235, 'max_depth': 112, 'learning_rate': 0.007959449363282503, 'min_child_samples': 149}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:11:21,995] Trial 125 finished with value: 0.19727891156462582 and parameters: {'n_estimators': 2430, 'num_leaves': 1160, 'max_depth': 160, 'learning_rate': 0.005948285057931331, 'min_child_samples': 170}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:12:30,321] Trial 126 finished with value: 0.21630615640599002 and parameters: {'n_estimators': 2260, 'num_leaves': 1348, 'max_depth': 141, 'learning_rate': 0.0037712845622636807, 'min_child_samples': 180}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[I 2024-09-28 19:13:32,276] Trial 127 finished with value: 0.21440536013400335 and parameters: {'n_estimators': 2373, 'num_leaves': 1469, 'max_depth': 175, 'learning_rate': 0.009458463857124124, 'min_child_samples': 244}. Best is trial 121 with value: 0.27705627705627706.\n",
      "[W 2024-09-28 19:13:44,493] Trial 128 failed with parameters: {'n_estimators': 2484, 'num_leaves': 1284, 'max_depth': 150, 'learning_rate': 0.004797147491810743, 'min_child_samples': 150} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_23788\\311198498.py\", line 45, in <lambda>\n",
      "    study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_23788\\311198498.py\", line 26, in objectiveLGBM_dart\n",
      "    model.fit(x_tr, y_tr)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1298, in fit\n",
      "    init_model=init_model,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 963, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\", line 4138, in update\n",
      "    ctypes.byref(is_finished),\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-28 19:13:44,500] Trial 128 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23788\\311198498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23788\\311198498.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23788\\311198498.py\u001b[0m in \u001b[0;36mobjectiveLGBM_dart\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 양성 클래스 확률\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_proba\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 스레드홀드에 따른 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4136\u001b[0m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m                 )\n\u001b[0;32m   4140\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_fill2['target'] = train_data_fill2['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill2.drop(\"target\", axis=1),\n",
    "    train_data_fill2[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e849c9e",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
