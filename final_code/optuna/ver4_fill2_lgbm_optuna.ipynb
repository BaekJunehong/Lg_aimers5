{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570f8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./data/train_data_ver4.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_data_ver4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52fcef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'PalletID_Collect_Result',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'Receip_No_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70793df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df3b81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb5b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af8da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82ed5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 39\n",
      "train_data_dam DataFrame의 칼럼 수: 20\n",
      "train_data_autoclave DataFrame의 칼럼 수: 9\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 40\n",
      "test_data_dam DataFrame의 칼럼 수: 21\n",
      "test_data_autoclave DataFrame의 칼럼 수: 10\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4132/704068152.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data_fill2['target'] = train_data_fill2['target'].map({'Normal': 0, 'AbNormal': 1})\n",
      "[I 2024-09-28 23:07:54,744] A new study created in memory with name: no-name-cdc4ea64-97ef-4752-bfbb-628e95467159\n",
      "[I 2024-09-28 23:08:41,502] Trial 0 finished with value: 0.24408014571949002 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:14:14,349] Trial 1 finished with value: 0.19911504424778761 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:15:54,255] Trial 2 finished with value: 0.21733505821474772 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:17:56,905] Trial 3 finished with value: 0.2365988909426987 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:19:48,407] Trial 4 finished with value: 0.2267080745341615 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:20:22,986] Trial 5 finished with value: 0.23776223776223776 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:25:48,303] Trial 6 finished with value: 0.19887005649717515 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:29:14,220] Trial 7 finished with value: 0.22446043165467627 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:32:16,101] Trial 8 finished with value: 0.21090047393364933 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:32:39,289] Trial 9 finished with value: 0.2140221402214022 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:33:53,482] Trial 10 finished with value: 0.23127035830618894 and parameters: {'n_estimators': 996, 'num_leaves': 1534, 'max_depth': 104, 'learning_rate': 0.09731505694411961, 'min_child_samples': 211}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:34:15,872] Trial 11 finished with value: 0.1973929236499069 and parameters: {'n_estimators': 519, 'num_leaves': 1002, 'max_depth': 300, 'learning_rate': 0.040338453467110576, 'min_child_samples': 191}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:35:20,922] Trial 12 finished with value: 0.23971377459749552 and parameters: {'n_estimators': 924, 'num_leaves': 1852, 'max_depth': 276, 'learning_rate': 0.059047712126274104, 'min_child_samples': 184}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:40:03,791] Trial 13 finished with value: 0.22395833333333337 and parameters: {'n_estimators': 2922, 'num_leaves': 1932, 'max_depth': 120, 'learning_rate': 0.07222876152309926, 'min_child_samples': 194}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:40:58,684] Trial 14 finished with value: 0.22222222222222218 and parameters: {'n_estimators': 963, 'num_leaves': 1484, 'max_depth': 13, 'learning_rate': 0.06468044460156709, 'min_child_samples': 246}. Best is trial 0 with value: 0.24408014571949002.\n",
      "[I 2024-09-28 23:42:04,305] Trial 15 finished with value: 0.24581005586592178 and parameters: {'n_estimators': 1034, 'num_leaves': 2141, 'max_depth': 231, 'learning_rate': 0.02588903555727193, 'min_child_samples': 175}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:43:14,842] Trial 16 finished with value: 0.21892393320964748 and parameters: {'n_estimators': 1202, 'num_leaves': 2845, 'max_depth': 220, 'learning_rate': 0.026744213003533527, 'min_child_samples': 245}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:44:00,597] Trial 17 finished with value: 0.24489795918367346 and parameters: {'n_estimators': 828, 'num_leaves': 2161, 'max_depth': 130, 'learning_rate': 0.02582779387438112, 'min_child_samples': 166}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:46:17,466] Trial 18 finished with value: 0.23801065719360567 and parameters: {'n_estimators': 1827, 'num_leaves': 2602, 'max_depth': 155, 'learning_rate': 0.026373053390696805, 'min_child_samples': 163}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:48:34,011] Trial 19 finished with value: 0.24175824175824173 and parameters: {'n_estimators': 1864, 'num_leaves': 2084, 'max_depth': 222, 'learning_rate': 0.015830807137607587, 'min_child_samples': 152}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:51:11,740] Trial 20 finished with value: 0.20044052863436124 and parameters: {'n_estimators': 1211, 'num_leaves': 1540, 'max_depth': 143, 'learning_rate': 0.03435161631825513, 'min_child_samples': 3}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:51:53,868] Trial 21 finished with value: 0.21033210332103325 and parameters: {'n_estimators': 807, 'num_leaves': 2164, 'max_depth': 103, 'learning_rate': 0.03252333238220213, 'min_child_samples': 230}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:52:27,203] Trial 22 finished with value: 0.21184919210053862 and parameters: {'n_estimators': 757, 'num_leaves': 2613, 'max_depth': 64, 'learning_rate': 0.013812979575405258, 'min_child_samples': 275}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:53:07,601] Trial 23 finished with value: 0.23853211009174316 and parameters: {'n_estimators': 708, 'num_leaves': 1990, 'max_depth': 88, 'learning_rate': 0.04864137070213829, 'min_child_samples': 168}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:54:29,600] Trial 24 finished with value: 0.23591549295774647 and parameters: {'n_estimators': 1078, 'num_leaves': 2275, 'max_depth': 135, 'learning_rate': 0.03862725649777801, 'min_child_samples': 126}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:56:32,670] Trial 25 finished with value: 0.23529411764705888 and parameters: {'n_estimators': 1497, 'num_leaves': 2527, 'max_depth': 168, 'learning_rate': 0.07857374173756171, 'min_child_samples': 209}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:57:16,112] Trial 26 finished with value: 0.241635687732342 and parameters: {'n_estimators': 764, 'num_leaves': 1737, 'max_depth': 204, 'learning_rate': 0.02429542175371983, 'min_child_samples': 138}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:58:47,039] Trial 27 finished with value: 0.24381625441696111 and parameters: {'n_estimators': 1272, 'num_leaves': 1696, 'max_depth': 79, 'learning_rate': 0.055531125427864536, 'min_child_samples': 225}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-28 23:59:46,033] Trial 28 finished with value: 0.22185970636215335 and parameters: {'n_estimators': 1069, 'num_leaves': 2136, 'max_depth': 22, 'learning_rate': 0.003952506194687452, 'min_child_samples': 173}. Best is trial 15 with value: 0.24581005586592178.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-09-29 00:03:14,408] Trial 29 finished with value: 0.21939586645469 and parameters: {'n_estimators': 2701, 'num_leaves': 2655, 'max_depth': 207, 'learning_rate': 0.04618696128522181, 'min_child_samples': 257}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:05:40,671] Trial 30 finished with value: 0.22222222222222224 and parameters: {'n_estimators': 1662, 'num_leaves': 2931, 'max_depth': 151, 'learning_rate': 0.03273690408542684, 'min_child_samples': 98}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:07:18,435] Trial 31 finished with value: 0.23752151462994836 and parameters: {'n_estimators': 1330, 'num_leaves': 1672, 'max_depth': 91, 'learning_rate': 0.05952411254006535, 'min_child_samples': 222}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:08:14,889] Trial 32 finished with value: 0.23247232472324722 and parameters: {'n_estimators': 895, 'num_leaves': 1282, 'max_depth': 75, 'learning_rate': 0.055226362355429805, 'min_child_samples': 203}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:09:36,234] Trial 33 finished with value: 0.24041811846689898 and parameters: {'n_estimators': 1152, 'num_leaves': 2034, 'max_depth': 48, 'learning_rate': 0.06613740921247976, 'min_child_samples': 228}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:11:30,355] Trial 34 finished with value: 0.22009569377990432 and parameters: {'n_estimators': 1355, 'num_leaves': 2262, 'max_depth': 131, 'learning_rate': 0.0539833005407077, 'min_child_samples': 147}. Best is trial 15 with value: 0.24581005586592178.\n",
      "[I 2024-09-29 00:12:11,833] Trial 35 finished with value: 0.24686940966010737 and parameters: {'n_estimators': 702, 'num_leaves': 1297, 'max_depth': 111, 'learning_rate': 0.07270644607562114, 'min_child_samples': 181}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 00:12:54,045] Trial 36 finished with value: 0.23338735818476503 and parameters: {'n_estimators': 644, 'num_leaves': 986, 'max_depth': 105, 'learning_rate': 0.07614998741232672, 'min_child_samples': 110}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 00:13:53,943] Trial 37 finished with value: 0.23232323232323232 and parameters: {'n_estimators': 852, 'num_leaves': 1258, 'max_depth': 169, 'learning_rate': 0.08613768246488508, 'min_child_samples': 185}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 00:14:25,054] Trial 38 finished with value: 0.21973929236499068 and parameters: {'n_estimators': 639, 'num_leaves': 1045, 'max_depth': 121, 'learning_rate': 0.01758778832133575, 'min_child_samples': 140}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 00:14:55,692] Trial 39 finished with value: 0.2226148409893993 and parameters: {'n_estimators': 653, 'num_leaves': 2423, 'max_depth': 192, 'learning_rate': 0.009505257170434045, 'min_child_samples': 163}. Best is trial 35 with value: 0.24686940966010737.\n",
      "[I 2024-09-29 00:17:16,908] Trial 40 finished with value: 0.2235294117647059 and parameters: {'n_estimators': 1623, 'num_leaves': 2777, 'max_depth': 250, 'learning_rate': 0.06762787133773411, 'min_child_samples': 174}. Best is trial 35 with value: 0.24686940966010737.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_fill2['target'] = train_data_fill2['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill2.drop(\"target\", axis=1),\n",
    "    train_data_fill2[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=300)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3fc4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name]\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e257145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_fill2 데이터로 학습한 결과:\n",
      "F1 Score: 0.24233983286908078\n",
      "---\n",
      "Confusion Matrix:\n",
      "[[7471  191]\n",
      " [ 353   87]]\n",
      "---\n",
      "Accuracy: 0.9328560849173043\n",
      "Precision: 0.3129496402877698\n",
      "Recall: 0.19772727272727272\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1998, \n",
    "    learning_rate = 0.030898693059763598, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.0017554538174868774, \n",
    "    gamma = 0.0007257577447593802, \n",
    "    reg_alpha = 0.7581280398368035, \n",
    "    reg_lambda = 0.5872331353519633, \n",
    "    colsample_bytree = 0.56275606593282, \n",
    "    subsample = 0.8342870707789082,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6892ae",
   "metadata": {},
   "source": [
    "xgb 모델이 train_data_fill2 데이터로 학습한 결과:\n",
    "\n",
    "F1 Score: 0.24233983286908078\n",
    "\n",
    "Confusion Matrix:\n",
    "[[7471  191]\n",
    " [ 353   87]]\n",
    "\n",
    "Accuracy: 0.9328560849173043\n",
    "Precision: 0.3129496402877698\n",
    "Recall: 0.19772727272727272\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d461c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2-5. Fill2\n",
    "# train_model_Fill2 = train_and_evaluate_model(\n",
    "#     'xgb', train_data_fill2\n",
    "#     , n_estimators = 488\n",
    "#     , learning_rate = 0.27456156507923796\n",
    "#     , max_depth = 18\n",
    "#     , alpha = 0.001345329538356762\n",
    "#     , gamma = 0.001271261094255318\n",
    "#     , reg_alpha = 0.8757519133030134\n",
    "#     , reg_lambda = 0.08373579326505055\n",
    "#     , colsample_bytree = 0.8186279659279335\n",
    "#     , subsample = 0.24909941675865316\n",
    "#     , objective = 'binary:logistic'\n",
    "#     , tree_method = 'exact'\n",
    "#     , random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293ee6a",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ecc88d",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
