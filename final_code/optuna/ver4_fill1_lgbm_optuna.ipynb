{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5468dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./final_data/train_data_ver4.csv\")\n",
    "test_data = pd.read_csv(\"./final_data/test_data_ver4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84efc2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'PalletID_Collect_Result',\n",
    "    'Production_Qty_Collect_Result',\n",
    "    'Receip_No_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be6bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_receip_combined_encoded',\n",
    "    'cleaned_workorder_encoded',\n",
    "    'time_gap_All'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab42a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e7e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81578ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b2cfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ea40b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 39\n",
      "train_data_dam DataFrame의 칼럼 수: 20\n",
      "train_data_autoclave DataFrame의 칼럼 수: 9\n",
      "train_data_fill1 DataFrame의 칼럼 수: 14\n",
      "train_data_fill2 DataFrame의 칼럼 수: 14\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 40\n",
      "test_data_dam DataFrame의 칼럼 수: 21\n",
      "test_data_autoclave DataFrame의 칼럼 수: 10\n",
      "test_data_fill1 DataFrame의 칼럼 수: 15\n",
      "test_data_fill2 DataFrame의 칼럼 수: 15\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45a10a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f4f86",
   "metadata": {},
   "source": [
    "스레스홀드 0.3으로 맞춘상태에서 튜닝 진행한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f1f651b-d56f-4b1b-90cc-12270e83463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 110\n",
    "THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2608ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juneh\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "[I 2024-09-29 07:56:07,142] A new study created in memory with name: no-name-c49cf848-ecd4-4b65-aca3-9a9ad687d005\n",
      "[I 2024-09-29 07:56:21,088] Trial 0 finished with value: 0.19133574007220217 and parameters: {'n_estimators': 790, 'num_leaves': 2146, 'max_depth': 119, 'learning_rate': 0.06166547557397882, 'min_child_samples': 205}. Best is trial 0 with value: 0.19133574007220217.\n",
      "[I 2024-09-29 07:59:04,597] Trial 1 finished with value: 0.19102416570771003 and parameters: {'n_estimators': 2206, 'num_leaves': 2888, 'max_depth': 195, 'learning_rate': 0.05178141716690417, 'min_child_samples': 28}. Best is trial 0 with value: 0.19133574007220217.\n",
      "[I 2024-09-29 07:59:51,166] Trial 2 finished with value: 0.17179487179487177 and parameters: {'n_estimators': 1469, 'num_leaves': 1226, 'max_depth': 49, 'learning_rate': 0.002000452888170992, 'min_child_samples': 126}. Best is trial 0 with value: 0.19133574007220217.\n",
      "[I 2024-09-29 08:00:48,354] Trial 3 finished with value: 0.16206261510128914 and parameters: {'n_estimators': 1731, 'num_leaves': 553, 'max_depth': 172, 'learning_rate': 0.008684052021612865, 'min_child_samples': 124}. Best is trial 0 with value: 0.19133574007220217.\n",
      "[I 2024-09-29 08:01:41,818] Trial 4 finished with value: 0.19161676646706588 and parameters: {'n_estimators': 1285, 'num_leaves': 2427, 'max_depth': 184, 'learning_rate': 0.042318458794414655, 'min_child_samples': 102}. Best is trial 4 with value: 0.19161676646706588.\n",
      "[I 2024-09-29 08:01:58,830] Trial 5 finished with value: 0.2154882154882155 and parameters: {'n_estimators': 562, 'num_leaves': 723, 'max_depth': 258, 'learning_rate': 0.04962001162483311, 'min_child_samples': 77}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:04:27,281] Trial 6 finished with value: 0.1940639269406393 and parameters: {'n_estimators': 2403, 'num_leaves': 1851, 'max_depth': 122, 'learning_rate': 0.06476333477413102, 'min_child_samples': 54}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:06:07,372] Trial 7 finished with value: 0.20815752461322085 and parameters: {'n_estimators': 2273, 'num_leaves': 600, 'max_depth': 184, 'learning_rate': 0.02113127234039541, 'min_child_samples': 77}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:07:27,621] Trial 8 finished with value: 0.21052631578947367 and parameters: {'n_estimators': 1498, 'num_leaves': 2285, 'max_depth': 240, 'learning_rate': 0.08959229338857824, 'min_child_samples': 68}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:07:38,118] Trial 9 finished with value: 0.14503816793893132 and parameters: {'n_estimators': 532, 'num_leaves': 2402, 'max_depth': 63, 'learning_rate': 0.0795619223737381, 'min_child_samples': 286}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:08:05,249] Trial 10 finished with value: 0.1821561338289963 and parameters: {'n_estimators': 1010, 'num_leaves': 1104, 'max_depth': 286, 'learning_rate': 0.03483524235844172, 'min_child_samples': 190}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:10:03,698] Trial 11 finished with value: 0.18928164196123146 and parameters: {'n_estimators': 1803, 'num_leaves': 1470, 'max_depth': 277, 'learning_rate': 0.09817862694370527, 'min_child_samples': 7}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:12:18,231] Trial 12 finished with value: 0.19274376417233557 and parameters: {'n_estimators': 2867, 'num_leaves': 2846, 'max_depth': 241, 'learning_rate': 0.07962551796241299, 'min_child_samples': 68}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:12:26,853] Trial 13 finished with value: 0.19354838709677422 and parameters: {'n_estimators': 512, 'num_leaves': 1769, 'max_depth': 232, 'learning_rate': 0.0972683392531865, 'min_child_samples': 191}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:12:56,715] Trial 14 finished with value: 0.19364599092284418 and parameters: {'n_estimators': 1128, 'num_leaves': 954, 'max_depth': 238, 'learning_rate': 0.07702778909497249, 'min_child_samples': 159}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:14:03,762] Trial 15 finished with value: 0.21356783919597988 and parameters: {'n_estimators': 1632, 'num_leaves': 2176, 'max_depth': 293, 'learning_rate': 0.03319515739020328, 'min_child_samples': 44}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:18:05,728] Trial 16 finished with value: 0.18837209302325583 and parameters: {'n_estimators': 2939, 'num_leaves': 1447, 'max_depth': 297, 'learning_rate': 0.0273007939146066, 'min_child_samples': 3}. Best is trial 5 with value: 0.2154882154882155.\n",
      "[I 2024-09-29 08:19:13,105] Trial 17 finished with value: 0.2157434402332362 and parameters: {'n_estimators': 1928, 'num_leaves': 778, 'max_depth': 12, 'learning_rate': 0.0481574514434557, 'min_child_samples': 38}. Best is trial 17 with value: 0.2157434402332362.\n",
      "[I 2024-09-29 08:20:45,759] Trial 18 finished with value: 0.17179487179487177 and parameters: {'n_estimators': 2013, 'num_leaves': 808, 'max_depth': 97, 'learning_rate': 0.05318173091660466, 'min_child_samples': 101}. Best is trial 17 with value: 0.2157434402332362.\n",
      "[I 2024-09-29 08:21:40,297] Trial 19 finished with value: 0.1646234676007005 and parameters: {'n_estimators': 1913, 'num_leaves': 764, 'max_depth': 12, 'learning_rate': 0.06398335413076864, 'min_child_samples': 300}. Best is trial 17 with value: 0.2157434402332362.\n",
      "[I 2024-09-29 08:23:27,273] Trial 20 finished with value: 0.18156028368794327 and parameters: {'n_estimators': 2578, 'num_leaves': 1403, 'max_depth': 17, 'learning_rate': 0.04444087651459614, 'min_child_samples': 95}. Best is trial 17 with value: 0.2157434402332362.\n",
      "[I 2024-09-29 08:24:53,489] Trial 21 finished with value: 0.20884520884520885 and parameters: {'n_estimators': 1583, 'num_leaves': 1981, 'max_depth': 264, 'learning_rate': 0.03252333238220215, 'min_child_samples': 39}. Best is trial 17 with value: 0.2157434402332362.\n",
      "[I 2024-09-29 08:25:30,418] Trial 22 finished with value: 0.21603927986906707 and parameters: {'n_estimators': 872, 'num_leaves': 2613, 'max_depth': 219, 'learning_rate': 0.018387124012829117, 'min_child_samples': 41}. Best is trial 22 with value: 0.21603927986906707.\n",
      "[I 2024-09-29 08:26:09,698] Trial 23 finished with value: 0.2255192878338279 and parameters: {'n_estimators': 801, 'num_leaves': 1061, 'max_depth': 211, 'learning_rate': 0.018715663647142014, 'min_child_samples': 26}. Best is trial 23 with value: 0.2255192878338279.\n",
      "[I 2024-09-29 08:27:03,846] Trial 24 finished with value: 0.2121640735502122 and parameters: {'n_estimators': 986, 'num_leaves': 2595, 'max_depth': 211, 'learning_rate': 0.01648151941407899, 'min_child_samples': 24}. Best is trial 23 with value: 0.2255192878338279.\n",
      "[I 2024-09-29 08:27:20,869] Trial 25 finished with value: 0.13011152416356878 and parameters: {'n_estimators': 826, 'num_leaves': 978, 'max_depth': 153, 'learning_rate': 0.013957853003832529, 'min_child_samples': 245}. Best is trial 23 with value: 0.2255192878338279.\n",
      "[I 2024-09-29 08:28:37,578] Trial 26 finished with value: 0.22281167108753316 and parameters: {'n_estimators': 1182, 'num_leaves': 1590, 'max_depth': 213, 'learning_rate': 0.004042011004792989, 'min_child_samples': 17}. Best is trial 23 with value: 0.2255192878338279.\n",
      "[I 2024-09-29 08:30:12,273] Trial 27 finished with value: 0.2316043425814234 and parameters: {'n_estimators': 1274, 'num_leaves': 1696, 'max_depth': 216, 'learning_rate': 0.0034227172793110452, 'min_child_samples': 14}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:31:44,033] Trial 28 finished with value: 0.19363762102351315 and parameters: {'n_estimators': 1229, 'num_leaves': 1624, 'max_depth': 166, 'learning_rate': 0.0019078544403017873, 'min_child_samples': 13}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:32:23,673] Trial 29 finished with value: 0.12781954887218044 and parameters: {'n_estimators': 1340, 'num_leaves': 2016, 'max_depth': 137, 'learning_rate': 0.008032331873399436, 'min_child_samples': 161}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:32:45,215] Trial 30 finished with value: 0.17439703153988867 and parameters: {'n_estimators': 785, 'num_leaves': 1598, 'max_depth': 211, 'learning_rate': 0.02540318739547493, 'min_child_samples': 129}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:33:12,845] Trial 31 finished with value: 0.22459893048128343 and parameters: {'n_estimators': 771, 'num_leaves': 1270, 'max_depth': 212, 'learning_rate': 0.011112079423716432, 'min_child_samples': 56}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:33:47,442] Trial 32 finished with value: 0.21913580246913583 and parameters: {'n_estimators': 667, 'num_leaves': 1282, 'max_depth': 198, 'learning_rate': 0.011054328993323315, 'min_child_samples': 21}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:34:26,453] Trial 33 finished with value: 0.10302036993678296 and parameters: {'n_estimators': 1050, 'num_leaves': 1132, 'max_depth': 201, 'learning_rate': 0.0012667246715932692, 'min_child_samples': 57}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:35:28,198] Trial 34 finished with value: 0.2261146496815287 and parameters: {'n_estimators': 1167, 'num_leaves': 1307, 'max_depth': 259, 'learning_rate': 0.008586849494937997, 'min_child_samples': 27}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:36:44,220] Trial 35 finished with value: 0.22257053291536052 and parameters: {'n_estimators': 1399, 'num_leaves': 1251, 'max_depth': 259, 'learning_rate': 0.008435312567778956, 'min_child_samples': 30}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:37:16,832] Trial 36 finished with value: 0.20284697508896796 and parameters: {'n_estimators': 923, 'num_leaves': 1007, 'max_depth': 226, 'learning_rate': 0.022612619501107763, 'min_child_samples': 88}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:37:39,529] Trial 37 finished with value: 0.21390374331550802 and parameters: {'n_estimators': 660, 'num_leaves': 1347, 'max_depth': 181, 'learning_rate': 0.013948411612316233, 'min_child_samples': 55}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:38:05,728] Trial 38 finished with value: 0.22885572139303484 and parameters: {'n_estimators': 736, 'num_leaves': 1160, 'max_depth': 269, 'learning_rate': 0.006814004815004845, 'min_child_samples': 53}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:38:22,351] Trial 39 finished with value: 0.15357766143106458 and parameters: {'n_estimators': 670, 'num_leaves': 1120, 'max_depth': 276, 'learning_rate': 0.006269585104808982, 'min_child_samples': 116}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:39:03,972] Trial 40 finished with value: 0.2122719734660033 and parameters: {'n_estimators': 1073, 'num_leaves': 1835, 'max_depth': 250, 'learning_rate': 0.028002950644028194, 'min_child_samples': 78}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:39:32,194] Trial 41 finished with value: 0.21669626998223804 and parameters: {'n_estimators': 758, 'num_leaves': 881, 'max_depth': 263, 'learning_rate': 0.012346477235489737, 'min_child_samples': 51}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:40:18,376] Trial 42 finished with value: 0.2176470588235294 and parameters: {'n_estimators': 885, 'num_leaves': 1161, 'max_depth': 250, 'learning_rate': 0.01831064740896929, 'min_child_samples': 29}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:41:11,422] Trial 43 finished with value: 0.20774647887323944 and parameters: {'n_estimators': 1331, 'num_leaves': 1703, 'max_depth': 278, 'learning_rate': 0.007027210576690402, 'min_child_samples': 66}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:41:45,936] Trial 44 finished with value: 0.2255192878338279 and parameters: {'n_estimators': 701, 'num_leaves': 1494, 'max_depth': 185, 'learning_rate': 0.02171034218115478, 'min_child_samples': 27}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:42:25,314] Trial 45 finished with value: 0.1936245572609209 and parameters: {'n_estimators': 599, 'num_leaves': 1491, 'max_depth': 163, 'learning_rate': 0.03971253708214842, 'min_child_samples': 4}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:43:24,655] Trial 46 finished with value: 0.21476510067114096 and parameters: {'n_estimators': 985, 'num_leaves': 1953, 'max_depth': 187, 'learning_rate': 0.02188823922250883, 'min_child_samples': 25}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:44:25,914] Trial 47 finished with value: 0.21739130434782608 and parameters: {'n_estimators': 1201, 'num_leaves': 1533, 'max_depth': 227, 'learning_rate': 0.017364658596441675, 'min_child_samples': 35}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:45:04,112] Trial 48 finished with value: 0.12177121771217711 and parameters: {'n_estimators': 1471, 'num_leaves': 623, 'max_depth': 147, 'learning_rate': 0.0055966378353996295, 'min_child_samples': 229}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:45:39,106] Trial 49 finished with value: 0.2080624187256177 and parameters: {'n_estimators': 519, 'num_leaves': 1703, 'max_depth': 176, 'learning_rate': 0.029716040648052593, 'min_child_samples': 14}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:46:22,882] Trial 50 finished with value: 0.20735785953177258 and parameters: {'n_estimators': 1138, 'num_leaves': 1342, 'max_depth': 193, 'learning_rate': 0.023730885629258257, 'min_child_samples': 74}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:46:48,664] Trial 51 finished with value: 0.21516754850088185 and parameters: {'n_estimators': 738, 'num_leaves': 1211, 'max_depth': 246, 'learning_rate': 0.01088990900635859, 'min_child_samples': 58}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:47:32,004] Trial 52 finished with value: 0.21566110397946084 and parameters: {'n_estimators': 885, 'num_leaves': 1362, 'max_depth': 207, 'learning_rate': 0.05757020530174976, 'min_child_samples': 46}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:48:08,954] Trial 53 finished with value: 0.2114047287899861 and parameters: {'n_estimators': 688, 'num_leaves': 1044, 'max_depth': 228, 'learning_rate': 0.013719172716767359, 'min_child_samples': 15}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:48:25,469] Trial 54 finished with value: 0.10302036993678296 and parameters: {'n_estimators': 596, 'num_leaves': 908, 'max_depth': 270, 'learning_rate': 0.0012513654675807648, 'min_child_samples': 84}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:49:02,019] Trial 55 finished with value: 0.2031523642732049 and parameters: {'n_estimators': 978, 'num_leaves': 1244, 'max_depth': 242, 'learning_rate': 0.019043436580162672, 'min_child_samples': 65}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:49:23,707] Trial 56 finished with value: 0.17679558011049723 and parameters: {'n_estimators': 803, 'num_leaves': 1071, 'max_depth': 286, 'learning_rate': 0.011223378248672084, 'min_child_samples': 110}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:50:23,701] Trial 57 finished with value: 0.19242902208201892 and parameters: {'n_estimators': 1685, 'num_leaves': 1526, 'max_depth': 221, 'learning_rate': 0.036882436622455175, 'min_child_samples': 135}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:51:28,329] Trial 58 finished with value: 0.2009345794392523 and parameters: {'n_estimators': 1083, 'num_leaves': 668, 'max_depth': 236, 'learning_rate': 0.07341312291079435, 'min_child_samples': 34}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:53:18,495] Trial 59 finished with value: 0.20316027088036118 and parameters: {'n_estimators': 1530, 'num_leaves': 1421, 'max_depth': 116, 'learning_rate': 0.004406873202255608, 'min_child_samples': 4}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:53:59,276] Trial 60 finished with value: 0.20735785953177258 and parameters: {'n_estimators': 938, 'num_leaves': 1784, 'max_depth': 201, 'learning_rate': 0.016158809302988623, 'min_child_samples': 46}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:55:12,218] Trial 61 finished with value: 0.22788203753351205 and parameters: {'n_estimators': 1142, 'num_leaves': 1631, 'max_depth': 214, 'learning_rate': 0.004019864738555192, 'min_child_samples': 19}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:56:33,573] Trial 62 finished with value: 0.22421524663677128 and parameters: {'n_estimators': 1237, 'num_leaves': 1310, 'max_depth': 186, 'learning_rate': 0.009557919278293817, 'min_child_samples': 23}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:57:10,986] Trial 63 finished with value: 0.22701149425287354 and parameters: {'n_estimators': 833, 'num_leaves': 1896, 'max_depth': 173, 'learning_rate': 0.004368033721059091, 'min_child_samples': 37}. Best is trial 27 with value: 0.2316043425814234.\n",
      "[I 2024-09-29 08:59:00,853] Trial 64 finished with value: 0.2381596752368065 and parameters: {'n_estimators': 1388, 'num_leaves': 2096, 'max_depth': 170, 'learning_rate': 0.004320561988307032, 'min_child_samples': 14}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:01:10,704] Trial 65 finished with value: 0.21386603995299647 and parameters: {'n_estimators': 1377, 'num_leaves': 2121, 'max_depth': 136, 'learning_rate': 0.004565809618585321, 'min_child_samples': 8}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:02:12,832] Trial 66 finished with value: 0.2358803986710964 and parameters: {'n_estimators': 1295, 'num_leaves': 2177, 'max_depth': 167, 'learning_rate': 0.007240988834222747, 'min_child_samples': 39}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:03:16,424] Trial 67 finished with value: 0.2262443438914027 and parameters: {'n_estimators': 1295, 'num_leaves': 2339, 'max_depth': 168, 'learning_rate': 0.003342114924433789, 'min_child_samples': 37}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:04:24,565] Trial 68 finished with value: 0.2134646962233169 and parameters: {'n_estimators': 1440, 'num_leaves': 2374, 'max_depth': 165, 'learning_rate': 0.0036560368130501915, 'min_child_samples': 43}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:06:02,186] Trial 69 finished with value: 0.21467391304347824 and parameters: {'n_estimators': 1305, 'num_leaves': 2195, 'max_depth': 119, 'learning_rate': 0.006370006075697063, 'min_child_samples': 15}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:07:29,259] Trial 70 finished with value: 0.23684210526315788 and parameters: {'n_estimators': 1764, 'num_leaves': 2073, 'max_depth': 154, 'learning_rate': 0.0034429454644833266, 'min_child_samples': 38}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:09:02,314] Trial 71 finished with value: 0.2179072276159655 and parameters: {'n_estimators': 1792, 'num_leaves': 2092, 'max_depth': 153, 'learning_rate': 0.0015004553336721727, 'min_child_samples': 35}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:10:16,319] Trial 72 finished with value: 0.21775544388609716 and parameters: {'n_estimators': 1594, 'num_leaves': 2238, 'max_depth': 98, 'learning_rate': 0.0042262816321868785, 'min_child_samples': 47}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:11:51,193] Trial 73 finished with value: 0.20725388601036268 and parameters: {'n_estimators': 2152, 'num_leaves': 1907, 'max_depth': 136, 'learning_rate': 0.008250648655045042, 'min_child_samples': 62}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:13:35,831] Trial 74 finished with value: 0.217032967032967 and parameters: {'n_estimators': 1930, 'num_leaves': 2479, 'max_depth': 169, 'learning_rate': 0.014133601191677336, 'min_child_samples': 39}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:15:24,083] Trial 75 finished with value: 0.13805231919103098 and parameters: {'n_estimators': 1247, 'num_leaves': 2048, 'max_depth': 157, 'learning_rate': 0.0011543005823748359, 'min_child_samples': 12}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:16:33,309] Trial 76 finished with value: 0.20577617328519857 and parameters: {'n_estimators': 1727, 'num_leaves': 2363, 'max_depth': 174, 'learning_rate': 0.008937567689865178, 'min_child_samples': 74}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:17:17,417] Trial 77 finished with value: 0.1209829867674858 and parameters: {'n_estimators': 1535, 'num_leaves': 2282, 'max_depth': 146, 'learning_rate': 0.006494763735096584, 'min_child_samples': 170}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:19:16,635] Trial 78 finished with value: 0.2128712871287129 and parameters: {'n_estimators': 1655, 'num_leaves': 2581, 'max_depth': 127, 'learning_rate': 0.014865468826651233, 'min_child_samples': 20}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:20:28,545] Trial 79 finished with value: 0.21316614420062693 and parameters: {'n_estimators': 1375, 'num_leaves': 1884, 'max_depth': 192, 'learning_rate': 0.0036470542559384994, 'min_child_samples': 33}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:21:18,188] Trial 80 finished with value: 0.22183098591549297 and parameters: {'n_estimators': 1109, 'num_leaves': 1964, 'max_depth': 178, 'learning_rate': 0.01146452769379509, 'min_child_samples': 50}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:22:36,910] Trial 81 finished with value: 0.219941348973607 and parameters: {'n_estimators': 1161, 'num_leaves': 2062, 'max_depth': 162, 'learning_rate': 0.007870731700067135, 'min_child_samples': 19}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:23:48,289] Trial 82 finished with value: 0.23787167449139282 and parameters: {'n_estimators': 1282, 'num_leaves': 2137, 'max_depth': 143, 'learning_rate': 0.009500838872191534, 'min_child_samples': 30}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:26:07,092] Trial 83 finished with value: 0.20892018779342722 and parameters: {'n_estimators': 1419, 'num_leaves': 2194, 'max_depth': 144, 'learning_rate': 0.003937202001030426, 'min_child_samples': 9}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:27:09,902] Trial 84 finished with value: 0.22988505747126436 and parameters: {'n_estimators': 1265, 'num_leaves': 2456, 'max_depth': 157, 'learning_rate': 0.01012542654056412, 'min_child_samples': 41}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:28:38,452] Trial 85 finished with value: 0.21153846153846154 and parameters: {'n_estimators': 1881, 'num_leaves': 2706, 'max_depth': 128, 'learning_rate': 0.012686957119569792, 'min_child_samples': 55}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:29:48,556] Trial 86 finished with value: 0.23417721518987342 and parameters: {'n_estimators': 1281, 'num_leaves': 2479, 'max_depth': 157, 'learning_rate': 0.006153852015823029, 'min_child_samples': 29}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:31:20,985] Trial 87 finished with value: 0.19168591224018475 and parameters: {'n_estimators': 1263, 'num_leaves': 2471, 'max_depth': 105, 'learning_rate': 0.09018938488508789, 'min_child_samples': 29}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:33:24,631] Trial 88 finished with value: 0.18956336528221512 and parameters: {'n_estimators': 1039, 'num_leaves': 2921, 'max_depth': 60, 'learning_rate': 0.010014533800129002, 'min_child_samples': 3}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:35:06,270] Trial 89 finished with value: 0.20802005012531324 and parameters: {'n_estimators': 1473, 'num_leaves': 2715, 'max_depth': 151, 'learning_rate': 0.01604380278321857, 'min_child_samples': 21}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:35:47,227] Trial 90 finished with value: 0.12757973733583491 and parameters: {'n_estimators': 1591, 'num_leaves': 2269, 'max_depth': 158, 'learning_rate': 0.0067699994667330095, 'min_child_samples': 254}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[I 2024-09-29 09:36:54,237] Trial 91 finished with value: 0.22512234910277326 and parameters: {'n_estimators': 1341, 'num_leaves': 1677, 'max_depth': 139, 'learning_rate': 0.00935046041796811, 'min_child_samples': 38}. Best is trial 64 with value: 0.2381596752368065.\n",
      "[W 2024-09-29 09:38:20,629] Trial 92 failed with parameters: {'n_estimators': 2654, 'num_leaves': 2151, 'max_depth': 158, 'learning_rate': 0.02016529881864451, 'min_child_samples': 42} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_22900\\3531454242.py\", line 45, in <lambda>\n",
      "    study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_22900\\3531454242.py\", line 26, in objectiveLGBM_dart\n",
      "    model.fit(x_tr, y_tr)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1298, in fit\n",
      "    init_model=init_model,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\", line 963, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\", line 4138, in update\n",
      "    ctypes.byref(is_finished),\n",
      "KeyboardInterrupt\n",
      "[W 2024-09-29 09:38:20,633] Trial 92 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22900\\3531454242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22900\\3531454242.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# 하이퍼 파라미터 튜닝\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobjectiveLGBM_dart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best trial: score {}, \\nparams {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22900\\3531454242.py\u001b[0m in \u001b[0;36mobjectiveLGBM_dart\u001b[1;34m(trial, x_tr, y_tr, x_val, y_val)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mpred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 양성 클래스 확률\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_proba\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mTHRESHOLD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 스레드홀드에 따른 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m         )\n\u001b[0;32m   1300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metrics_callable\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    305\u001b[0m             )\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4136\u001b[0m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m                 )\n\u001b[0;32m   4140\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 'Normal'과 'AbNormal'을 숫자로 변환\n",
    "train_data_fill1['target'] = train_data_fill1['target'].map({'Normal': 0, 'AbNormal': 1})\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "def objectiveLGBM_dart(trial, x_tr, y_tr, x_val, y_val):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 3000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 500, 3000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 3, 300),\n",
    "        \n",
    "        'boosting_type': 'dart',  # 'boosting'를 'boosting_type'으로 수정\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1\n",
    "    }\n",
    "       \n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    pred = (pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "    \n",
    "    score = f1_score(y_val, pred, average=\"binary\")\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 데이터셋 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_data_fill1.drop(\"target\", axis=1),\n",
    "    train_data_fill1[\"target\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "# 하이퍼 파라미터 튜닝\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\n",
    "study.optimize(lambda trial: objectiveLGBM_dart(trial, x_train, y_train, x_val, y_val), n_trials=200)\n",
    "\n",
    "print('Best trial: score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036385b7",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
