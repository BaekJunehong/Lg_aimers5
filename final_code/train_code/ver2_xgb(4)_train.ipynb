{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c41e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost==2.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.3\n",
    "RANDOM_STATE = 110\n",
    "\n",
    "train_data = pd.read_csv(\"./data/final_train_data_ver2.csv\")\n",
    "test_data = pd.read_csv(\"./data/final_test_data_ver2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam, fill1, fill2 공통 변수\n",
    "var_dam_fill = [\n",
    "    'Equipment_same_num',\n",
    "    'PalletID_Collect_Result_encoded',\n",
    "    'Production_Qty_Collect_Result_encoded',\n",
    "    'WorkMode Collect Result',\n",
    "    'Receip_n_suffix_3',\n",
    "    'time_gap_All'\n",
    "]\n",
    "\n",
    "# 전체 공통 변수\n",
    "### correlation 확인을 위한 변수 리스트\n",
    "var_all_corr = [\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### train\n",
    "var_all_train = [\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]\n",
    "\n",
    "### test\n",
    "var_all_test = [\n",
    "    'Set ID',\n",
    "    'target',\n",
    "    'model_suffix_encoded',\n",
    "    'cleaned_workorder_encoded'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b003ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Dam'을 포함하는 변수 선택\n",
    "dam_variables = [var for var in train_data.columns if '_Dam' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + dam_variables\n",
    "train_data_dam = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + dam_variables\n",
    "test_data_dam = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a333ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill1'을 포함하는 변수 선택\n",
    "fill1_variables = [var for var in train_data.columns if '_Fill1' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill1_variables\n",
    "train_data_fill1 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill1_variables\n",
    "test_data_fill1 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_Fill2'을 포함하는 변수 선택\n",
    "fill2_variables = [var for var in train_data.columns if '_Fill2' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_dam_fill + var_all_train + fill2_variables\n",
    "train_data_fill2 = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_dam_fill + var_all_test + fill2_variables\n",
    "test_data_fill2 = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ffec39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_AutoClave'을 포함하는 변수 선택\n",
    "autoclave_variables = [var for var in train_data.columns if '_AutoClave' in var]\n",
    "\n",
    "# train\n",
    "final_columns_train = var_all_train + autoclave_variables\n",
    "train_data_autoclave = train_data[final_columns_train]\n",
    "\n",
    "# test \n",
    "final_columns_test = var_all_test + autoclave_variables\n",
    "test_data_autoclave = test_data[final_columns_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be86915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----train data-----\n",
      "train_data DataFrame의 칼럼 수: 44\n",
      "train_data_dam DataFrame의 칼럼 수: 25\n",
      "train_data_autoclave DataFrame의 칼럼 수: 8\n",
      "train_data_fill1 DataFrame의 칼럼 수: 16\n",
      "train_data_fill2 DataFrame의 칼럼 수: 16\n",
      "----test data-----\n",
      "test_data DataFrame의 칼럼 수: 45\n",
      "test_data_dam DataFrame의 칼럼 수: 26\n",
      "test_data_autoclave DataFrame의 칼럼 수: 9\n",
      "test_data_fill1 DataFrame의 칼럼 수: 17\n",
      "test_data_fill2 DataFrame의 칼럼 수: 17\n"
     ]
    }
   ],
   "source": [
    "# 각 DataFrame의 칼럼 수 계산\n",
    "num_columns_train_data = train_data.shape[1]\n",
    "num_columns_train_data_dam = train_data_dam.shape[1]\n",
    "num_columns_train_data_autoclave = train_data_autoclave.shape[1]\n",
    "num_columns_train_data_fill1 = train_data_fill1.shape[1]\n",
    "num_columns_train_data_fill2 = train_data_fill2.shape[1]\n",
    "\n",
    "num_columns_test_data = test_data.shape[1]\n",
    "num_columns_test_data_dam = test_data_dam.shape[1]\n",
    "num_columns_test_data_autoclave = test_data_autoclave.shape[1]\n",
    "num_columns_test_data_fill1 = test_data_fill1.shape[1]\n",
    "num_columns_test_data_fill2 = test_data_fill2.shape[1]\n",
    "\n",
    "# 각 DataFrame의 칼럼 수 출력\n",
    "print(\"----train data-----\")\n",
    "print(f\"train_data DataFrame의 칼럼 수: {num_columns_train_data}\")\n",
    "print(f\"train_data_dam DataFrame의 칼럼 수: {num_columns_train_data_dam}\")\n",
    "print(f\"train_data_autoclave DataFrame의 칼럼 수: {num_columns_train_data_autoclave}\")\n",
    "print(f\"train_data_fill1 DataFrame의 칼럼 수: {num_columns_train_data_fill1}\")\n",
    "print(f\"train_data_fill2 DataFrame의 칼럼 수: {num_columns_train_data_fill2}\")\n",
    "print(\"----test data-----\")\n",
    "print(f\"test_data DataFrame의 칼럼 수: {num_columns_test_data}\")\n",
    "print(f\"test_data_dam DataFrame의 칼럼 수: {num_columns_test_data_dam}\")\n",
    "print(f\"test_data_autoclave DataFrame의 칼럼 수: {num_columns_test_data_autoclave}\")\n",
    "print(f\"test_data_fill1 DataFrame의 칼럼 수: {num_columns_test_data_fill1}\")\n",
    "print(f\"test_data_fill2 DataFrame의 칼럼 수: {num_columns_test_data_fill2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7941e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5b59",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa06da",
   "metadata": {},
   "source": [
    "### 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d288bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# 스레드홀드 설정\n",
    "THRESHOLD = 0.3\n",
    "\n",
    "# 모델 설정 및 하이퍼파라미터\n",
    "models = {\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'cat': CatBoostClassifier(),\n",
    "    'lgbm': LGBMClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "    'ada': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "def train_and_evaluate_model(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    # 예측\n",
    "    y_val_pred_proba = model.predict_proba(x_val)[:, 1]  # 양성 클래스 확률\n",
    "    y_val_pred = (y_val_pred_proba >= THRESHOLD).astype(int)  # 스레드홀드에 따른 예측\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def fit_all_train_data_function(model_name, data, **params):\n",
    "    if model_name not in models:\n",
    "        print(f\"{model_name}은(는) 지원되지 않는 모델입니다.\")\n",
    "        return None  # 지원되지 않는 모델일 경우 None 반환\n",
    "    \n",
    "    # 모델 선택\n",
    "    model = models[model_name].__class__()  # 새로운 모델 인스턴스 생성\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    model.set_params(**params)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(data.drop(\"target\", axis=1), data[\"target\"].map({'Normal': 0, 'AbNormal': 1}))\n",
    "\n",
    "    # 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\n",
    "    data_name = [name for name in globals() if globals()[name] is data][0]\n",
    "\n",
    "    print(f'{model_name} 모델이 {data_name} 데이터로 학습 완료')\n",
    "    return model  # 학습된 모델 반환\n",
    "\n",
    "def voting_function(data, estimators, voting='hard', threshold=0.5):\n",
    "    # 데이터셋 분할 # voting='hard'일 경우 threshold는 사용되지 않음\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        data.drop(\"target\", axis=1),\n",
    "        data[\"target\"].map({'Normal': 0, 'AbNormal': 1}),\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    # VotingClassifier 설정\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting=voting)\n",
    "\n",
    "    # 모델 학습\n",
    "    voting_clf.fit(x_train, y_train)\n",
    "\n",
    "    if voting == 'soft':\n",
    "        # 소프트 보팅의 경우 확률 예측\n",
    "        y_val_pred_proba = voting_clf.predict_proba(x_val)[:, 1]\n",
    "        y_val_pred = (y_val_pred_proba >= threshold).astype(int)\n",
    "    else:\n",
    "        # 하드 보팅의 경우 직접 예측\n",
    "        y_val_pred = voting_clf.predict(x_val)\n",
    "\n",
    "    # 평가지표 계산\n",
    "    f1 = f1_score(y_val, y_val_pred, average=\"binary\")\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_val_pred)\n",
    "    conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f'Voting Classifier로 학습한 결과:')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('---')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    print('---')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print('\\n')\n",
    "\n",
    "    return voting_clf  # 학습된 VotingClassifier 반환\n",
    "\n",
    "def voting(preds_or_probs, method='soft', threshold=0.3):\n",
    "    \"\"\"\n",
    "    하드 보팅 또는 소프트 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "    Parameters:\n",
    "    preds_or_probs (list of np.array): 각 모델의 예측 배열 리스트 (하드 보팅) 또는 예측 확률 배열 리스트 (소프트 보팅)\n",
    "    method (str): 'soft' 또는 'hard' 보팅 방법 선택\n",
    "    threshold (float): 소프트 보팅 시 예측을 양성으로 간주할 확률 임계값\n",
    "\n",
    "    Returns:\n",
    "    np.array: 최종 예측 결과\n",
    "    \"\"\"\n",
    "    if method == 'soft':\n",
    "        # 소프트 보팅: 각 모델의 확률 평균 계산\n",
    "        soft_voting_probs = np.mean(preds_or_probs, axis=0)\n",
    "        # 최종 예측: 평균 확률에 대해 스레드 홀드 적용\n",
    "        final_predictions = (soft_voting_probs >= threshold).astype(int)\n",
    "    elif method == 'hard':\n",
    "        # 하드 보팅: 각 모델의 예측을 모아서 다수결 원칙 적용\n",
    "        preds = np.array(preds_or_probs)\n",
    "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "    else:\n",
    "        raise ValueError(\"method 인자는 'soft' 또는 'hard'여야 합니다.\")\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2af914",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15f2a7",
   "metadata": {},
   "source": [
    "Dam 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24c98a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model_Dam \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_dam\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1856\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01638311402750273\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.540170869128343e-05\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.003773016359390547\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_alpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.15796324877186574\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_lambda\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3878919320887503\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolsample_bytree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9991002332152314\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6530278893487681\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary:logistic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexact\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 47\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model_name, data, **params)\u001b[0m\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# 데이터 이름을 자동으로 추출하기 위한 래퍼 함수\u001b[39;00m\n\u001b[1;32m     50\u001b[0m data_name \u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;129;01mis\u001b[39;00m data][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model_Dam = train_and_evaluate_model(\n",
    "    'xgb', train_data_dam\n",
    "    , n_estimators = 1856\n",
    "    , learning_rate = 0.01638311402750273\n",
    "    , max_depth = 5\n",
    "    , alpha = 1.540170869128343e-05\n",
    "    , gamma = 0.003773016359390547\n",
    "    , reg_alpha = 0.15796324877186574\n",
    "    , reg_lambda = 0.3878919320887503\n",
    "    , colsample_bytree = 0.9991002332152314\n",
    "    , subsample = 0.6530278893487681\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b184d",
   "metadata": {},
   "source": [
    "AutoClave 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7cbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_AutoClave = train_and_evaluate_model(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1826, \n",
    "    learning_rate = 0.025532149504411204, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.002258943897259359, \n",
    "    gamma = 2.1767130934899896e-05, \n",
    "    reg_alpha = 0.6788369039489287, \n",
    "    reg_lambda = 0.9390213394779513, \n",
    "    colsample_bytree = 0.966269917168233, \n",
    "    subsample = 0.3318345199347898,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d357e142",
   "metadata": {},
   "source": [
    "Fill1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a1e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_Fill1 = train_and_evaluate_model(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1938, \n",
    "    learning_rate = 0.010824981733462226, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.0002625738567143068,\n",
    "    gamma = 0.0004710954812783293,\n",
    "    reg_alpha =  0.43802975941948236, \n",
    "    reg_lambda = 0.38175795577379884, \n",
    "    colsample_bytree = 0.8935302706188526,\n",
    "    subsample = 0.558903924149479,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98025a2",
   "metadata": {},
   "source": [
    "Fill2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_Fill2 = train_and_evaluate_model(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1775, \n",
    "    learning_rate = 0.023666883670474672, \n",
    "    max_depth = 7, \n",
    "    alpha = 3.010808722829044e-05,\n",
    "    gamma = 0.0011030528723094237,\n",
    "    reg_alpha = 0.8140817957809128, \n",
    "    reg_lambda = 0.6322115614369442, \n",
    "    colsample_bytree = 0.965642065135186,\n",
    "    subsample = 0.28768158299274954,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb4d",
   "metadata": {},
   "source": [
    "전체공정 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_All = train_and_evaluate_model(\n",
    "#     'xgb', train_data,\n",
    "#     n_estimators = 2427,\n",
    "#     learning_rate = 0.010774204513905965, \n",
    "#     max_depth = 17, \n",
    "#     alpha = 0.0005233654110538582, \n",
    "#     gamma = 5.551445919277608e-05, \n",
    "#     reg_alpha = 0.9652805882189326, \n",
    "#     reg_lambda = 0.3542856398135083, \n",
    "#     colsample_bytree = 0.9094884645797131, \n",
    "#     subsample = 0.1733751790853043,\n",
    "#     objective = 'binary:logistic',  # 이진 분류\n",
    "#     tree_method = \"exact\", \n",
    "#     random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a59250",
   "metadata": {},
   "source": [
    "soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VotingClassifier 사용 \n",
    "estimators = [\n",
    "      ('dam', train_model_Dam)\n",
    "    , ('autoclave', train_model_AutoClave)\n",
    "    , ('fill1', train_model_Fill1)\n",
    "    , ('fill2', train_model_Fill2)\n",
    "    # , ('all', train_model_All)\n",
    "]\n",
    "\n",
    "# VotingClassifier 학습 및 평가\n",
    "# voting_clf_hard = voting_function(train_data, estimators, voting='hard')\n",
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb2eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e907e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d329d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ad24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_clf_soft = voting_function(train_data, estimators, voting='soft', threshold=0.22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7548c01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec6ee4",
   "metadata": {},
   "source": [
    "### 모델 학습(train 데이터 전체 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa25b4",
   "metadata": {},
   "source": [
    "위의 모델학습 코드에서 함수명만 바뀌고 들어가는 값들은 동일  \n",
    "-> 위의 코드 복붙한다음 함수명만 바꿔주면 사용하기 편함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c08dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 모델이 train_data_dam 데이터로 학습 완료\n",
      "xgb 모델이 train_data_autoclave 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill1 데이터로 학습 완료\n",
      "xgb 모델이 train_data_fill2 데이터로 학습 완료\n"
     ]
    }
   ],
   "source": [
    "model_Dam = fit_all_train_data_function(\n",
    "        'xgb', train_data_dam\n",
    "    , n_estimators = 1856\n",
    "    , learning_rate = 0.01638311402750273\n",
    "    , max_depth = 5\n",
    "    , alpha = 1.540170869128343e-05\n",
    "    , gamma = 0.003773016359390547\n",
    "    , reg_alpha = 0.15796324877186574\n",
    "    , reg_lambda = 0.3878919320887503\n",
    "    , colsample_bytree = 0.9991002332152314\n",
    "    , subsample = 0.6530278893487681\n",
    "    , objective = 'binary:logistic'\n",
    "    , tree_method = 'exact'\n",
    "    , random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_AutoClave = fit_all_train_data_function(\n",
    "    'xgb', train_data_autoclave,\n",
    "    n_estimators = 1826, \n",
    "    learning_rate = 0.025532149504411204, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.002258943897259359, \n",
    "    gamma = 2.1767130934899896e-05, \n",
    "    reg_alpha = 0.6788369039489287, \n",
    "    reg_lambda = 0.9390213394779513, \n",
    "    colsample_bytree = 0.966269917168233, \n",
    "    subsample = 0.3318345199347898,\n",
    "    objective = 'binary:logistic',  # 이진 분류\n",
    "    tree_method = \"exact\", \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill1 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill1,\n",
    "    n_estimators = 1938, \n",
    "    learning_rate = 0.010824981733462226, \n",
    "    max_depth = 8, \n",
    "    alpha = 0.0002625738567143068,\n",
    "    gamma = 0.0004710954812783293,\n",
    "    reg_alpha =  0.43802975941948236, \n",
    "    reg_lambda = 0.38175795577379884, \n",
    "    colsample_bytree = 0.8935302706188526,\n",
    "    subsample = 0.558903924149479,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model_Fill2 = fit_all_train_data_function(\n",
    "    'xgb', train_data_fill2,\n",
    "    n_estimators = 1775, \n",
    "    learning_rate = 0.023666883670474672, \n",
    "    max_depth = 7, \n",
    "    alpha = 3.010808722829044e-05,\n",
    "    gamma = 0.0011030528723094237,\n",
    "    reg_alpha = 0.8140817957809128, \n",
    "    reg_lambda = 0.6322115614369442, \n",
    "    colsample_bytree = 0.965642065135186,\n",
    "    subsample = 0.28768158299274954,\n",
    "    objective = 'binary:logistic',\n",
    "    tree_method = 'exact',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# model_All = fit_all_train_data_function(\n",
    "# 'xgb', train_data,\n",
    "#     n_estimators = 2427,\n",
    "#     learning_rate = 0.010774204513905965, \n",
    "#     max_depth = 17, \n",
    "#     alpha = 0.0005233654110538582, \n",
    "#     gamma = 5.551445919277608e-05, \n",
    "#     reg_alpha = 0.9652805882189326, \n",
    "#     reg_lambda = 0.3542856398135083, \n",
    "#     colsample_bytree = 0.9094884645797131, \n",
    "#     subsample = 0.1733751790853043,\n",
    "#     objective = 'binary:logistic',  # 이진 분류\n",
    "#     tree_method = \"exact\", \n",
    "#     random_state=RANDOM_STATE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8b158",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee55c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측에 필요한 데이터 분리\n",
    "x_test_dam = test_data_dam.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_autoclave = test_data_autoclave.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill1 = test_data_fill1.drop([\"target\", \"Set ID\"], axis=1)\n",
    "x_test_fill2 = test_data_fill2.drop([\"target\", \"Set ID\"], axis=1)\n",
    "# x_test_all = test_data.drop([\"target\", \"Set ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d855e",
   "metadata": {},
   "source": [
    "Voting(hard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98f3e1",
   "metadata": {},
   "source": [
    "4개의 모델중 다수의 모델이 판단한 값을 타겟값으로 가져감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c7f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예측 리스트 (하드 보팅용)\n",
    "# preds = [\n",
    "#     model_Dam.predict(x_test_dam)\n",
    "#     , model_AutoClave.predict(x_test_autoclave)\n",
    "#     , model_Fill1.predict(x_test_fill1)\n",
    "#     , model_Fill2.predict(x_test_fill2)\n",
    "#     , model_All.predict(x_test_all)\n",
    "# ]\n",
    "\n",
    "# # 하드 보팅 결과\n",
    "# final_predictions = voting(preds, method='hard')\n",
    "# print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287a3c3",
   "metadata": {},
   "source": [
    "Voting(soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a4ed1",
   "metadata": {},
   "source": [
    "4개의 모델의 확률의 합에 대한 평균이 일정 수치(스레스홀드) 값을 넘으면 AbNormal 값을 가짐  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5151edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    }
   ],
   "source": [
    "# 예측 확률 리스트 (소프트 보팅용)\n",
    "probs = [\n",
    "    model_Dam.predict_proba(x_test_dam)[:, 1]\n",
    "    , model_AutoClave.predict_proba(x_test_autoclave)[:, 1]\n",
    "    , model_Fill1.predict_proba(x_test_fill1)[:, 1]\n",
    "    , model_Fill2.predict_proba(x_test_fill2)[:, 1]\n",
    "    # , model_All.predict_proba(x_test_all)[:, 1]\n",
    "]\n",
    "\n",
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.26)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ce9f85",
   "metadata": {},
   "source": [
    "threshold 0.26 score: 0.2358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d825264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.24)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869213b7",
   "metadata": {},
   "source": [
    "threshold 0.24 score: 0.23281907433380084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac35926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.28)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60e407",
   "metadata": {},
   "source": [
    "0.28 score: 0.22560975609756098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65a1315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.22)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e5524",
   "metadata": {},
   "source": [
    "0.22 score: 0.2431372549019608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e75f1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586\n"
     ]
    }
   ],
   "source": [
    "# 소프트 보팅 결과\n",
    "final_predictions = voting(probs, method='soft', threshold=0.2)\n",
    "print(sum(final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b477361",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2 score: 0.237"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170f013",
   "metadata": {},
   "source": [
    "=== Message ===\n",
    "\n",
    "작성하신 답안 제출이 완료되었습니다.\n",
    "\n",
    "Public Score : 0.22973"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be6ab9",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f188b",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "754986da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = final_predictions\n",
    "\n",
    "# df_sub['target'] 값을 문자열 레이블로 변환\n",
    "df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844bfe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      16775\n",
       "AbNormal      586\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9efee1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba0550e",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8a8f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b240214",
   "metadata": {},
   "source": [
    "## 5. ETC..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899379df",
   "metadata": {},
   "source": [
    "모델을 통해 예측해 낸 정답지(csv) 파일의 결과값을 불러와 voting 하는 방식  \n",
    "이때의 voting은 hard방식만 가능(예측확률은 저장되어있지 않음으로 soft 보팅은 불가능)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03053beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def read_submission_files(file_paths):\n",
    "#     \"\"\"\n",
    "#     제출 파일을 읽어와서 예측 결과를 반환합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     file_paths (list of str): 제출 파일 경로 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     list of np.array: 각 제출 파일의 예측 결과 리스트\n",
    "#     \"\"\"\n",
    "#     predictions = []\n",
    "#     for file_path in file_paths:\n",
    "#         df = pd.read_csv(file_path)\n",
    "#         preds = df['target'].apply(lambda x: 1 if x == 'AbNormal' else 0).values\n",
    "#         predictions.append(preds)\n",
    "#     return predictions\n",
    "\n",
    "# def hard_voting(preds):\n",
    "#     \"\"\"\n",
    "#     하드 보팅을 사용하여 최종 예측을 수행합니다.\n",
    "\n",
    "#     Parameters:\n",
    "#     preds (list of np.array): 각 모델의 예측 배열 리스트\n",
    "\n",
    "#     Returns:\n",
    "#     np.array: 최종 예측 결과\n",
    "#     \"\"\"\n",
    "#     preds = np.array(preds)\n",
    "#     final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=preds)\n",
    "#     return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae7de4",
   "metadata": {},
   "source": [
    "submission_file 에서 csv 파일을 불러와 hard voting 하는 알고리즘  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d98d36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 공통 경로\n",
    "# common_path = \"C:/Users/KimDongyoung/Desktop/git_LGaimers5/Lg_aimers5/data/submission_file/\"\n",
    "\n",
    "# # 제출 파일 이름 리스트\n",
    "# file_names = [\n",
    "#     \"data0816_light_cutoff0.28_submission.csv\",\n",
    "#     \"submission_score0.23.csv\"\n",
    "#     # 파일 추가 가능  <----- 파일 필요시 추가하세요!!\n",
    "# ]\n",
    "\n",
    "# # 경로를 추가하는 함수\n",
    "# def add_common_path(file_names, common_path):\n",
    "#     return [common_path + file_name for file_name in file_names]\n",
    "\n",
    "# # 경로가 추가된 파일 리스트\n",
    "# file_paths = add_common_path(file_names, common_path)\n",
    "\n",
    "# # 제출 파일에서 예측 결과 읽어오기\n",
    "# predictions = read_submission_files(file_paths)\n",
    "\n",
    "# # 하드 보팅 결과\n",
    "# final_predictions_hard = hard_voting(predictions)\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장할 파일 이름\n",
    "# output_file_name = \"final_submission.csv\" # <----- 파일 이름을 변경하세요!!\n",
    "\n",
    "# # 결과를 새로운 제출 파일로 저장\n",
    "# df_sub = pd.read_csv(file_paths[0])\n",
    "# df_sub[\"target\"] = final_predictions_hard\n",
    "# df_sub['target'] = df_sub['target'].apply(lambda x: 'AbNormal' if x == 1 else 'Normal')\n",
    "# df_sub.to_csv(output_file_name, index=False)\n",
    "\n",
    "# print(f\"최종 제출 파일이 '{output_file_name}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d826211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2138cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
